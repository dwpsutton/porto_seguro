{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simpler modelling stack, where models have been pulled from the stack if they are not useful.  Strangely, the regularization on the top level of the stack must be light l1.  Produces 0.28966 in local test. Just over 0.285 on LB.  Position: 387 (386 was bottom of bronze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd,matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(array):\n",
    "    srtInd = array.argsort()\n",
    "    ranks = np.empty(len(array), float)\n",
    "    ranks[srtInd] = np.arange(len(array))\n",
    "    return ranks / float(len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keeps= np.load(open('xgboost_rfe_keepers.bin','rb'))\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, n_splits, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]              \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                #\n",
    "                test_probs= clf.predict_proba(T)[:,1]\n",
    "                S_test_i[:, j] = np.log(test_probs) - np.log(1.0 - test_probs)\n",
    "            agg_lor= S_test_i.mean(axis=1)\n",
    "            S_test[:, i] = 1.0 / (1.0 + np.exp( -agg_lor) )\n",
    "        return S_train,S_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add output of layer results ofr quick iteration\n",
    "class Stack:\n",
    "    def __init__(self,k_folds,hidden_layers,top_layer,saveInternalVectors=False):\n",
    "        self.saveInternalVectors= saveInternalVectors\n",
    "        self.layers= []\n",
    "        for h in hidden_layers:\n",
    "            self.layers.append( Layer(k_folds,h) )\n",
    "        self.top_layer= top_layer \n",
    "        return None\n",
    "    \n",
    "    def fit_predict(self,X,y,T,external_base_scores= None):\n",
    "        Xt_train= copy.deepcopy(X)\n",
    "        Xt_test= copy.deepcopy(T)\n",
    "        i= 1\n",
    "        for layer in self.layers:\n",
    "            print 'Fitting stack layer '+str(i)\n",
    "            Xt_train, Xt_test= layer.fit_predict(Xt_train,y,Xt_test)\n",
    "            if external_base_scores is not None and i==1:\n",
    "                Xt_train= np.concatenate( (Xt_train,np.reshape(external_base_scores[0],\n",
    "                                                               (np.shape(external_base_scores[0])[0],1))),\n",
    "                                         axis=1)\n",
    "                Xt_test= np.concatenate( (Xt_test,np.reshape(external_base_scores[1],\n",
    "                                                            (np.shape(external_base_scores[1])[0],1))), \n",
    "                                        axis=1)\n",
    "            #\n",
    "            # Add entropy score from layer\n",
    "#             train_entropy= np.array(map(lambda i: np.sum(Xt_train[i] * np.log(Xt_train[i])), \n",
    "#                                         range(np.shape(Xt_train)[0] )))\n",
    "#             Xt_train= np.concatenate( (Xt_train,np.reshape(train_entropy,(len(train_entropy),1))) ,axis=1)\n",
    "#             test_entropy= np.array(map(lambda i: np.sum(Xt_test[i] * np.log(Xt_test[i])), \n",
    "#                                         range(np.shape(Xt_test)[0] )))\n",
    "#             Xt_test= np.concatenate( (Xt_test,np.reshape(test_entropy,(len(test_entropy),1))) ,axis=1)\n",
    "            #\n",
    "#             # Rank transform\n",
    "#             for jj in range(np.shape(Xt_train)[1]):\n",
    "#                 Xt_train[:,jj]= rank(Xt_train[:,jj])\n",
    "#                 Xt_test[:,jj]= rank(Xt_test[:,jj])\n",
    "#             #\n",
    "            if self.saveInternalVectors:\n",
    "                fname= 'STACK_internal_train_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_train)\n",
    "                fname= 'STACK_internal_test_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_test)\n",
    "            i+=1\n",
    "#         for i in range(np.shape(Xt_train)[1]): #-1 so we don't apply to entropy!!\n",
    "#             p= copy.deepcopy(Xt_train[:,i])\n",
    "#             Xt_train[:,i]= np.log( p ) - np.log(1.0 - p)\n",
    "        self.top_layer.fit(Xt_train,y)\n",
    "        return self.top_layer.predict_proba(Xt_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now score the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "# train\n",
    "X_train= np.load(open('../wp013/full_train_matrix.bin','rb'))\n",
    "y_train= np.load(open('../wp013/full_train_labels.bin','rb'))\n",
    "\n",
    "# test\n",
    "X_test= np.load(open('../wp013/blind_test_matrix.bin','rb'))\n",
    "# y_test= np.load(open('../wp013/blind_test_labels.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keeps= np.load(open('xgboost_rfe_keepers.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sklearn.linear_model\n",
    "# lr= sklearn.linear_model.LogisticRegression(C=10000.0,class_weight={0:1.,1.:10/0.034},penalty='l1')\n",
    "# lr.fit(X_train,y_train)\n",
    "# y_pred= lr.predict_proba(X_test)[:,1]\n",
    "# print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ids= pd.read_csv('../data/test.csv',usecols=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm.sklearn\n",
    "import xgboost.sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.neural_network\n",
    "\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['n_estimators'] = 1300\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['num_leaves']= 25\n",
    "lgb_params['n_jobs']=8\n",
    "\n",
    "\n",
    "lgb_params_3 = {\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 800,\n",
    "    'max_depth': 4,\n",
    "    'n_jobs':8\n",
    "}\n",
    "\n",
    "lgb_params_4 = {\n",
    "    'learning_rate':0.05,\n",
    "    'n_estimators':600,\n",
    "    'num_leaves':35,\n",
    "    'min_child_samples':500,\n",
    "    'n_jobs':8\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params= {'learning_rate': 0.07,\n",
    "             'n_estimators':2000, #525,\n",
    "             'max_depth': 4, \n",
    "             'nthread':8,\n",
    "             'subsample': 0.8,\n",
    "             'min_child_weight':0.77,\n",
    "             'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', \n",
    "             'eval_metric': 'auc', \n",
    "             'seed': 99, \n",
    "             'silent': True,\n",
    "             'scale_pos_weight': 1.6,\n",
    "             'reg_alpha':8,\n",
    "             'reg_lambda':1.3,\n",
    "             'gamma':10\n",
    "            }\n",
    "\n",
    "\n",
    "# Layer 1\n",
    "lgbm1 = lightgbm.sklearn.LGBMClassifier(**lgb_params)\n",
    "xgbm1= xgboost.sklearn.XGBClassifier(**xgb_params)\n",
    "lgbm3 = lightgbm.sklearn.LGBMClassifier(**lgb_params_3)\n",
    "lgbm4 = lightgbm.sklearn.LGBMClassifier(**lgb_params_4)\n",
    "\n",
    "# Top layer\n",
    "stacker= sklearn.linear_model.LogisticRegression(C=500.0,class_weight='balanced',penalty='l1')\n",
    "\n",
    "# Define the stack\n",
    "stack = Stack(10,[ [xgbm1,lgbm1,lgbm3,lgbm4] ], stacker)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting stack layer 1\n",
      "Fit XGBClassifier fold 1\n",
      "Fit XGBClassifier fold 2\n",
      "Fit XGBClassifier fold 3\n",
      "Fit XGBClassifier fold 4\n",
      "Fit XGBClassifier fold 5\n",
      "Fit XGBClassifier fold 6\n",
      "Fit XGBClassifier fold 7\n",
      "Fit XGBClassifier fold 8\n",
      "Fit XGBClassifier fold 9\n",
      "Fit XGBClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      " Training took 5902.224565\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict\n",
    "from datetime import datetime\n",
    "tc= datetime.now()\n",
    "y_pred = stack.fit_predict(X_train, y_train, X_test) #,\n",
    "print' Training took '+str( (datetime.now() - tc).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best local score=  0.290737925496 0.289662696292\n",
      "Baseline 0.288711072302\n"
     ]
    }
   ],
   "source": [
    "print 'Best local score= ',0.290737925496,0.289662696292\n",
    "print 'Baseline',0.288711072302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df= pd.DataFrame( {'id': test_ids.id.values, 'target': y_pred},\n",
    "                     columns=['id','target']\n",
    "                    ).to_csv('submission_wp013d.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.587442\n",
      "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.604111\n",
      "[2]\tvalidation_0-auc:0.604609\n",
      "[3]\tvalidation_0-auc:0.609857\n",
      "[4]\tvalidation_0-auc:0.610012\n",
      "[5]\tvalidation_0-auc:0.613922\n",
      "[6]\tvalidation_0-auc:0.614897\n",
      "[7]\tvalidation_0-auc:0.615186\n",
      "[8]\tvalidation_0-auc:0.615893\n",
      "[9]\tvalidation_0-auc:0.615365\n",
      "[10]\tvalidation_0-auc:0.615606\n",
      "[11]\tvalidation_0-auc:0.616957\n",
      "[12]\tvalidation_0-auc:0.616898\n",
      "[13]\tvalidation_0-auc:0.61743\n",
      "[14]\tvalidation_0-auc:0.617757\n",
      "[15]\tvalidation_0-auc:0.618349\n",
      "[16]\tvalidation_0-auc:0.618636\n",
      "[17]\tvalidation_0-auc:0.619403\n",
      "[18]\tvalidation_0-auc:0.619486\n",
      "[19]\tvalidation_0-auc:0.619779\n",
      "[20]\tvalidation_0-auc:0.62052\n",
      "[21]\tvalidation_0-auc:0.621023\n",
      "[22]\tvalidation_0-auc:0.621524\n",
      "[23]\tvalidation_0-auc:0.62188\n",
      "[24]\tvalidation_0-auc:0.621653\n",
      "[25]\tvalidation_0-auc:0.621614\n",
      "[26]\tvalidation_0-auc:0.622377\n",
      "[27]\tvalidation_0-auc:0.622772\n",
      "[28]\tvalidation_0-auc:0.622941\n",
      "[29]\tvalidation_0-auc:0.623317\n",
      "[30]\tvalidation_0-auc:0.623473\n",
      "[31]\tvalidation_0-auc:0.62449\n",
      "[32]\tvalidation_0-auc:0.624793\n",
      "[33]\tvalidation_0-auc:0.624923\n",
      "[34]\tvalidation_0-auc:0.62488\n",
      "[35]\tvalidation_0-auc:0.626279\n",
      "[36]\tvalidation_0-auc:0.626619\n",
      "[37]\tvalidation_0-auc:0.626945\n",
      "[38]\tvalidation_0-auc:0.627313\n",
      "[39]\tvalidation_0-auc:0.627837\n",
      "[40]\tvalidation_0-auc:0.628155\n",
      "[41]\tvalidation_0-auc:0.628517\n",
      "[42]\tvalidation_0-auc:0.628616\n",
      "[43]\tvalidation_0-auc:0.629415\n",
      "[44]\tvalidation_0-auc:0.629958\n",
      "[45]\tvalidation_0-auc:0.629971\n",
      "[46]\tvalidation_0-auc:0.630711\n",
      "[47]\tvalidation_0-auc:0.63086\n",
      "[48]\tvalidation_0-auc:0.631253\n",
      "[49]\tvalidation_0-auc:0.631647\n",
      "[50]\tvalidation_0-auc:0.632153\n",
      "[51]\tvalidation_0-auc:0.632379\n",
      "[52]\tvalidation_0-auc:0.632536\n",
      "[53]\tvalidation_0-auc:0.632836\n",
      "[54]\tvalidation_0-auc:0.63293\n",
      "[55]\tvalidation_0-auc:0.632771\n",
      "[56]\tvalidation_0-auc:0.633295\n",
      "[57]\tvalidation_0-auc:0.633657\n",
      "[58]\tvalidation_0-auc:0.633835\n",
      "[59]\tvalidation_0-auc:0.633853\n",
      "[60]\tvalidation_0-auc:0.633976\n",
      "[61]\tvalidation_0-auc:0.634227\n",
      "[62]\tvalidation_0-auc:0.634441\n",
      "[63]\tvalidation_0-auc:0.634613\n",
      "[64]\tvalidation_0-auc:0.634893\n",
      "[65]\tvalidation_0-auc:0.634973\n",
      "[66]\tvalidation_0-auc:0.635009\n",
      "[67]\tvalidation_0-auc:0.635274\n",
      "[68]\tvalidation_0-auc:0.635453\n",
      "[69]\tvalidation_0-auc:0.635598\n",
      "[70]\tvalidation_0-auc:0.635873\n",
      "[71]\tvalidation_0-auc:0.636328\n",
      "[72]\tvalidation_0-auc:0.636499\n",
      "[73]\tvalidation_0-auc:0.636566\n",
      "[74]\tvalidation_0-auc:0.636754\n",
      "[75]\tvalidation_0-auc:0.636969\n",
      "[76]\tvalidation_0-auc:0.636927\n",
      "[77]\tvalidation_0-auc:0.636989\n",
      "[78]\tvalidation_0-auc:0.636914\n",
      "[79]\tvalidation_0-auc:0.637084\n",
      "[80]\tvalidation_0-auc:0.637189\n",
      "[81]\tvalidation_0-auc:0.637281\n",
      "[82]\tvalidation_0-auc:0.637417\n",
      "[83]\tvalidation_0-auc:0.63768\n",
      "[84]\tvalidation_0-auc:0.637647\n",
      "[85]\tvalidation_0-auc:0.637795\n",
      "[86]\tvalidation_0-auc:0.637892\n",
      "[87]\tvalidation_0-auc:0.637997\n",
      "[88]\tvalidation_0-auc:0.638071\n",
      "[89]\tvalidation_0-auc:0.638327\n",
      "[90]\tvalidation_0-auc:0.638783\n",
      "[91]\tvalidation_0-auc:0.638944\n",
      "[92]\tvalidation_0-auc:0.638931\n",
      "[93]\tvalidation_0-auc:0.639067\n",
      "[94]\tvalidation_0-auc:0.639423\n",
      "[95]\tvalidation_0-auc:0.639522\n",
      "[96]\tvalidation_0-auc:0.639469\n",
      "[97]\tvalidation_0-auc:0.639424\n",
      "[98]\tvalidation_0-auc:0.639716\n",
      "[99]\tvalidation_0-auc:0.639847\n",
      "[100]\tvalidation_0-auc:0.639897\n",
      "[101]\tvalidation_0-auc:0.639895\n",
      "[102]\tvalidation_0-auc:0.639942\n",
      "[103]\tvalidation_0-auc:0.639952\n",
      "[104]\tvalidation_0-auc:0.64005\n",
      "[105]\tvalidation_0-auc:0.640363\n",
      "[106]\tvalidation_0-auc:0.640342\n",
      "[107]\tvalidation_0-auc:0.640344\n",
      "[108]\tvalidation_0-auc:0.640529\n",
      "[109]\tvalidation_0-auc:0.640625\n",
      "[110]\tvalidation_0-auc:0.640695\n",
      "[111]\tvalidation_0-auc:0.640726\n",
      "[112]\tvalidation_0-auc:0.640689\n",
      "[113]\tvalidation_0-auc:0.640747\n",
      "[114]\tvalidation_0-auc:0.640898\n",
      "[115]\tvalidation_0-auc:0.640953\n",
      "[116]\tvalidation_0-auc:0.64103\n",
      "[117]\tvalidation_0-auc:0.640992\n",
      "[118]\tvalidation_0-auc:0.640943\n",
      "[119]\tvalidation_0-auc:0.641097\n",
      "[120]\tvalidation_0-auc:0.641298\n",
      "[121]\tvalidation_0-auc:0.641297\n",
      "[122]\tvalidation_0-auc:0.641308\n",
      "[123]\tvalidation_0-auc:0.641362\n",
      "[124]\tvalidation_0-auc:0.641368\n",
      "[125]\tvalidation_0-auc:0.64136\n",
      "[126]\tvalidation_0-auc:0.641413\n",
      "[127]\tvalidation_0-auc:0.64144\n",
      "[128]\tvalidation_0-auc:0.641409\n",
      "[129]\tvalidation_0-auc:0.641412\n",
      "[130]\tvalidation_0-auc:0.641417\n",
      "[131]\tvalidation_0-auc:0.641562\n",
      "[132]\tvalidation_0-auc:0.641654\n",
      "[133]\tvalidation_0-auc:0.64168\n",
      "[134]\tvalidation_0-auc:0.641703\n",
      "[135]\tvalidation_0-auc:0.641669\n",
      "[136]\tvalidation_0-auc:0.64172\n",
      "[137]\tvalidation_0-auc:0.641755\n",
      "[138]\tvalidation_0-auc:0.641755\n",
      "[139]\tvalidation_0-auc:0.641798\n",
      "[140]\tvalidation_0-auc:0.641896\n",
      "[141]\tvalidation_0-auc:0.641872\n",
      "[142]\tvalidation_0-auc:0.641885\n",
      "[143]\tvalidation_0-auc:0.64185\n",
      "[144]\tvalidation_0-auc:0.641862\n",
      "[145]\tvalidation_0-auc:0.641872\n",
      "[146]\tvalidation_0-auc:0.641863\n",
      "[147]\tvalidation_0-auc:0.642016\n",
      "[148]\tvalidation_0-auc:0.642191\n",
      "[149]\tvalidation_0-auc:0.642175\n",
      "[150]\tvalidation_0-auc:0.642181\n",
      "[151]\tvalidation_0-auc:0.642153\n",
      "[152]\tvalidation_0-auc:0.642203\n",
      "[153]\tvalidation_0-auc:0.642189\n",
      "[154]\tvalidation_0-auc:0.64215\n",
      "[155]\tvalidation_0-auc:0.642129\n",
      "[156]\tvalidation_0-auc:0.642079\n",
      "[157]\tvalidation_0-auc:0.64208\n",
      "[158]\tvalidation_0-auc:0.642134\n",
      "[159]\tvalidation_0-auc:0.642161\n",
      "[160]\tvalidation_0-auc:0.642205\n",
      "[161]\tvalidation_0-auc:0.642164\n",
      "[162]\tvalidation_0-auc:0.642124\n",
      "[163]\tvalidation_0-auc:0.642169\n",
      "[164]\tvalidation_0-auc:0.642169\n",
      "[165]\tvalidation_0-auc:0.642187\n",
      "[166]\tvalidation_0-auc:0.642206\n",
      "[167]\tvalidation_0-auc:0.642212\n",
      "[168]\tvalidation_0-auc:0.642186\n",
      "[169]\tvalidation_0-auc:0.642246\n",
      "[170]\tvalidation_0-auc:0.642323\n",
      "[171]\tvalidation_0-auc:0.64231\n",
      "[172]\tvalidation_0-auc:0.642312\n",
      "[173]\tvalidation_0-auc:0.642343\n",
      "[174]\tvalidation_0-auc:0.642309\n",
      "[175]\tvalidation_0-auc:0.642373\n",
      "[176]\tvalidation_0-auc:0.642373\n",
      "[177]\tvalidation_0-auc:0.642347\n",
      "[178]\tvalidation_0-auc:0.64238\n",
      "[179]\tvalidation_0-auc:0.642332\n",
      "[180]\tvalidation_0-auc:0.642375\n",
      "[181]\tvalidation_0-auc:0.642375\n",
      "[182]\tvalidation_0-auc:0.642382\n",
      "[183]\tvalidation_0-auc:0.642368\n",
      "[184]\tvalidation_0-auc:0.642363\n",
      "[185]\tvalidation_0-auc:0.642357\n",
      "[186]\tvalidation_0-auc:0.642491\n",
      "[187]\tvalidation_0-auc:0.64246\n",
      "[188]\tvalidation_0-auc:0.64246\n",
      "[189]\tvalidation_0-auc:0.642452\n",
      "[190]\tvalidation_0-auc:0.642451\n",
      "[191]\tvalidation_0-auc:0.642437\n",
      "[192]\tvalidation_0-auc:0.642441\n",
      "[193]\tvalidation_0-auc:0.642468\n",
      "[194]\tvalidation_0-auc:0.642421\n",
      "[195]\tvalidation_0-auc:0.642421\n",
      "[196]\tvalidation_0-auc:0.642464\n",
      "[197]\tvalidation_0-auc:0.642464\n",
      "[198]\tvalidation_0-auc:0.642464\n",
      "[199]\tvalidation_0-auc:0.642543\n",
      "[200]\tvalidation_0-auc:0.642523\n",
      "[201]\tvalidation_0-auc:0.642523\n",
      "[202]\tvalidation_0-auc:0.642542\n",
      "[203]\tvalidation_0-auc:0.642542\n",
      "[204]\tvalidation_0-auc:0.642528\n",
      "[205]\tvalidation_0-auc:0.642522\n",
      "[206]\tvalidation_0-auc:0.64257\n",
      "[207]\tvalidation_0-auc:0.64256\n",
      "[208]\tvalidation_0-auc:0.642541\n",
      "[209]\tvalidation_0-auc:0.642614\n",
      "[210]\tvalidation_0-auc:0.642614\n",
      "[211]\tvalidation_0-auc:0.642605\n",
      "[212]\tvalidation_0-auc:0.642657\n",
      "[213]\tvalidation_0-auc:0.642657\n",
      "[214]\tvalidation_0-auc:0.642646\n",
      "[215]\tvalidation_0-auc:0.642636\n",
      "[216]\tvalidation_0-auc:0.642636\n",
      "[217]\tvalidation_0-auc:0.642636\n",
      "[218]\tvalidation_0-auc:0.642627\n",
      "[219]\tvalidation_0-auc:0.642631\n",
      "[220]\tvalidation_0-auc:0.642659\n",
      "[221]\tvalidation_0-auc:0.642673\n",
      "[222]\tvalidation_0-auc:0.64266\n",
      "[223]\tvalidation_0-auc:0.64266\n",
      "[224]\tvalidation_0-auc:0.642657\n",
      "[225]\tvalidation_0-auc:0.642657\n",
      "[226]\tvalidation_0-auc:0.642653\n",
      "[227]\tvalidation_0-auc:0.642669\n",
      "[228]\tvalidation_0-auc:0.642655\n",
      "[229]\tvalidation_0-auc:0.642655\n",
      "[230]\tvalidation_0-auc:0.642697\n",
      "[231]\tvalidation_0-auc:0.642697\n",
      "[232]\tvalidation_0-auc:0.642697\n",
      "[233]\tvalidation_0-auc:0.642765\n",
      "[234]\tvalidation_0-auc:0.6428\n",
      "[235]\tvalidation_0-auc:0.642799\n",
      "[236]\tvalidation_0-auc:0.64281\n",
      "[237]\tvalidation_0-auc:0.64281\n",
      "[238]\tvalidation_0-auc:0.642834\n",
      "[239]\tvalidation_0-auc:0.642826\n",
      "[240]\tvalidation_0-auc:0.642808\n",
      "[241]\tvalidation_0-auc:0.64281\n",
      "[242]\tvalidation_0-auc:0.64281\n",
      "[243]\tvalidation_0-auc:0.642829\n",
      "[244]\tvalidation_0-auc:0.642875\n",
      "[245]\tvalidation_0-auc:0.642875\n",
      "[246]\tvalidation_0-auc:0.642875\n",
      "[247]\tvalidation_0-auc:0.642875\n",
      "[248]\tvalidation_0-auc:0.6429\n",
      "[249]\tvalidation_0-auc:0.642865\n",
      "[250]\tvalidation_0-auc:0.642852\n",
      "[251]\tvalidation_0-auc:0.642849\n",
      "[252]\tvalidation_0-auc:0.642853\n",
      "[253]\tvalidation_0-auc:0.642853\n",
      "[254]\tvalidation_0-auc:0.642853\n",
      "[255]\tvalidation_0-auc:0.642855\n",
      "[256]\tvalidation_0-auc:0.642848\n",
      "[257]\tvalidation_0-auc:0.642848\n",
      "[258]\tvalidation_0-auc:0.642923\n",
      "[259]\tvalidation_0-auc:0.642933\n",
      "[260]\tvalidation_0-auc:0.642933\n",
      "[261]\tvalidation_0-auc:0.642958\n",
      "[262]\tvalidation_0-auc:0.642958\n",
      "[263]\tvalidation_0-auc:0.64296\n",
      "[264]\tvalidation_0-auc:0.64296\n",
      "[265]\tvalidation_0-auc:0.642965\n",
      "[266]\tvalidation_0-auc:0.642958\n",
      "[267]\tvalidation_0-auc:0.642958\n",
      "[268]\tvalidation_0-auc:0.642958\n",
      "[269]\tvalidation_0-auc:0.642958\n",
      "[270]\tvalidation_0-auc:0.642958\n",
      "[271]\tvalidation_0-auc:0.642946\n",
      "[272]\tvalidation_0-auc:0.642997\n",
      "[273]\tvalidation_0-auc:0.643032\n",
      "[274]\tvalidation_0-auc:0.643037\n",
      "[275]\tvalidation_0-auc:0.643078\n",
      "[276]\tvalidation_0-auc:0.643124\n",
      "[277]\tvalidation_0-auc:0.643167\n",
      "[278]\tvalidation_0-auc:0.643139\n",
      "[279]\tvalidation_0-auc:0.643139\n",
      "[280]\tvalidation_0-auc:0.643139\n",
      "[281]\tvalidation_0-auc:0.643137\n",
      "[282]\tvalidation_0-auc:0.643137\n",
      "[283]\tvalidation_0-auc:0.643137\n",
      "[284]\tvalidation_0-auc:0.643157\n",
      "[285]\tvalidation_0-auc:0.643139\n",
      "[286]\tvalidation_0-auc:0.643234\n",
      "[287]\tvalidation_0-auc:0.64329\n",
      "[288]\tvalidation_0-auc:0.64329\n",
      "[289]\tvalidation_0-auc:0.643287\n",
      "[290]\tvalidation_0-auc:0.643287\n",
      "[291]\tvalidation_0-auc:0.643343\n",
      "[292]\tvalidation_0-auc:0.643343\n",
      "[293]\tvalidation_0-auc:0.643343\n",
      "[294]\tvalidation_0-auc:0.643343\n",
      "[295]\tvalidation_0-auc:0.643372\n",
      "[296]\tvalidation_0-auc:0.643372\n",
      "[297]\tvalidation_0-auc:0.643407\n",
      "[298]\tvalidation_0-auc:0.643407\n",
      "[299]\tvalidation_0-auc:0.643407\n",
      "[300]\tvalidation_0-auc:0.643393\n",
      "[301]\tvalidation_0-auc:0.643369\n",
      "[302]\tvalidation_0-auc:0.643375\n",
      "[303]\tvalidation_0-auc:0.643355\n",
      "[304]\tvalidation_0-auc:0.643355\n",
      "[305]\tvalidation_0-auc:0.643355\n",
      "[306]\tvalidation_0-auc:0.643352\n",
      "[307]\tvalidation_0-auc:0.643524\n",
      "[308]\tvalidation_0-auc:0.643524\n",
      "[309]\tvalidation_0-auc:0.643466\n",
      "[310]\tvalidation_0-auc:0.643461\n",
      "[311]\tvalidation_0-auc:0.643433\n",
      "[312]\tvalidation_0-auc:0.643391\n",
      "[313]\tvalidation_0-auc:0.64344\n",
      "[314]\tvalidation_0-auc:0.643404\n",
      "[315]\tvalidation_0-auc:0.643424\n",
      "[316]\tvalidation_0-auc:0.643424\n",
      "[317]\tvalidation_0-auc:0.643412\n",
      "[318]\tvalidation_0-auc:0.64341\n",
      "[319]\tvalidation_0-auc:0.643389\n",
      "[320]\tvalidation_0-auc:0.643413\n",
      "[321]\tvalidation_0-auc:0.643411\n",
      "[322]\tvalidation_0-auc:0.643435\n",
      "[323]\tvalidation_0-auc:0.643409\n",
      "[324]\tvalidation_0-auc:0.643391\n",
      "[325]\tvalidation_0-auc:0.643392\n",
      "[326]\tvalidation_0-auc:0.643392\n",
      "[327]\tvalidation_0-auc:0.643442\n",
      "[328]\tvalidation_0-auc:0.643442\n",
      "[329]\tvalidation_0-auc:0.64343\n",
      "[330]\tvalidation_0-auc:0.643456\n",
      "[331]\tvalidation_0-auc:0.643492\n",
      "[332]\tvalidation_0-auc:0.643475\n",
      "[333]\tvalidation_0-auc:0.643553\n",
      "[334]\tvalidation_0-auc:0.643553\n",
      "[335]\tvalidation_0-auc:0.643585\n",
      "[336]\tvalidation_0-auc:0.643585\n",
      "[337]\tvalidation_0-auc:0.643585\n",
      "[338]\tvalidation_0-auc:0.643585\n",
      "[339]\tvalidation_0-auc:0.643585\n",
      "[340]\tvalidation_0-auc:0.643585\n",
      "[341]\tvalidation_0-auc:0.643596\n",
      "[342]\tvalidation_0-auc:0.643648\n",
      "[343]\tvalidation_0-auc:0.643648\n",
      "[344]\tvalidation_0-auc:0.643648\n",
      "[345]\tvalidation_0-auc:0.64364\n",
      "[346]\tvalidation_0-auc:0.643635\n",
      "[347]\tvalidation_0-auc:0.643641\n",
      "[348]\tvalidation_0-auc:0.643635\n",
      "[349]\tvalidation_0-auc:0.643641\n",
      "[350]\tvalidation_0-auc:0.6436\n",
      "[351]\tvalidation_0-auc:0.643577\n",
      "[352]\tvalidation_0-auc:0.643684\n",
      "[353]\tvalidation_0-auc:0.64374\n",
      "[354]\tvalidation_0-auc:0.643743\n",
      "[355]\tvalidation_0-auc:0.643706\n",
      "[356]\tvalidation_0-auc:0.643685\n",
      "[357]\tvalidation_0-auc:0.643685\n",
      "[358]\tvalidation_0-auc:0.643676\n",
      "[359]\tvalidation_0-auc:0.643676\n",
      "[360]\tvalidation_0-auc:0.643676\n",
      "[361]\tvalidation_0-auc:0.643649\n",
      "[362]\tvalidation_0-auc:0.643602\n",
      "[363]\tvalidation_0-auc:0.643593\n",
      "[364]\tvalidation_0-auc:0.643593\n",
      "[365]\tvalidation_0-auc:0.643593\n",
      "[366]\tvalidation_0-auc:0.643604\n",
      "[367]\tvalidation_0-auc:0.643604\n",
      "[368]\tvalidation_0-auc:0.6436\n",
      "[369]\tvalidation_0-auc:0.643573\n",
      "[370]\tvalidation_0-auc:0.643573\n",
      "[371]\tvalidation_0-auc:0.643555\n",
      "[372]\tvalidation_0-auc:0.643555\n",
      "[373]\tvalidation_0-auc:0.643583\n",
      "[374]\tvalidation_0-auc:0.643583\n",
      "[375]\tvalidation_0-auc:0.643579\n",
      "[376]\tvalidation_0-auc:0.643617\n",
      "[377]\tvalidation_0-auc:0.643629\n",
      "[378]\tvalidation_0-auc:0.643641\n",
      "[379]\tvalidation_0-auc:0.643628\n",
      "[380]\tvalidation_0-auc:0.64364\n",
      "[381]\tvalidation_0-auc:0.643658\n",
      "[382]\tvalidation_0-auc:0.643646\n",
      "[383]\tvalidation_0-auc:0.643646\n",
      "[384]\tvalidation_0-auc:0.643647\n",
      "[385]\tvalidation_0-auc:0.643647\n",
      "[386]\tvalidation_0-auc:0.643643\n",
      "[387]\tvalidation_0-auc:0.643643\n",
      "[388]\tvalidation_0-auc:0.643643\n",
      "[389]\tvalidation_0-auc:0.643615\n",
      "[390]\tvalidation_0-auc:0.643586\n",
      "[391]\tvalidation_0-auc:0.643586\n",
      "[392]\tvalidation_0-auc:0.643581\n",
      "[393]\tvalidation_0-auc:0.643581\n",
      "[394]\tvalidation_0-auc:0.643575\n",
      "[395]\tvalidation_0-auc:0.643605\n",
      "[396]\tvalidation_0-auc:0.643584\n",
      "[397]\tvalidation_0-auc:0.643584\n",
      "[398]\tvalidation_0-auc:0.643584\n",
      "[399]\tvalidation_0-auc:0.643584\n",
      "[400]\tvalidation_0-auc:0.643584\n",
      "[401]\tvalidation_0-auc:0.643584\n",
      "[402]\tvalidation_0-auc:0.643588\n",
      "[403]\tvalidation_0-auc:0.643582\n",
      "[404]\tvalidation_0-auc:0.643582\n",
      "Stopping. Best iteration:\n",
      "[354]\tvalidation_0-auc:0.643743\n",
      "\n",
      "Gini score=  0.287163328068\n"
     ]
    }
   ],
   "source": [
    "xgb_params= {'learning_rate': 0.07,\n",
    "             'n_estimators':1000, #525, #,354\n",
    "             'max_depth': 4, \n",
    "             'nthread':8,\n",
    "             'subsample': 0.8,\n",
    "             'min_child_weight':0.77,\n",
    "             'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', \n",
    "             'eval_metric': 'auc', \n",
    "             'seed': 99, \n",
    "             'silent': True,\n",
    "             'scale_pos_weight': 1.6,\n",
    "             'reg_alpha':8,\n",
    "             'reg_lambda':1.3,\n",
    "             'gamma':10\n",
    "            }\n",
    "xgbm1= xgboost.sklearn.XGBClassifier(**xgb_params)\n",
    "xgbm1.fit(X_train,y_train,eval_metric='auc',early_stopping_rounds=50,eval_set=[(X_test,y_test)])\n",
    "y_pred= xgbm1.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep= np.where(xgbm1.feature_importances_ > 0.)[0]\n",
    "# keep2= np.where(xgbm1.feature_importances_ > 0.)[0]\n",
    "keeps= keep[keep2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(open('xgboost_rfe_keepers.bin','wb'),keeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.288190290095"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.288190290095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05974843,  0.0932914 ,  0.00052411,  0.05398323,  0.04874214,\n",
       "        0.04192872,  0.0927673 ,  0.01415094,  0.01572327,  0.11268344,\n",
       "        0.04507338,  0.02568134,  0.02935011,  0.03249476,  0.00314465,\n",
       "        0.01572327,  0.00681342,  0.00052411,  0.00052411,  0.00524109,\n",
       "        0.00628931,  0.00733753,  0.00262054,  0.03563941,  0.00104822,\n",
       "        0.01100629,  0.00471698,  0.00157233,  0.01048218,  0.00366876,\n",
       "        0.00209644,  0.01100629,  0.00052411,  0.00890985,  0.00524109,\n",
       "        0.00681342,  0.0115304 ,  0.00157233,  0.00157233,  0.00262054,\n",
       "        0.00209644,  0.00471698,  0.00209644,  0.00995807,  0.01415094,\n",
       "        0.00314465,  0.        ,  0.00733753,  0.01572327,  0.00262054,\n",
       "        0.00209644,  0.00104822,  0.        ,  0.01257862,  0.01519916,\n",
       "        0.00943396,  0.01310273,  0.0115304 ,  0.03459119,  0.00419287], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbm1.feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
