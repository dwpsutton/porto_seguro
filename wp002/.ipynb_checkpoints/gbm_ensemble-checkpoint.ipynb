{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    " \n",
    "def test_gini():\n",
    "    def fequ(a,b):\n",
    "        return abs( a -b) < 1e-6\n",
    "    def T(a, p, g, n):\n",
    "        assert( fequ(gini(a,p), g) )\n",
    "        assert( fequ(gini_normalized(a,p), n) )\n",
    "    T([1, 2, 3], [10, 20, 30], 0.111111, 1)\n",
    "    T([1, 2, 3], [30, 20, 10], -0.111111, -1)\n",
    "    T([1, 2, 3], [0, 0, 0], -0.111111, -1)\n",
    "    T([3, 2, 1], [0, 0, 0], 0.111111, 1)\n",
    "    T([1, 2, 4, 3], [0, 0, 0, 0], -0.1, -0.8)\n",
    "    T([2, 1, 4, 3], [0, 0, 2, 1], 0.125, 1)\n",
    "    T([0, 20, 40, 0, 10], [40, 40, 10, 5, 5], 0, 0)\n",
    "    T([40, 0, 20, 0, 10], [1000000, 40, 40, 5, 5], 0.171428,\n",
    "       0.6)\n",
    "    T([40, 20, 10, 0, 0], [40, 20, 10, 0, 0], 0.285714, 1)\n",
    "    T([1, 1, 0, 1], [0.86, 0.26, 0.52, 0.32], -0.041666,\n",
    "       -0.333333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train= np.load(open('../wp004/train_matrix.bin','rb'))\n",
    "#y_train= np.load(open('../wp004/train_labels.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test= np.load(open('../wp004/test_matrix.bin','rb'))\n",
    "#y_test= np.load(open('../wp004/test_labels.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in wp007 feature set and split into train and test\n",
    "import sklearn.cross_validation\n",
    "df= pd.read_csv('../data/train.csv',usecols= ['id','target'])\n",
    "train,test= sklearn.cross_validation.train_test_split(range(df['target'].count()),test_size= 0.33,random_state=0)\n",
    "y_train= df.target.values[train]\n",
    "y_test= df.target.values[test]\n",
    "df2= pd.read_csv('../wp007/full_248_train.csv')\n",
    "X_train= df2.as_matrix()[train,:]\n",
    "X_test= df2.as_matrix()[test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df= pd.DataFrame(X_train,columns= ['x'+str(i) for i in range(np.shape(X_train)[1])])\n",
    "# df.loc[:,'y']= y_train\n",
    "# df.to_csv('train.csv',index=False,columns=['y']+['x'+str(i) for i in range(np.shape(X_train)[1])])\n",
    "# \n",
    "# df= pd.DataFrame(X_test,columns= ['x'+str(i) for i in range(np.shape(X_train)[1])])\n",
    "# df.loc[:,'y']= np.zeros(np.shape(X_test)[0])\n",
    "# df.to_csv('test.csv',index=False,columns=['y']+['x'+str(i) for i in range(np.shape(X_train)[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run vanilla random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sklearn.linear_model\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tc= datetime.now()\n",
    "# lr= sklearn.linear_model.LogisticRegression(penalty='l2',\n",
    "#                                             C=1.,\n",
    "#                                             class_weight='balanced'\n",
    "#                                             )\n",
    "# lr.fit(X_train,y_train)\n",
    "# print 'Training took: ',(datetime.now() - tc).total_seconds(),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sample_weights = np.load(open('sample_weights.bin','rb'))\n",
    "\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "#                y_holdout = y[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "#                 if i == len(self.base_models)-1:\n",
    "#                     print 'fitting grey area model'\n",
    "#                     clf.fit(X_train, y_train, sample_weight= sample_weights[train_idx])\n",
    "#                 else:\n",
    "                clf.fit(X_train, y_train)\n",
    "#                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "#                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (2.*results.mean()-1.))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  153.139017  seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tc= datetime.now()\n",
    "import lightgbm.sklearn\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['n_estimators'] = 1300\n",
    "#lgb_params['max_depth'] = 10\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['num_leaves']= 25\n",
    "# lgb_params['random_state']= 0\n",
    "gbm1 = lightgbm.sklearn.LGBMClassifier(**lgb_params)\n",
    "\n",
    "lgb_params_2 = {\n",
    "    'learning_rate': 0.005,\n",
    "    'n_estimators': 3700,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 2,\n",
    "    'colsample_bytree': 0.3,  \n",
    "    'num_leaves': 16\n",
    "}\n",
    "\n",
    "lgb_params_3 = {\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 800,\n",
    "    'max_depth': 4\n",
    "}\n",
    "\n",
    "lgb_params_4 = {\n",
    "    'learning_rate':0.05,\n",
    "    'n_estimators':600,\n",
    "    'num_leaves':35,\n",
    "    'min_child_samples':500\n",
    "}\n",
    "\n",
    "# lgb_params_5 = {\n",
    "#     'learning_rate':0.01,\n",
    "#     'n_estimators':1300,\n",
    "#     'num_leaves':25,\n",
    "#     'subsample': 0.8,\n",
    "#     'subsample_freq': 10,\n",
    "#     'colsample_bytree': 0.8 ,  \n",
    "#     'min_child_samples': 500,\n",
    "#     'num_leaves': 25\n",
    "# }\n",
    "\n",
    "gbm2 = lightgbm.sklearn.LGBMClassifier(**lgb_params_2)\n",
    "gbm3 = lightgbm.sklearn.LGBMClassifier(**lgb_params_3)\n",
    "gbm4 = lightgbm.sklearn.LGBMClassifier(**lgb_params_4)\n",
    "# gbm5 = lightgbm.sklearn.LGBMClassifier(**lgb_params_5)\n",
    "\n",
    "gbm1.fit(X_train,y_train)\n",
    "y_pred= gbm1.predict_proba(X_test)[:,1]\n",
    "\n",
    "import sklearn.neural_network\n",
    "mlp_params= {\n",
    "    'hidden_layer_sizes':(100,100), \n",
    "    'activation':'relu', \n",
    "    'solver':'adam', \n",
    "    'alpha':0.00000001, \n",
    "    'batch_size':'auto', \n",
    "    'learning_rate_init':0.001, \n",
    "    'shuffle':True, \n",
    "    'tol':0.0001, \n",
    "    'early_stopping': True,\n",
    "    'validation_fraction':0.1, \n",
    "    'beta_1':0.9, \n",
    "    'beta_2':0.999, \n",
    "    'epsilon':1e-08\n",
    "}\n",
    "mlp= sklearn.neural_network.MLPClassifier(**mlp_params)\n",
    "#mlp.fit(X_train,y_train)\n",
    "#y_pred= mlp.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "import sklearn.linear_model\n",
    "lr_base_params= {\n",
    "    'C':100.0,\n",
    "     'penalty':'l2',\n",
    "    'class_weight':'balanced'\n",
    "}\n",
    "# lr_base= sklearn.linear_model.LogisticRegression(**lr_base_params)\n",
    "#lr_base.fit(X_train,y_train)\n",
    "#y_pred= lr_base.predict_proba(X_test)[:,1]\n",
    "\n",
    "lr_stacker= sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "# lgbm_stacker= lightgbm.sklearn.LGBMClassifier(**{'learning_rate':0.01,\n",
    "#                                                  'n_estimators':500,\n",
    "#                                                  'num_leaves':6,\n",
    "#                                                  'min_child_samples':500})\n",
    "\n",
    "#import sklearn.ensemble\n",
    "#rf_stacker= sklearn.ensemble.RandomForestClassifier(n_estimators=300,\n",
    "#                                                   max_depth=7,\n",
    "#                                                   min_samples_leaf= 300)\n",
    "\n",
    "# knnparams={\n",
    "#     'n_neighbors':5, \n",
    "#     'weights':'uniform', \n",
    "#     'algorithm':'kd_tree'\n",
    "# }\n",
    "# import sklearn.neighbors\n",
    "# knn= sklearn.neighbors.KNeighborsClassifier(**knnparams)\n",
    "# knn.fit(X_train,y_train)\n",
    "# y_pred= knn.predict_proba(X_test)\n",
    "\n",
    "# tc= datetime.now()\n",
    "# stack = Ensemble(n_splits=3,\n",
    "# stacker = lr_stacker,\n",
    "#         base_models = (gbm1, gbm2, gbm3, gbm4))#, mlp, lr_base))        \n",
    "# y_pred = stack.fit_predict(X_train, y_train, X_test) \n",
    "\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds(),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob= y_pred #gbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=  0.639781503074\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "print 'AUC= ',sklearn.metrics.roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28036380223742596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27265345351512127"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_normalized(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(stack,open('simple_stacker.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
