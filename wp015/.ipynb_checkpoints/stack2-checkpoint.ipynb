{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simpler modelling stack, where models have been pulled from the stack if they are not useful.  Strangely, the regularization on the top level of the stack must be light l1.  Produces 0.28966 in local test. Just over 0.285 on LB.  Position: 387 (386 was bottom of bronze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd,matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(array):\n",
    "    srtInd = array.argsort()\n",
    "    ranks = np.empty(len(array), float)\n",
    "    ranks[srtInd] = np.arange(len(array))\n",
    "    return ranks / float(len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, n_splits, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.pipelines= []\n",
    "        self.base_models= []\n",
    "        for x in base_models:\n",
    "            self.pipelines.append( x[0] )\n",
    "            self.base_models.append( x[1] )\n",
    "\n",
    "    def fit_predict(self, df_train, y, df_test):\n",
    "        y = np.array(y)\n",
    "\n",
    "        folds = StratifiedKFold(y,n_folds=self.n_splits, shuffle=True, random_state=2016)\n",
    "\n",
    "        S_train = np.zeros((len(df_train.index), len(self.base_models)))\n",
    "        S_test = np.zeros((len(df_test.index), len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            #\n",
    "            PIPELINE= self.pipelines[i]\n",
    "            #\n",
    "            S_test_i = np.zeros((len(df_test.index), self.n_splits))\n",
    "#             X_train, y_train, X_test, y_test= PIPELINE(df_train.copy(),df_test.copy())\n",
    "            #\n",
    "            for j, (train_idx, val_idx) in enumerate(folds):\n",
    "                #\n",
    "                X_train, y_train, X_holdout, y_holdout= PIPELINE(\n",
    "                    df_train.copy().loc[train_idx,:],\n",
    "                    df_train.copy().loc[val_idx,:]\n",
    "                )\n",
    "                _, _, X_test, y_test= PIPELINE(df_train.copy().loc[train_idx,:],df_test.copy()\n",
    "                )\n",
    "                #\n",
    "                print (\"Fit %s --> %s fold %d\" % (str(PIPELINE).split()[1],str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]              \n",
    "\n",
    "                S_train[val_idx, i] = y_pred\n",
    "                #\n",
    "                test_probs= clf.predict_proba(X_test)[:,1]\n",
    "                S_test_i[:, j] = np.log(test_probs) - np.log(1.0 - test_probs)\n",
    "            agg_lor= S_test_i.mean(axis=1)\n",
    "            S_test[:, i] = 1.0 / (1.0 + np.exp( -agg_lor) )\n",
    "        return pd.DataFrame(S_train,columns=['x_'+str(i) for i in range(np.shape(S_train)[1])]),pd.DataFrame(S_test,columns=['x_'+str(i) for i in range(np.shape(S_test)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add output of layer results ofr quick iteration\n",
    "class Stack:\n",
    "    def __init__(self,k_folds,hidden_layers,top_layer,saveInternalVectors=False):\n",
    "        self.saveInternalVectors= saveInternalVectors\n",
    "        self.layers= []\n",
    "        for h in hidden_layers:\n",
    "            self.layers.append( Layer(k_folds,h) )\n",
    "        self.top_layer= top_layer \n",
    "        return None\n",
    "    \n",
    "    def fit_predict(self,df_train,y,df_test,external_base_scores= None):\n",
    "        Xt_train= df_train\n",
    "        Xt_test= df_test\n",
    "        i= 1\n",
    "        for layer in self.layers:\n",
    "            print 'Fitting stack layer '+str(i)\n",
    "            Xt_train, Xt_test= layer.fit_predict(Xt_train,y,Xt_test)\n",
    "            Xt_train.loc[:,'target']= y\n",
    "            if external_base_scores is not None and i==1:\n",
    "                Xt_train= np.concatenate( (Xt_train,np.reshape(external_base_scores[0],\n",
    "                                                               (np.shape(external_base_scores[0])[0],1))),\n",
    "                                         axis=1)\n",
    "                Xt_test= np.concatenate( (Xt_test,np.reshape(external_base_scores[1],\n",
    "                                                            (np.shape(external_base_scores[1])[0],1))), \n",
    "                                        axis=1)\n",
    "            #\n",
    "            if self.saveInternalVectors:\n",
    "                fname= 'STACK_internal_train_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_train)\n",
    "                fname= 'STACK_internal_test_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_test)\n",
    "            i+=1\n",
    "        Xt_train.drop('target',axis=1,inplace=True)\n",
    "        self.top_layer.fit(Xt_train.as_matrix(),y)\n",
    "        return self.top_layer.predict_proba(Xt_test.as_matrix())[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now score the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Read data\n",
    "\n",
    "# # train\n",
    "# X_train= np.load(open('../WP014/dummy_train_matrix.bin','rb'))\n",
    "# y_train= np.load(open('../WP014/dummy_train_labels.bin','rb'))\n",
    "\n",
    "# # test\n",
    "# X_test= np.load(open('../WP014/dummy_test_matrix.bin','rb'))\n",
    "# y_test= np.load(open('../WP014/dummy_test_labels.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection, pipe1,pipe2,pipe3\n",
    "\n",
    "df_train= pd.read_csv('../data/train.csv')\n",
    "df_test= pd.read_csv('../data/test.csv')\n",
    "\n",
    "# index_train, index_test= sklearn.model_selection.train_test_split( range(len(df_train.index)) , \n",
    "#                                                                     test_size=0.3,random_state=1)\n",
    "\n",
    "# df_test= df_train.loc[index_test,:].reset_index(drop=True)\n",
    "# y_test= df_test.target.values\n",
    "# df_train= df_train.loc[index_train,:].reset_index(drop=True)\n",
    "# y_train= df_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ids= pd.read_csv('../data/test.csv',usecols=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm.sklearn\n",
    "import xgboost.sklearn\n",
    "import catboost\n",
    "import sklearn.linear_model, sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['n_estimators'] = 1300\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['num_leaves']= 25\n",
    "lgb_params['n_jobs']=8\n",
    "\n",
    "\n",
    "# lgb_params_3 = {\n",
    "#     'learning_rate': 0.02,\n",
    "#     'n_estimators': 800,\n",
    "#     'max_depth': 4,\n",
    "#     'n_jobs':8\n",
    "# }\n",
    "lgb_params_3 = {\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 800, #150,\n",
    "    'max_depth': 4,\n",
    "    'n_jobs':8\n",
    "#     'min_child_samples':100\n",
    "}\n",
    "\n",
    "lgb_params_4 = {\n",
    "    'learning_rate':0.05,\n",
    "    'n_estimators':600,\n",
    "    'num_leaves':35,\n",
    "    'min_child_samples':500,\n",
    "    'n_jobs':8\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params= {'learning_rate': 0.07,\n",
    "             'n_estimators':525,\n",
    "             'max_depth': 4, \n",
    "             'nthread':8,\n",
    "             'subsample': 0.8,\n",
    "             'min_child_weight':6.0, #kernel now changed this to 0.77\n",
    "             'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', \n",
    "             'eval_metric': 'auc', \n",
    "             'seed': 99, \n",
    "             'silent': True,\n",
    "             'scale_pos_weight': 1.6,\n",
    "             'reg_alpha':8,\n",
    "             'reg_lambda':1.3,\n",
    "             'gamma':10\n",
    "            }\n",
    "\n",
    "cb_params= {\n",
    "    'learning_rate':0.05, \n",
    "    'depth':6, \n",
    "    'l2_leaf_reg': 14, \n",
    "    'iterations': 650,\n",
    "    'verbose': False,\n",
    "    'loss_function':'Logloss'\n",
    "    }\n",
    "\n",
    "# lgbmn_params= {'num_leaves': 81, 'verbose': 1, 'learning_rate': 0.005, \n",
    "#                'min_data': 650, 'categorical_column': [], 'bagging_fraction': 0.9, \n",
    "#                'metric': ['auc'], 'boosting_type': 'gbdt', 'lambda_l1': 30,\n",
    "#                'bagging_freq': 3, 'lambda_l2': 0, 'is_unbalance': True, \n",
    "#                'max_bin': 255, 'objective': ['binary'], 'max_depth': 6, \n",
    "#                'feature_fraction': 0.7,'n_estimators':1600\n",
    "#               }\n",
    "\n",
    "# Layer 1\n",
    "lgbm1 = (pipe1.run_pipe1,  lightgbm.sklearn.LGBMClassifier(**lgb_params))\n",
    "xgbm1= (pipe1.run_pipe1,   xgboost.sklearn.XGBClassifier(**xgb_params))\n",
    "lgbm3 = (pipe1.run_pipe1,  lightgbm.sklearn.LGBMClassifier(**lgb_params_3))\n",
    "lgbm4 = (pipe1.run_pipe1,  lightgbm.sklearn.LGBMClassifier(**lgb_params_4))\n",
    "cb= (pipe1.run_pipe1,      catboost.CatBoostClassifier(**cb_params))\n",
    "# lgbmn = (pipe3.run_pipe3,  lightgbm.sklearn.LGBMClassifier(**lgbmn_params))\n",
    "\n",
    "# Top layer\n",
    "stacker= sklearn.linear_model.LogisticRegression(C=500.0,class_weight='balanced',penalty='l1')\n",
    "\n",
    "# Define the stack\n",
    "stack = Stack(10,[ [cb,xgbm1,lgbm1,lgbm3,lgbm4] ], stacker) #, saveInternalVectors=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting stack layer 1\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 1\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 2\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 3\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 4\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 5\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 6\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 7\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 8\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 9\n",
      "Fit run_pipe1 --> <catboost.core.CatBoostClassifier object at 0x1151a2790> fold 10\n",
      "Fit run_pipe1 --> XGBClassifier fold 1\n",
      "Fit run_pipe1 --> XGBClassifier fold 2\n",
      "Fit run_pipe1 --> XGBClassifier fold 3\n",
      "Fit run_pipe1 --> XGBClassifier fold 4\n",
      "Fit run_pipe1 --> XGBClassifier fold 5\n",
      "Fit run_pipe1 --> XGBClassifier fold 6\n",
      "Fit run_pipe1 --> XGBClassifier fold 7\n",
      "Fit run_pipe1 --> XGBClassifier fold 8\n",
      "Fit run_pipe1 --> XGBClassifier fold 9\n",
      "Fit run_pipe1 --> XGBClassifier fold 10\n",
      "Fit run_pipe1 --> LGBMClassifier fold 1\n",
      "Fit run_pipe1 --> LGBMClassifier fold 2\n",
      "Fit run_pipe1 --> LGBMClassifier fold 3\n",
      "Fit run_pipe1 --> LGBMClassifier fold 4\n",
      "Fit run_pipe1 --> LGBMClassifier fold 5\n",
      "Fit run_pipe1 --> LGBMClassifier fold 6\n",
      "Fit run_pipe1 --> LGBMClassifier fold 7\n",
      "Fit run_pipe1 --> LGBMClassifier fold 8\n",
      "Fit run_pipe1 --> LGBMClassifier fold 9\n",
      "Fit run_pipe1 --> LGBMClassifier fold 10\n",
      "Fit run_pipe1 --> LGBMClassifier fold 1\n",
      "Fit run_pipe1 --> LGBMClassifier fold 2\n",
      "Fit run_pipe1 --> LGBMClassifier fold 3\n",
      "Fit run_pipe1 --> LGBMClassifier fold 4\n",
      "Fit run_pipe1 --> LGBMClassifier fold 5\n",
      "Fit run_pipe1 --> LGBMClassifier fold 6\n",
      "Fit run_pipe1 --> LGBMClassifier fold 7\n",
      "Fit run_pipe1 --> LGBMClassifier fold 8\n",
      "Fit run_pipe1 --> LGBMClassifier fold 9\n",
      "Fit run_pipe1 --> LGBMClassifier fold 10\n",
      "Fit run_pipe1 --> LGBMClassifier fold 1\n",
      "Fit run_pipe1 --> LGBMClassifier fold 2\n",
      "Fit run_pipe1 --> LGBMClassifier fold 3\n",
      "Fit run_pipe1 --> LGBMClassifier fold 4\n",
      "Fit run_pipe1 --> LGBMClassifier fold 5\n",
      "Fit run_pipe1 --> LGBMClassifier fold 6\n",
      "Fit run_pipe1 --> LGBMClassifier fold 7\n",
      "Fit run_pipe1 --> LGBMClassifier fold 8\n",
      "Fit run_pipe1 --> LGBMClassifier fold 9\n",
      "Fit run_pipe1 --> LGBMClassifier fold 10\n",
      " Training took 7707.743039\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict\n",
    "from datetime import datetime\n",
    "tc= datetime.now()\n",
    "y_pred = stack.fit_predict(df_train, df_train.target.values, df_test) #,\n",
    "print' Training took '+str( (datetime.now() - tc).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1.,0.290094358949"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added ps_car_11 prevalence encoding, ps_calc_14, and restored separate encodings of folds in stacking CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.289139167662, 0.289187617155)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.289139167662, 0.289187617155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best local score=  0.290737925496 0.289662696292\n",
      "Baseline 0.288711072302 0.290006985327\n"
     ]
    }
   ],
   "source": [
    "print 'Best local score= ',0.290737925496,0.289662696292\n",
    "print 'Baseline',0.288711072302,0.290006985327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df= pd.DataFrame( {'id': test_ids.id.values, 'target': y_pred},\n",
    "                     columns=['id','target']\n",
    "                    ).to_csv('submission_wp015d.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "stacker= sklearn.linear_model.LogisticRegression(C=500.,class_weight='balanced',penalty='l2')\n",
    "X_train= np.load('STACK_internal_train_layer_1.bin')[:,[1,2,3,4,5]]\n",
    "X_test= np.load('STACK_internal_test_layer_1.bin')[:,[1,2,3,4,5]]\n",
    "\n",
    "# for i in range(np.shape(X_train)[1]):\n",
    "#     X_train[:,i]= rank(X_train[:,i])\n",
    "# for i in range(np.shape(X_test)[1]):\n",
    "#     X_test[:,i]= rank(X_test[:,i])\n",
    "# Xcross_train= np.zeros([np.shape(X_train)[0], np.shape(X_train)[1]**2 - np.shape(X_train)[1]])\n",
    "# for iv in range(np.shape(X_train)[0]):\n",
    "#     for i in range(np.shape(X_train)[1]-1):\n",
    "#         for j in range(i+1,np.shape(X_train)[1]):\n",
    "#             Xcross_train[iv,i*j]= X_train[iv,i] * X_train[iv,j]\n",
    "# Xcross_test= np.zeros([np.shape(X_test)[0], np.shape(X_test)[1]**2 - np.shape(X_test)[1]])\n",
    "# for iv in range(np.shape(X_test)[0]):\n",
    "#     for i in range(np.shape(X_test)[1]-1):\n",
    "#         for j in range(i+1,np.shape(X_test)[1]):\n",
    "#             Xcross_test[iv,i*j]= X_test[iv,i] * X_test[iv,j]\n",
    "# for i in range(np.shape(Xcross_test)[1]):\n",
    "#     Xcross_test[:,i]= rank(Xcross_test[:,i])\n",
    "# for i in range(np.shape(Xcross_train)[1]):\n",
    "#     Xcross_train[:,i]= rank(Xcross_train[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini score=  0.290443587595\n"
     ]
    }
   ],
   "source": [
    "stacker= sklearn.linear_model.LogisticRegression(C=500.,class_weight='balanced',penalty='l1')\n",
    "stacker.fit(X_train,y_train)\n",
    "y_pred= stacker.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29044380853"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.29044380853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.628198\n",
      "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.628893\n",
      "[2]\tvalidation_0-auc:0.636688\n",
      "[3]\tvalidation_0-auc:0.636717\n",
      "[4]\tvalidation_0-auc:0.63682\n",
      "[5]\tvalidation_0-auc:0.637537\n",
      "[6]\tvalidation_0-auc:0.639109\n",
      "[7]\tvalidation_0-auc:0.641839\n",
      "[8]\tvalidation_0-auc:0.642356\n",
      "[9]\tvalidation_0-auc:0.643074\n",
      "[10]\tvalidation_0-auc:0.64321\n",
      "[11]\tvalidation_0-auc:0.643156\n",
      "[12]\tvalidation_0-auc:0.64316\n",
      "[13]\tvalidation_0-auc:0.643393\n",
      "[14]\tvalidation_0-auc:0.643363\n",
      "[15]\tvalidation_0-auc:0.643354\n",
      "[16]\tvalidation_0-auc:0.643406\n",
      "[17]\tvalidation_0-auc:0.643378\n",
      "[18]\tvalidation_0-auc:0.643479\n",
      "[19]\tvalidation_0-auc:0.64346\n",
      "[20]\tvalidation_0-auc:0.643446\n",
      "[21]\tvalidation_0-auc:0.643894\n",
      "[22]\tvalidation_0-auc:0.643898\n",
      "[23]\tvalidation_0-auc:0.643877\n",
      "[24]\tvalidation_0-auc:0.643965\n",
      "[25]\tvalidation_0-auc:0.643996\n",
      "[26]\tvalidation_0-auc:0.644043\n",
      "[27]\tvalidation_0-auc:0.643943\n",
      "[28]\tvalidation_0-auc:0.643999\n",
      "[29]\tvalidation_0-auc:0.644016\n",
      "[30]\tvalidation_0-auc:0.644007\n",
      "[31]\tvalidation_0-auc:0.644143\n",
      "[32]\tvalidation_0-auc:0.644194\n",
      "[33]\tvalidation_0-auc:0.644153\n",
      "[34]\tvalidation_0-auc:0.644113\n",
      "[35]\tvalidation_0-auc:0.643972\n",
      "[36]\tvalidation_0-auc:0.643941\n",
      "[37]\tvalidation_0-auc:0.644017\n",
      "[38]\tvalidation_0-auc:0.644024\n",
      "[39]\tvalidation_0-auc:0.644013\n",
      "[40]\tvalidation_0-auc:0.644056\n",
      "[41]\tvalidation_0-auc:0.644096\n",
      "[42]\tvalidation_0-auc:0.644186\n",
      "[43]\tvalidation_0-auc:0.644164\n",
      "[44]\tvalidation_0-auc:0.644171\n",
      "[45]\tvalidation_0-auc:0.644163\n",
      "[46]\tvalidation_0-auc:0.644147\n",
      "[47]\tvalidation_0-auc:0.644126\n",
      "[48]\tvalidation_0-auc:0.644102\n",
      "[49]\tvalidation_0-auc:0.644124\n",
      "[50]\tvalidation_0-auc:0.644134\n",
      "[51]\tvalidation_0-auc:0.644145\n",
      "[52]\tvalidation_0-auc:0.644175\n",
      "[53]\tvalidation_0-auc:0.644142\n",
      "[54]\tvalidation_0-auc:0.644183\n",
      "[55]\tvalidation_0-auc:0.644217\n",
      "[56]\tvalidation_0-auc:0.644222\n",
      "[57]\tvalidation_0-auc:0.644242\n",
      "[58]\tvalidation_0-auc:0.644265\n",
      "[59]\tvalidation_0-auc:0.644277\n",
      "[60]\tvalidation_0-auc:0.644294\n",
      "[61]\tvalidation_0-auc:0.6443\n",
      "[62]\tvalidation_0-auc:0.644315\n",
      "[63]\tvalidation_0-auc:0.644338\n",
      "[64]\tvalidation_0-auc:0.644335\n",
      "[65]\tvalidation_0-auc:0.644346\n",
      "[66]\tvalidation_0-auc:0.64435\n",
      "[67]\tvalidation_0-auc:0.644316\n",
      "[68]\tvalidation_0-auc:0.644328\n",
      "[69]\tvalidation_0-auc:0.644291\n",
      "[70]\tvalidation_0-auc:0.644261\n",
      "[71]\tvalidation_0-auc:0.644254\n",
      "[72]\tvalidation_0-auc:0.644233\n",
      "[73]\tvalidation_0-auc:0.644219\n",
      "[74]\tvalidation_0-auc:0.644204\n",
      "[75]\tvalidation_0-auc:0.644221\n",
      "[76]\tvalidation_0-auc:0.644228\n",
      "[77]\tvalidation_0-auc:0.644228\n",
      "[78]\tvalidation_0-auc:0.644194\n",
      "[79]\tvalidation_0-auc:0.644194\n",
      "[80]\tvalidation_0-auc:0.644205\n",
      "[81]\tvalidation_0-auc:0.644214\n",
      "[82]\tvalidation_0-auc:0.644202\n",
      "[83]\tvalidation_0-auc:0.644169\n",
      "[84]\tvalidation_0-auc:0.644162\n",
      "[85]\tvalidation_0-auc:0.644155\n",
      "[86]\tvalidation_0-auc:0.644088\n",
      "[87]\tvalidation_0-auc:0.644077\n",
      "[88]\tvalidation_0-auc:0.644066\n",
      "[89]\tvalidation_0-auc:0.644037\n",
      "[90]\tvalidation_0-auc:0.644031\n",
      "[91]\tvalidation_0-auc:0.643989\n",
      "[92]\tvalidation_0-auc:0.644013\n",
      "[93]\tvalidation_0-auc:0.644013\n",
      "[94]\tvalidation_0-auc:0.644013\n",
      "[95]\tvalidation_0-auc:0.644013\n",
      "[96]\tvalidation_0-auc:0.644013\n",
      "[97]\tvalidation_0-auc:0.644015\n",
      "[98]\tvalidation_0-auc:0.644015\n",
      "[99]\tvalidation_0-auc:0.644015\n",
      "[100]\tvalidation_0-auc:0.644015\n",
      "[101]\tvalidation_0-auc:0.644015\n",
      "[102]\tvalidation_0-auc:0.644021\n",
      "[103]\tvalidation_0-auc:0.644021\n",
      "[104]\tvalidation_0-auc:0.644021\n",
      "[105]\tvalidation_0-auc:0.644023\n",
      "[106]\tvalidation_0-auc:0.644023\n",
      "[107]\tvalidation_0-auc:0.644027\n",
      "[108]\tvalidation_0-auc:0.64403\n",
      "[109]\tvalidation_0-auc:0.644018\n",
      "[110]\tvalidation_0-auc:0.644018\n",
      "[111]\tvalidation_0-auc:0.644024\n",
      "[112]\tvalidation_0-auc:0.644027\n",
      "[113]\tvalidation_0-auc:0.644027\n",
      "[114]\tvalidation_0-auc:0.644045\n",
      "[115]\tvalidation_0-auc:0.644045\n",
      "[116]\tvalidation_0-auc:0.644043\n",
      "Stopping. Best iteration:\n",
      "[66]\tvalidation_0-auc:0.64435\n",
      "\n",
      "Gini score=  0.288085348525\n"
     ]
    }
   ],
   "source": [
    "xgb_params= {'learning_rate': 0.07,\n",
    "             'n_estimators':1000, #525, #,354\n",
    "             'max_depth': 4, \n",
    "             'nthread':8,\n",
    "             'subsample': 0.8,\n",
    "             'min_child_weight':0.77,\n",
    "             'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', \n",
    "             'eval_metric': 'auc', \n",
    "             'seed': 99, \n",
    "             'silent': True,\n",
    "             'scale_pos_weight': 1.6,\n",
    "             'reg_alpha':8,\n",
    "             'reg_lambda':1.3,\n",
    "             'gamma':10\n",
    "            }\n",
    "xgbm1= xgboost.sklearn.XGBClassifier(**xgb_params)\n",
    "xgbm1.fit(X_train,y_train,eval_metric='auc',early_stopping_rounds=50,eval_set=[(X_test,y_test)])\n",
    "y_pred= xgbm1.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d0ae371093ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# keep= np.where(xgbm1.feature_importances_ > 0.)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# keep2= np.where(xgbm1.feature_importances_ > 0.)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkeeps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keep' is not defined"
     ]
    }
   ],
   "source": [
    "# keep= np.where(xgbm1.feature_importances_ > 0.)[0]\n",
    "# keep2= np.where(xgbm1.feature_importances_ > 0.)[0]\n",
    "keeps= keep[keep2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(open('xgboost_rfe_keepers.bin','wb'),keeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 650\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.05\n",
    "cb_params= {\n",
    "    'learning_rate':0.05, \n",
    "    'depth':6, \n",
    "    'l2_leaf_reg': 14, \n",
    "    'iterations':650,\n",
    "    'verbose': True,\n",
    "    'loss_function':'Logloss'\n",
    "    }\n",
    "\n",
    "cb= catboost.CatBoostClassifier(**cb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "y_pred= cb.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection, pipe3\n",
    "\n",
    "df_train= pd.read_csv('../data/train.csv')\n",
    "df_test= pd.read_csv('../data/test.csv')\n",
    "\n",
    "index_train, index_test= sklearn.model_selection.train_test_split( range(len(df_train.index)) , \n",
    "                                                                    test_size=0.3,random_state=1)\n",
    "\n",
    "df_test= df_train.loc[index_test,:].reset_index(drop=True)\n",
    "y_test= df_test.target.values\n",
    "df_train= df_train.loc[index_train,:].reset_index(drop=True)\n",
    "y_train= df_train.target.values\n",
    "\n",
    "X_train,y_train,X_test,y_test= pipe3.run_pipe3(df_train.copy(),df_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "lgb_params_3 = {\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 4,\n",
    "    'n_jobs':8,\n",
    "#     'early_stopping_round':50,\n",
    "    'min_child_samples':100\n",
    "}\n",
    "\n",
    "lgbmn = lightgbm.sklearn.LGBMClassifier(**lgb_params_3)\n",
    "bagger= sklearn.ensemble.BaggingClassifier(lgbmn,n_estimators=10,max_samples=0.3,random_state=1234)\n",
    "bagger.fit(X_train,y_train)\n",
    "# lgbmn.fit(X_train,y_train,eval_metric='auc',eval_set=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "y_pred= bagger.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.289135174661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= pd.read_csv('submission_wp015d.csv')\n",
    "b= pd.read_csv('gpx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c= 0.5*a.target.values + 0.5*b.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d= pd.DataFrame({'id':a.id.values, 'target':c},columns=['id','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.to_csv('submission_wp015d_blend_gpx_0.5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
