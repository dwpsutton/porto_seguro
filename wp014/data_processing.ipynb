{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odf= pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "index_train, index_test= sklearn.model_selection.train_test_split( odf.index, \n",
    "                                                                    test_size=0.3,random_state=1)\n",
    "df= odf.loc[index_train,:]\n",
    "test_df= odf.loc[index_test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_df= pd.read_csv(open('../data/test.csv','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yoyoma= pd.merge(\n",
    "#     pd.merge( pd.DataFrame(df.groupby('ps_reg_03').target.agg(lambda x: float(len(x)) )) ,\n",
    "#          pd.DataFrame(df.groupby('ps_reg_03').target.agg(lambda x: float(sum(x)) )),\n",
    "#          left_index=True,right_index=True),\n",
    "#     pd.DataFrame(test_df.groupby('ps_reg_03').ps_reg_03.agg(lambda x: float(len(x)) )),\n",
    "#     left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yoyoma.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# upscore= yoyoma[ (yoyoma.index > 2.0) & (yoyoma.target_y == 0) & (yoyoma.ps_reg_03 < 10) ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_ids= pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.save(open('upscore_ids.bin','wb'),\n",
    "#         test_ids[ map(lambda x: x in upscore,test_ids.ps_reg_03.values)].loc[:,'id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group columns by type\n",
    "colnames= map(lambda x: str(x),df.columns.values)\n",
    "id_col= colnames[0]\n",
    "target_col= colnames[1]\n",
    "cat_cols= filter(lambda x: '_cat' in x,colnames)\n",
    "bin_cols= filter(lambda x: '_bin' in x,colnames)\n",
    "num_cols= filter(lambda x: ('_cat' not in x) and ('_bin' not in x) and x not in [id_col,target_col] ,\n",
    "                colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recon(reg):\n",
    "    integer = int(np.round((40*reg)**2)) \n",
    "    for a in range(27):\n",
    "        if (integer - a) % 27 == 0:\n",
    "            A = a\n",
    "#     M = (integer - A)//31\n",
    "    return A\n",
    "\n",
    "# df.loc[:,'ps_reg_04_cat'] = df.ps_reg_03.apply(recon)\n",
    "# cat_cols.append('ps_reg_04_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.corrcoef(df.ps_reg_02.values,df.ps_reg_03.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.loc[:,'c13']= pd.qcut(df.ps_car_13.values,6)\n",
    "# df.groupby('c13').target.agg(lambda x: sum(x) / float(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.loc[:,'in3_car13']= map(lambda x: str(x[0]) + '_' + str(x[1]),zip(df['ps_ind_03'].values,df['c13'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.groupby('in3_car13').target.agg(lambda x: float(sum(x)) / len(x)).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cut bad fields, based on kernel discussions\n",
    "bin_cols.remove('ps_ind_12_bin')\n",
    "df.drop('ps_ind_12_bin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tmp  = df['ps_calc_15_bin'] * 32 + df['ps_calc_16_bin'] * 16 + df['ps_calc_17_bin'] * 8\n",
    "# tmp += df['ps_calc_18_bin'] * 4 + df['ps_calc_19_bin'] * 2 + df['ps_calc_20_bin'] * 1\n",
    "# df.loc[:,'test_cat']= tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove uninformative of noisy shadow features\n",
    "shadows= ['ps_car_11_cat',       \n",
    "            'ps_calc_14',        \n",
    "            'ps_calc_11',         \n",
    "            'ps_calc_06',           \n",
    "            'ps_calc_16_bin',       \n",
    "            'ps_calc_19_bin',       \n",
    "            'ps_calc_20_bin',     \n",
    "            'ps_calc_15_bin',      \n",
    "            'ps_ind_11_bin',       \n",
    "            'ps_ind_10_bin']\n",
    "for s in shadows:\n",
    "    if s in bin_cols:\n",
    "        bin_cols.remove(s)\n",
    "    elif s in num_cols:\n",
    "        num_cols.remove(s)\n",
    "    elif s in cat_cols:\n",
    "        cat_cols.remove(s)\n",
    "    df.drop(s,axis=1,inplace=True)\n",
    "    \n",
    "for c in df.columns:\n",
    "    if 'calc' in c:\n",
    "        df.drop(c,axis=1,inplace=True)\n",
    "        if c in bin_cols:\n",
    "            bin_cols.remove(c)\n",
    "        elif c in num_cols:\n",
    "            num_cols.remove(c)\n",
    "        elif c in cat_cols:\n",
    "            cat_cols.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Split train and test\n",
    "# import sklearn.cross_validation\n",
    "# #train= range(len(df[target_col].values))\n",
    "# train,test= sklearn.cross_validation.train_test_split(range(df[target_col].count()),test_size= 0.33,random_state=0)\n",
    "\n",
    "train_df= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TO try:\n",
    "# - with and without ps_reg_03 and its combo\n",
    "# - add extra combos\n",
    "# - convert -1s to NaNs\n",
    "\n",
    "# Add some extra features\n",
    "train_df = train_df.replace(-1, np.NaN)\n",
    "d_median = train_df.median(axis=0)\n",
    "d_mean = train_df.mean(axis=0)\n",
    "train_df = train_df.fillna(-1)\n",
    "\n",
    "def transform_df(indf):\n",
    "    indf = pd.DataFrame(indf)\n",
    "    dcol = [c for c in indf.columns if c not in ['id','target']]\n",
    "    indf['ps_car_13_x_ps_reg_03'] = indf['ps_car_13'] * indf['ps_reg_03']    \n",
    "#     indf['ps_reg_01_x_ps_car_02_cat'] = str(indf['ps_reg_01']) + str(indf['ps_car_02_cat'])\n",
    "#     indf['ps_reg_01_x_ps_car_04_cat'] = str(indf['ps_reg_01']) + str(indf['ps_car_04_cat'])\n",
    "    indf['negative_one_vals'] = np.sum((indf[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            indf[c+str('_median_range')] = (indf[c].values > d_median[c]).astype(np.int)\n",
    "            indf[c+str('_mean_range')] = (indf[c].values > d_mean[c]).astype(np.int)\n",
    "    return indf\n",
    "\n",
    "train_df= transform_df(train_df)\n",
    "\n",
    "# cat_cols.append('ps_reg_01_x_ps_car_02_cat')\n",
    "# cat_cols.append('ps_reg_01_x_ps_car_04_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: implement a class prevalence vectorizer for categoricals, to be used in processing some columns \n",
    "# and in understanding field importance\n",
    "\n",
    "pr_prev= df.target.mean()\n",
    "prior_obs= 20.\n",
    "alpha= pr_prev*prior_obs\n",
    "beta= prior_obs - alpha\n",
    "\n",
    "class prevalence_vectorizer:\n",
    "    def __init__(self,field_list,target_col):\n",
    "        self.field_list= field_list\n",
    "        self.target_col= target_col\n",
    "        self.vectorizer= {}\n",
    "        for f in field_list:\n",
    "            self.vectorizer[f]= {}\n",
    "        return None\n",
    "    \n",
    "    def beta_prior_ratio(self,x):\n",
    "        return float(np.sum(x[self.target_col]) + alpha) / len(x[self.target_col] + beta)     \n",
    "    \n",
    "    def train(self,df):\n",
    "        data_fields= map(lambda x: str(x),df.columns)\n",
    "        for f in self.field_list:\n",
    "            if f in data_fields:\n",
    "                self.vectorizer[f]= {}\n",
    "                grps= df.groupby(f).apply(self.beta_prior_ratio)\n",
    "                for g in grps.index.values:\n",
    "                    self.vectorizer[f][g]= grps[g]\n",
    "            else:\n",
    "                print 'Warning: field '+f+' not in train data'\n",
    "        return None\n",
    "    \n",
    "    def parse(self,vec,field_name):\n",
    "        if field_name in self.field_list:\n",
    "            return map(lambda x: self.vectorizer[field_name][x] if x in self.vectorizer[field_name] else pr_prev,vec)\n",
    "        else:\n",
    "            print field_name + ' not in vectorizer. Available fields: '+ self.field_list\n",
    "            raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing plan: \n",
    "- cut rows with missing ps_car_11 and ps_car_12\n",
    "- Normalize all numerics, except: [ps_car_14 and ps_reg_03]\n",
    "- For [ps_car_14 and ps_reg_03], bin and convert to class prevalence (future work: fit for the missing values?)\n",
    "- Treat categoricals: dict vectorize, except for: \n",
    "     [ps_car_11_cat, ps_car_06_cat, ps_car_04_cat, ps_car_01_cat, ps_car_09_cat, ps_ind_05_cat], which we turn into class prevalence rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: better treatment of: [ps_car_14 and ps_reg_03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toPrevalate= ['ps_car_06_cat','ps_car_01_cat']#,'ps_reg_04_cat']#,'ps_reg_01_x_ps_car_02_cat','ps_reg_01_x_ps_car_04_cat']\n",
    "toOneHot= filter(lambda x: x not in toPrevalate,cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot encoder\n",
    "import sklearn.preprocessing\n",
    "enc= sklearn.preprocessing.OneHotEncoder(sparse= False)\n",
    "X_train_onehot= enc.fit_transform( train_df.loc[:,toOneHot].as_matrix()+1.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prevalence vectorizer\n",
    "vectorizer= prevalence_vectorizer(toPrevalate,target_col)\n",
    "vectorizer.train(train_df.loc[:,toPrevalate + [target_col] ])\n",
    "\n",
    "X_train_prevalence= np.zeros([train_df.target.count(),len(toPrevalate)])\n",
    "i=0\n",
    "for c in toPrevalate:\n",
    "    X_train_prevalence[:,i]= vectorizer.parse( train_df.loc[:,c].values, c ) \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get means and stds for the columns in training set (for non-missing values)\n",
    "numerical_norms= {}\n",
    "for c in num_cols:\n",
    "    numerical_norms[c]= (train_df.loc[ train_df[c] >= 0, c].mean(),train_df.loc[ train_df[c] >= 0, c].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalise numerical fields <- TODO: better treatment of [ps_car_14 and ps_reg_03]\n",
    "X_train_numeric= np.zeros([train_df.target.count(),len(num_cols)])\n",
    "i=0\n",
    "for c in num_cols:\n",
    "    X_train_numeric[:,i]= ( train_df[c].values - numerical_norms[c][0] ) / numerical_norms[c][1]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train= np.concatenate([ X_train_numeric, \n",
    "                          X_train_prevalence, \n",
    "                          X_train_onehot, \n",
    "                          train_df.loc[:,bin_cols].as_matrix() \n",
    "                        ],\n",
    "                        axis=1)\n",
    "\n",
    "X_train[X_train == -1]= np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(open('dummy_train_matrix.bin','wb'),X_train)\n",
    "np.save(open('dummy_train_labels.bin','wb'),train_df[target_col].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat encodings for actual test set (without fitting them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_df= pd.read_csv(open('../data/test.csv','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_df.loc[:,'ps_reg_04_cat'] = test_df.ps_reg_03.apply(recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp  = test_df['ps_calc_15_bin'] * 32 + test_df['ps_calc_16_bin'] * 16 + test_df['ps_calc_17_bin'] * 8\n",
    "# tmp += test_df['ps_calc_18_bin'] * 4 + test_df['ps_calc_19_bin'] * 2 + test_df['ps_calc_20_bin'] * 1\n",
    "# test_df.loc[:,'test_cat']= tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove uninformative of noisy shadow features\n",
    "shadows= ['ps_car_11_cat',       \n",
    "            'ps_calc_14',        \n",
    "            'ps_calc_11',         \n",
    "            'ps_calc_06',           \n",
    "            'ps_calc_16_bin',       \n",
    "            'ps_calc_19_bin',       \n",
    "            'ps_calc_20_bin',     \n",
    "            'ps_calc_15_bin',      \n",
    "            'ps_ind_11_bin',       \n",
    "            'ps_ind_10_bin']\n",
    "for s in shadows:\n",
    "    if s in bin_cols:\n",
    "        bin_cols.remove(s)\n",
    "    elif s in num_cols:\n",
    "        num_cols.remove(s)\n",
    "    elif s in cat_cols:\n",
    "        cat_cols.remove(s)\n",
    "    test_df.drop(s,axis=1,inplace=True)\n",
    "    \n",
    "for c in test_df.columns:\n",
    "    if 'calc' in c:\n",
    "        test_df.drop(c,axis=1,inplace=True)\n",
    "        if c in bin_cols:\n",
    "            bin_cols.remove(c)\n",
    "        elif c in num_cols:\n",
    "            num_cols.remove(c)\n",
    "        elif c in cat_cols:\n",
    "            cat_cols.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df= transform_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_onehot= enc.transform( test_df.loc[:,toOneHot].as_matrix()+1.0 )\n",
    "X_test_prevalence= np.zeros([test_df.id.count(),len(toPrevalate)])\n",
    "i=0\n",
    "for c in toPrevalate:\n",
    "    X_test_prevalence[:,i]= vectorizer.parse( test_df.loc[:,c].values, c ) \n",
    "    i += 1\n",
    "X_test_numeric= np.zeros([test_df.id.count(),len(num_cols)])\n",
    "i=0\n",
    "for c in num_cols:\n",
    "    X_test_numeric[:,i]= ( test_df[c].values - numerical_norms[c][0] ) / numerical_norms[c][1]\n",
    "    i+=1\n",
    "X_test= np.concatenate([ X_test_numeric, \n",
    "                          X_test_prevalence, \n",
    "                          X_test_onehot, \n",
    "                          test_df.loc[:,bin_cols].as_matrix() \n",
    "                        ],\n",
    "                        axis=1)\n",
    "X_test[X_test == -1]= np.NaN\n",
    "np.save(open('dummy_test_matrix.bin','wb'),X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(open('dummy_test_labels.bin','wb'),test_df[target_col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
