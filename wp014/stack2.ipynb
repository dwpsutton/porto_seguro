{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simpler modelling stack, where models have been pulled from the stack if they are not useful.  Strangely, the regularization on the top level of the stack must be light l1.  Produces 0.28966 in local test. Just over 0.285 on LB.  Position: 387 (386 was bottom of bronze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd,matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(array):\n",
    "    srtInd = array.argsort()\n",
    "    ranks = np.empty(len(array), float)\n",
    "    ranks[srtInd] = np.arange(len(array))\n",
    "    return ranks / float(len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, n_splits, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]              \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                #\n",
    "                test_probs= clf.predict_proba(T)[:,1]\n",
    "                S_test_i[:, j] = np.log(test_probs) - np.log(1.0 - test_probs)\n",
    "            agg_lor= S_test_i.mean(axis=1)\n",
    "            S_test[:, i] = 1.0 / (1.0 + np.exp( -agg_lor) )\n",
    "        return S_train,S_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add output of layer results ofr quick iteration\n",
    "class Stack:\n",
    "    def __init__(self,k_folds,hidden_layers,top_layer,saveInternalVectors=False):\n",
    "        self.saveInternalVectors= saveInternalVectors\n",
    "        self.layers= []\n",
    "        for h in hidden_layers:\n",
    "            self.layers.append( Layer(k_folds,h) )\n",
    "        self.top_layer= top_layer \n",
    "        return None\n",
    "    \n",
    "    def fit_predict(self,X,y,T,external_base_scores= None):\n",
    "        Xt_train= copy.deepcopy(X)\n",
    "        Xt_test= copy.deepcopy(T)\n",
    "        i= 1\n",
    "        for layer in self.layers:\n",
    "            print 'Fitting stack layer '+str(i)\n",
    "            Xt_train, Xt_test= layer.fit_predict(Xt_train,y,Xt_test)\n",
    "            if external_base_scores is not None and i==1:\n",
    "                Xt_train= np.concatenate( (Xt_train,np.reshape(external_base_scores[0],\n",
    "                                                               (np.shape(external_base_scores[0])[0],1))),\n",
    "                                         axis=1)\n",
    "                Xt_test= np.concatenate( (Xt_test,np.reshape(external_base_scores[1],\n",
    "                                                            (np.shape(external_base_scores[1])[0],1))), \n",
    "                                        axis=1)\n",
    "            #\n",
    "            # Add entropy score from layer\n",
    "#             train_entropy= np.array(map(lambda i: np.sum(Xt_train[i] * np.log(Xt_train[i])), \n",
    "#                                         range(np.shape(Xt_train)[0] )))\n",
    "#             Xt_train= np.concatenate( (Xt_train,np.reshape(train_entropy,(len(train_entropy),1))) ,axis=1)\n",
    "#             test_entropy= np.array(map(lambda i: np.sum(Xt_test[i] * np.log(Xt_test[i])), \n",
    "#                                         range(np.shape(Xt_test)[0] )))\n",
    "#             Xt_test= np.concatenate( (Xt_test,np.reshape(test_entropy,(len(test_entropy),1))) ,axis=1)\n",
    "            #\n",
    "#             # Rank transform\n",
    "#             for jj in range(np.shape(Xt_train)[1]):\n",
    "#                 Xt_train[:,jj]= rank(Xt_train[:,jj])\n",
    "#                 Xt_test[:,jj]= rank(Xt_test[:,jj])\n",
    "#             #\n",
    "            if self.saveInternalVectors:\n",
    "                fname= 'STACK_internal_train_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_train)\n",
    "                fname= 'STACK_internal_test_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_test)\n",
    "            i+=1\n",
    "#         for i in range(np.shape(Xt_train)[1]): #-1 so we don't apply to entropy!!\n",
    "#             p= copy.deepcopy(Xt_train[:,i])\n",
    "#             Xt_train[:,i]= np.log( p ) - np.log(1.0 - p)\n",
    "        self.top_layer.fit(Xt_train,y)\n",
    "        return self.top_layer.predict_proba(Xt_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now score the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "# train\n",
    "X_train= np.load(open('full_train_matrix.bin','rb'))\n",
    "y_train= np.load(open('full_train_labels.bin','rb'))\n",
    "\n",
    "# test\n",
    "X_test= np.load(open('blind_test_matrix.bin','rb'))\n",
    "# y_test= np.load(open('blind_test_labels.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keeps= np.load(open('xgboost_rfe_keepers.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sklearn.linear_model\n",
    "# lr= sklearn.linear_model.LogisticRegression(C=10000.0,class_weight={0:1.,1.:10/0.034},penalty='l1')\n",
    "# lr.fit(X_train,y_train)\n",
    "# y_pred= lr.predict_proba(X_test)[:,1]\n",
    "# print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ids= pd.read_csv('../data/test.csv',usecols=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm.sklearn\n",
    "import xgboost.sklearn\n",
    "import catboost\n",
    "import sklearn.linear_model\n",
    "import sklearn.neural_network\n",
    "\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['n_estimators'] = 1300\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['num_leaves']= 25\n",
    "lgb_params['n_jobs']=8\n",
    "\n",
    "\n",
    "lgb_params_3 = {\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 800,\n",
    "    'max_depth': 4,\n",
    "    'n_jobs':8\n",
    "}\n",
    "\n",
    "lgb_params_4 = {\n",
    "    'learning_rate':0.05,\n",
    "    'n_estimators':600,\n",
    "    'num_leaves':35,\n",
    "    'min_child_samples':500,\n",
    "    'n_jobs':8\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params= {'learning_rate': 0.07,\n",
    "             'n_estimators':525,\n",
    "             'max_depth': 4, \n",
    "             'nthread':8,\n",
    "             'subsample': 0.8,\n",
    "             'min_child_weight':0.77,\n",
    "             'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', \n",
    "             'eval_metric': 'auc', \n",
    "             'seed': 99, \n",
    "             'silent': True,\n",
    "             'scale_pos_weight': 1.6,\n",
    "             'reg_alpha':8,\n",
    "             'reg_lambda':1.3,\n",
    "             'gamma':10\n",
    "            }\n",
    "\n",
    "cb_params= {\n",
    "    'learning_rate':0.05, \n",
    "    'depth':6, \n",
    "    'l2_leaf_reg': 14, \n",
    "    'iterations': 650,\n",
    "    'verbose': False,\n",
    "    'loss_function':'Logloss'\n",
    "    }\n",
    "\n",
    "# Layer 1\n",
    "lgbm1 = lightgbm.sklearn.LGBMClassifier(**lgb_params)\n",
    "xgbm1= xgboost.sklearn.XGBClassifier(**xgb_params)\n",
    "lgbm3 = lightgbm.sklearn.LGBMClassifier(**lgb_params_3)\n",
    "lgbm4 = lightgbm.sklearn.LGBMClassifier(**lgb_params_4)\n",
    "cb= catboost.CatBoostClassifier(**cb_params)\n",
    "\n",
    "# Top layer\n",
    "stacker= sklearn.linear_model.LogisticRegression(C=500.0,class_weight='balanced',penalty='l1')\n",
    "\n",
    "# Define the stack\n",
    "stack = Stack(10,[ [cb,xgbm1,lgbm1,lgbm3,lgbm4] ], stacker, saveInternalVectors=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting stack layer 1\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 1\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 2\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 3\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 4\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 5\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 6\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 7\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 8\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 9\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x14509bb90> fold 10\n",
      "Fit XGBClassifier fold 1\n",
      "Fit XGBClassifier fold 2\n",
      "Fit XGBClassifier fold 3\n",
      "Fit XGBClassifier fold 4\n",
      "Fit XGBClassifier fold 5\n",
      "Fit XGBClassifier fold 6\n",
      "Fit XGBClassifier fold 7\n",
      "Fit XGBClassifier fold 8\n",
      "Fit XGBClassifier fold 9\n",
      "Fit XGBClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      " Training took 5715.619093\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict\n",
    "from datetime import datetime\n",
    "tc= datetime.now()\n",
    "y_pred = stack.fit_predict(X_train, y_train, X_test) #,\n",
    "print' Training took '+str( (datetime.now() - tc).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best local score=  0.290737925496 0.289662696292\n",
      "Baseline 0.288711072302\n"
     ]
    }
   ],
   "source": [
    "print 'Best local score= ',0.290737925496,0.289662696292\n",
    "print 'Baseline',0.288711072302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df= pd.DataFrame( {'id': test_ids.id.values, 'target': y_pred},\n",
    "                     columns=['id','target']\n",
    "                    ).to_csv('submission_wp014b.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini score=  0.290126214944\n"
     ]
    }
   ],
   "source": [
    "stacker= sklearn.linear_model.LogisticRegression(C=500.,class_weight='balanced',penalty='l1')\n",
    "X_train= np.load('STACK_internal_train_layer_1.bin')[:,[0,2,3,4]]\n",
    "X_test= np.load('STACK_internal_test_layer_1.bin')[:,[0,2,3,4]]\n",
    "stacker.fit(X_train,y_train)\n",
    "y_pred= stacker.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.289780485339"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.289780485339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.587442\n",
      "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.604111\n",
      "[2]\tvalidation_0-auc:0.604609\n",
      "[3]\tvalidation_0-auc:0.609857\n",
      "[4]\tvalidation_0-auc:0.610012\n",
      "[5]\tvalidation_0-auc:0.613922\n",
      "[6]\tvalidation_0-auc:0.614897\n",
      "[7]\tvalidation_0-auc:0.615186\n",
      "[8]\tvalidation_0-auc:0.615893\n",
      "[9]\tvalidation_0-auc:0.615365\n",
      "[10]\tvalidation_0-auc:0.615606\n",
      "[11]\tvalidation_0-auc:0.616957\n",
      "[12]\tvalidation_0-auc:0.616898\n",
      "[13]\tvalidation_0-auc:0.61743\n",
      "[14]\tvalidation_0-auc:0.617757\n",
      "[15]\tvalidation_0-auc:0.618349\n",
      "[16]\tvalidation_0-auc:0.618636\n",
      "[17]\tvalidation_0-auc:0.619403\n",
      "[18]\tvalidation_0-auc:0.619486\n",
      "[19]\tvalidation_0-auc:0.619779\n",
      "[20]\tvalidation_0-auc:0.62052\n",
      "[21]\tvalidation_0-auc:0.621023\n",
      "[22]\tvalidation_0-auc:0.621524\n",
      "[23]\tvalidation_0-auc:0.62188\n",
      "[24]\tvalidation_0-auc:0.621653\n",
      "[25]\tvalidation_0-auc:0.621614\n",
      "[26]\tvalidation_0-auc:0.622377\n",
      "[27]\tvalidation_0-auc:0.622772\n",
      "[28]\tvalidation_0-auc:0.622941\n",
      "[29]\tvalidation_0-auc:0.623317\n",
      "[30]\tvalidation_0-auc:0.623473\n",
      "[31]\tvalidation_0-auc:0.62449\n",
      "[32]\tvalidation_0-auc:0.624793\n",
      "[33]\tvalidation_0-auc:0.624923\n",
      "[34]\tvalidation_0-auc:0.62488\n",
      "[35]\tvalidation_0-auc:0.626279\n",
      "[36]\tvalidation_0-auc:0.626619\n",
      "[37]\tvalidation_0-auc:0.626945\n",
      "[38]\tvalidation_0-auc:0.627313\n",
      "[39]\tvalidation_0-auc:0.627837\n",
      "[40]\tvalidation_0-auc:0.628155\n",
      "[41]\tvalidation_0-auc:0.628517\n",
      "[42]\tvalidation_0-auc:0.628616\n",
      "[43]\tvalidation_0-auc:0.629415\n",
      "[44]\tvalidation_0-auc:0.629958\n",
      "[45]\tvalidation_0-auc:0.629971\n",
      "[46]\tvalidation_0-auc:0.630711\n",
      "[47]\tvalidation_0-auc:0.63086\n",
      "[48]\tvalidation_0-auc:0.631253\n",
      "[49]\tvalidation_0-auc:0.631647\n",
      "[50]\tvalidation_0-auc:0.632153\n",
      "[51]\tvalidation_0-auc:0.632379\n",
      "[52]\tvalidation_0-auc:0.632536\n",
      "[53]\tvalidation_0-auc:0.632836\n",
      "[54]\tvalidation_0-auc:0.63293\n",
      "[55]\tvalidation_0-auc:0.632771\n",
      "[56]\tvalidation_0-auc:0.633295\n",
      "[57]\tvalidation_0-auc:0.633657\n",
      "[58]\tvalidation_0-auc:0.633835\n",
      "[59]\tvalidation_0-auc:0.633853\n",
      "[60]\tvalidation_0-auc:0.633976\n",
      "[61]\tvalidation_0-auc:0.634227\n",
      "[62]\tvalidation_0-auc:0.634441\n",
      "[63]\tvalidation_0-auc:0.634613\n",
      "[64]\tvalidation_0-auc:0.634893\n",
      "[65]\tvalidation_0-auc:0.634973\n",
      "[66]\tvalidation_0-auc:0.635009\n",
      "[67]\tvalidation_0-auc:0.635274\n",
      "[68]\tvalidation_0-auc:0.635453\n",
      "[69]\tvalidation_0-auc:0.635598\n",
      "[70]\tvalidation_0-auc:0.635873\n",
      "[71]\tvalidation_0-auc:0.636328\n",
      "[72]\tvalidation_0-auc:0.636499\n",
      "[73]\tvalidation_0-auc:0.636566\n",
      "[74]\tvalidation_0-auc:0.636754\n",
      "[75]\tvalidation_0-auc:0.636969\n",
      "[76]\tvalidation_0-auc:0.636927\n",
      "[77]\tvalidation_0-auc:0.636989\n",
      "[78]\tvalidation_0-auc:0.636914\n",
      "[79]\tvalidation_0-auc:0.637084\n",
      "[80]\tvalidation_0-auc:0.637189\n",
      "[81]\tvalidation_0-auc:0.637281\n",
      "[82]\tvalidation_0-auc:0.637417\n",
      "[83]\tvalidation_0-auc:0.63768\n",
      "[84]\tvalidation_0-auc:0.637647\n",
      "[85]\tvalidation_0-auc:0.637795\n",
      "[86]\tvalidation_0-auc:0.637892\n",
      "[87]\tvalidation_0-auc:0.637997\n",
      "[88]\tvalidation_0-auc:0.638071\n",
      "[89]\tvalidation_0-auc:0.638327\n",
      "[90]\tvalidation_0-auc:0.638783\n",
      "[91]\tvalidation_0-auc:0.638944\n",
      "[92]\tvalidation_0-auc:0.638931\n",
      "[93]\tvalidation_0-auc:0.639067\n",
      "[94]\tvalidation_0-auc:0.639423\n",
      "[95]\tvalidation_0-auc:0.639522\n",
      "[96]\tvalidation_0-auc:0.639469\n",
      "[97]\tvalidation_0-auc:0.639424\n",
      "[98]\tvalidation_0-auc:0.639716\n",
      "[99]\tvalidation_0-auc:0.639847\n",
      "[100]\tvalidation_0-auc:0.639897\n",
      "[101]\tvalidation_0-auc:0.639895\n",
      "[102]\tvalidation_0-auc:0.639942\n",
      "[103]\tvalidation_0-auc:0.639952\n",
      "[104]\tvalidation_0-auc:0.64005\n",
      "[105]\tvalidation_0-auc:0.640363\n",
      "[106]\tvalidation_0-auc:0.640342\n",
      "[107]\tvalidation_0-auc:0.640344\n",
      "[108]\tvalidation_0-auc:0.640529\n",
      "[109]\tvalidation_0-auc:0.640625\n",
      "[110]\tvalidation_0-auc:0.640695\n",
      "[111]\tvalidation_0-auc:0.640726\n",
      "[112]\tvalidation_0-auc:0.640689\n",
      "[113]\tvalidation_0-auc:0.640747\n",
      "[114]\tvalidation_0-auc:0.640898\n",
      "[115]\tvalidation_0-auc:0.640953\n",
      "[116]\tvalidation_0-auc:0.64103\n",
      "[117]\tvalidation_0-auc:0.640992\n",
      "[118]\tvalidation_0-auc:0.640943\n",
      "[119]\tvalidation_0-auc:0.641097\n",
      "[120]\tvalidation_0-auc:0.641298\n",
      "[121]\tvalidation_0-auc:0.641297\n",
      "[122]\tvalidation_0-auc:0.641308\n",
      "[123]\tvalidation_0-auc:0.641362\n",
      "[124]\tvalidation_0-auc:0.641368\n",
      "[125]\tvalidation_0-auc:0.64136\n",
      "[126]\tvalidation_0-auc:0.641413\n",
      "[127]\tvalidation_0-auc:0.64144\n",
      "[128]\tvalidation_0-auc:0.641409\n",
      "[129]\tvalidation_0-auc:0.641412\n",
      "[130]\tvalidation_0-auc:0.641417\n",
      "[131]\tvalidation_0-auc:0.641562\n",
      "[132]\tvalidation_0-auc:0.641654\n",
      "[133]\tvalidation_0-auc:0.64168\n",
      "[134]\tvalidation_0-auc:0.641703\n",
      "[135]\tvalidation_0-auc:0.641669\n",
      "[136]\tvalidation_0-auc:0.64172\n",
      "[137]\tvalidation_0-auc:0.641755\n",
      "[138]\tvalidation_0-auc:0.641755\n",
      "[139]\tvalidation_0-auc:0.641798\n",
      "[140]\tvalidation_0-auc:0.641896\n",
      "[141]\tvalidation_0-auc:0.641872\n",
      "[142]\tvalidation_0-auc:0.641885\n",
      "[143]\tvalidation_0-auc:0.64185\n",
      "[144]\tvalidation_0-auc:0.641862\n",
      "[145]\tvalidation_0-auc:0.641872\n",
      "[146]\tvalidation_0-auc:0.641863\n",
      "[147]\tvalidation_0-auc:0.642016\n",
      "[148]\tvalidation_0-auc:0.642191\n",
      "[149]\tvalidation_0-auc:0.642175\n",
      "[150]\tvalidation_0-auc:0.642181\n",
      "[151]\tvalidation_0-auc:0.642153\n",
      "[152]\tvalidation_0-auc:0.642203\n",
      "[153]\tvalidation_0-auc:0.642189\n",
      "[154]\tvalidation_0-auc:0.64215\n",
      "[155]\tvalidation_0-auc:0.642129\n",
      "[156]\tvalidation_0-auc:0.642079\n",
      "[157]\tvalidation_0-auc:0.64208\n",
      "[158]\tvalidation_0-auc:0.642134\n",
      "[159]\tvalidation_0-auc:0.642161\n",
      "[160]\tvalidation_0-auc:0.642205\n",
      "[161]\tvalidation_0-auc:0.642164\n",
      "[162]\tvalidation_0-auc:0.642124\n",
      "[163]\tvalidation_0-auc:0.642169\n",
      "[164]\tvalidation_0-auc:0.642169\n",
      "[165]\tvalidation_0-auc:0.642187\n",
      "[166]\tvalidation_0-auc:0.642206\n",
      "[167]\tvalidation_0-auc:0.642212\n",
      "[168]\tvalidation_0-auc:0.642186\n",
      "[169]\tvalidation_0-auc:0.642246\n",
      "[170]\tvalidation_0-auc:0.642323\n",
      "[171]\tvalidation_0-auc:0.64231\n",
      "[172]\tvalidation_0-auc:0.642312\n",
      "[173]\tvalidation_0-auc:0.642343\n",
      "[174]\tvalidation_0-auc:0.642309\n",
      "[175]\tvalidation_0-auc:0.642373\n",
      "[176]\tvalidation_0-auc:0.642373\n",
      "[177]\tvalidation_0-auc:0.642347\n",
      "[178]\tvalidation_0-auc:0.64238\n",
      "[179]\tvalidation_0-auc:0.642332\n",
      "[180]\tvalidation_0-auc:0.642375\n",
      "[181]\tvalidation_0-auc:0.642375\n",
      "[182]\tvalidation_0-auc:0.642382\n",
      "[183]\tvalidation_0-auc:0.642368\n",
      "[184]\tvalidation_0-auc:0.642363\n",
      "[185]\tvalidation_0-auc:0.642357\n",
      "[186]\tvalidation_0-auc:0.642491\n",
      "[187]\tvalidation_0-auc:0.64246\n",
      "[188]\tvalidation_0-auc:0.64246\n",
      "[189]\tvalidation_0-auc:0.642452\n",
      "[190]\tvalidation_0-auc:0.642451\n",
      "[191]\tvalidation_0-auc:0.642437\n",
      "[192]\tvalidation_0-auc:0.642441\n",
      "[193]\tvalidation_0-auc:0.642468\n",
      "[194]\tvalidation_0-auc:0.642421\n",
      "[195]\tvalidation_0-auc:0.642421\n",
      "[196]\tvalidation_0-auc:0.642464\n",
      "[197]\tvalidation_0-auc:0.642464\n",
      "[198]\tvalidation_0-auc:0.642464\n",
      "[199]\tvalidation_0-auc:0.642543\n",
      "[200]\tvalidation_0-auc:0.642523\n",
      "[201]\tvalidation_0-auc:0.642523\n",
      "[202]\tvalidation_0-auc:0.642542\n",
      "[203]\tvalidation_0-auc:0.642542\n",
      "[204]\tvalidation_0-auc:0.642528\n",
      "[205]\tvalidation_0-auc:0.642522\n",
      "[206]\tvalidation_0-auc:0.64257\n",
      "[207]\tvalidation_0-auc:0.64256\n",
      "[208]\tvalidation_0-auc:0.642541\n",
      "[209]\tvalidation_0-auc:0.642614\n",
      "[210]\tvalidation_0-auc:0.642614\n",
      "[211]\tvalidation_0-auc:0.642605\n",
      "[212]\tvalidation_0-auc:0.642657\n",
      "[213]\tvalidation_0-auc:0.642657\n",
      "[214]\tvalidation_0-auc:0.642646\n",
      "[215]\tvalidation_0-auc:0.642636\n",
      "[216]\tvalidation_0-auc:0.642636\n",
      "[217]\tvalidation_0-auc:0.642636\n",
      "[218]\tvalidation_0-auc:0.642627\n",
      "[219]\tvalidation_0-auc:0.642631\n",
      "[220]\tvalidation_0-auc:0.642659\n",
      "[221]\tvalidation_0-auc:0.642673\n",
      "[222]\tvalidation_0-auc:0.64266\n",
      "[223]\tvalidation_0-auc:0.64266\n",
      "[224]\tvalidation_0-auc:0.642657\n",
      "[225]\tvalidation_0-auc:0.642657\n",
      "[226]\tvalidation_0-auc:0.642653\n",
      "[227]\tvalidation_0-auc:0.642669\n",
      "[228]\tvalidation_0-auc:0.642655\n",
      "[229]\tvalidation_0-auc:0.642655\n",
      "[230]\tvalidation_0-auc:0.642697\n",
      "[231]\tvalidation_0-auc:0.642697\n",
      "[232]\tvalidation_0-auc:0.642697\n",
      "[233]\tvalidation_0-auc:0.642765\n",
      "[234]\tvalidation_0-auc:0.6428\n",
      "[235]\tvalidation_0-auc:0.642799\n",
      "[236]\tvalidation_0-auc:0.64281\n",
      "[237]\tvalidation_0-auc:0.64281\n",
      "[238]\tvalidation_0-auc:0.642834\n",
      "[239]\tvalidation_0-auc:0.642826\n",
      "[240]\tvalidation_0-auc:0.642808\n",
      "[241]\tvalidation_0-auc:0.64281\n",
      "[242]\tvalidation_0-auc:0.64281\n",
      "[243]\tvalidation_0-auc:0.642829\n",
      "[244]\tvalidation_0-auc:0.642875\n",
      "[245]\tvalidation_0-auc:0.642875\n",
      "[246]\tvalidation_0-auc:0.642875\n",
      "[247]\tvalidation_0-auc:0.642875\n",
      "[248]\tvalidation_0-auc:0.6429\n",
      "[249]\tvalidation_0-auc:0.642865\n",
      "[250]\tvalidation_0-auc:0.642852\n",
      "[251]\tvalidation_0-auc:0.642849\n",
      "[252]\tvalidation_0-auc:0.642853\n",
      "[253]\tvalidation_0-auc:0.642853\n",
      "[254]\tvalidation_0-auc:0.642853\n",
      "[255]\tvalidation_0-auc:0.642855\n",
      "[256]\tvalidation_0-auc:0.642848\n",
      "[257]\tvalidation_0-auc:0.642848\n",
      "[258]\tvalidation_0-auc:0.642923\n",
      "[259]\tvalidation_0-auc:0.642933\n",
      "[260]\tvalidation_0-auc:0.642933\n",
      "[261]\tvalidation_0-auc:0.642958\n",
      "[262]\tvalidation_0-auc:0.642958\n",
      "[263]\tvalidation_0-auc:0.64296\n",
      "[264]\tvalidation_0-auc:0.64296\n",
      "[265]\tvalidation_0-auc:0.642965\n",
      "[266]\tvalidation_0-auc:0.642958\n",
      "[267]\tvalidation_0-auc:0.642958\n",
      "[268]\tvalidation_0-auc:0.642958\n",
      "[269]\tvalidation_0-auc:0.642958\n",
      "[270]\tvalidation_0-auc:0.642958\n",
      "[271]\tvalidation_0-auc:0.642946\n",
      "[272]\tvalidation_0-auc:0.642997\n",
      "[273]\tvalidation_0-auc:0.643032\n",
      "[274]\tvalidation_0-auc:0.643037\n",
      "[275]\tvalidation_0-auc:0.643078\n",
      "[276]\tvalidation_0-auc:0.643124\n",
      "[277]\tvalidation_0-auc:0.643167\n",
      "[278]\tvalidation_0-auc:0.643139\n",
      "[279]\tvalidation_0-auc:0.643139\n",
      "[280]\tvalidation_0-auc:0.643139\n",
      "[281]\tvalidation_0-auc:0.643137\n",
      "[282]\tvalidation_0-auc:0.643137\n",
      "[283]\tvalidation_0-auc:0.643137\n",
      "[284]\tvalidation_0-auc:0.643157\n",
      "[285]\tvalidation_0-auc:0.643139\n",
      "[286]\tvalidation_0-auc:0.643234\n",
      "[287]\tvalidation_0-auc:0.64329\n",
      "[288]\tvalidation_0-auc:0.64329\n",
      "[289]\tvalidation_0-auc:0.643287\n",
      "[290]\tvalidation_0-auc:0.643287\n",
      "[291]\tvalidation_0-auc:0.643343\n",
      "[292]\tvalidation_0-auc:0.643343\n",
      "[293]\tvalidation_0-auc:0.643343\n",
      "[294]\tvalidation_0-auc:0.643343\n",
      "[295]\tvalidation_0-auc:0.643372\n",
      "[296]\tvalidation_0-auc:0.643372\n",
      "[297]\tvalidation_0-auc:0.643407\n",
      "[298]\tvalidation_0-auc:0.643407\n",
      "[299]\tvalidation_0-auc:0.643407\n",
      "[300]\tvalidation_0-auc:0.643393\n",
      "[301]\tvalidation_0-auc:0.643369\n",
      "[302]\tvalidation_0-auc:0.643375\n",
      "[303]\tvalidation_0-auc:0.643355\n",
      "[304]\tvalidation_0-auc:0.643355\n",
      "[305]\tvalidation_0-auc:0.643355\n",
      "[306]\tvalidation_0-auc:0.643352\n",
      "[307]\tvalidation_0-auc:0.643524\n",
      "[308]\tvalidation_0-auc:0.643524\n",
      "[309]\tvalidation_0-auc:0.643466\n",
      "[310]\tvalidation_0-auc:0.643461\n",
      "[311]\tvalidation_0-auc:0.643433\n",
      "[312]\tvalidation_0-auc:0.643391\n",
      "[313]\tvalidation_0-auc:0.64344\n",
      "[314]\tvalidation_0-auc:0.643404\n",
      "[315]\tvalidation_0-auc:0.643424\n",
      "[316]\tvalidation_0-auc:0.643424\n",
      "[317]\tvalidation_0-auc:0.643412\n",
      "[318]\tvalidation_0-auc:0.64341\n",
      "[319]\tvalidation_0-auc:0.643389\n",
      "[320]\tvalidation_0-auc:0.643413\n",
      "[321]\tvalidation_0-auc:0.643411\n",
      "[322]\tvalidation_0-auc:0.643435\n",
      "[323]\tvalidation_0-auc:0.643409\n",
      "[324]\tvalidation_0-auc:0.643391\n",
      "[325]\tvalidation_0-auc:0.643392\n",
      "[326]\tvalidation_0-auc:0.643392\n",
      "[327]\tvalidation_0-auc:0.643442\n",
      "[328]\tvalidation_0-auc:0.643442\n",
      "[329]\tvalidation_0-auc:0.64343\n",
      "[330]\tvalidation_0-auc:0.643456\n",
      "[331]\tvalidation_0-auc:0.643492\n",
      "[332]\tvalidation_0-auc:0.643475\n",
      "[333]\tvalidation_0-auc:0.643553\n",
      "[334]\tvalidation_0-auc:0.643553\n",
      "[335]\tvalidation_0-auc:0.643585\n",
      "[336]\tvalidation_0-auc:0.643585\n",
      "[337]\tvalidation_0-auc:0.643585\n",
      "[338]\tvalidation_0-auc:0.643585\n",
      "[339]\tvalidation_0-auc:0.643585\n",
      "[340]\tvalidation_0-auc:0.643585\n",
      "[341]\tvalidation_0-auc:0.643596\n",
      "[342]\tvalidation_0-auc:0.643648\n",
      "[343]\tvalidation_0-auc:0.643648\n",
      "[344]\tvalidation_0-auc:0.643648\n",
      "[345]\tvalidation_0-auc:0.64364\n",
      "[346]\tvalidation_0-auc:0.643635\n",
      "[347]\tvalidation_0-auc:0.643641\n",
      "[348]\tvalidation_0-auc:0.643635\n",
      "[349]\tvalidation_0-auc:0.643641\n",
      "[350]\tvalidation_0-auc:0.6436\n",
      "[351]\tvalidation_0-auc:0.643577\n",
      "[352]\tvalidation_0-auc:0.643684\n",
      "[353]\tvalidation_0-auc:0.64374\n",
      "[354]\tvalidation_0-auc:0.643743\n",
      "[355]\tvalidation_0-auc:0.643706\n",
      "[356]\tvalidation_0-auc:0.643685\n",
      "[357]\tvalidation_0-auc:0.643685\n",
      "[358]\tvalidation_0-auc:0.643676\n",
      "[359]\tvalidation_0-auc:0.643676\n",
      "[360]\tvalidation_0-auc:0.643676\n",
      "[361]\tvalidation_0-auc:0.643649\n",
      "[362]\tvalidation_0-auc:0.643602\n",
      "[363]\tvalidation_0-auc:0.643593\n",
      "[364]\tvalidation_0-auc:0.643593\n",
      "[365]\tvalidation_0-auc:0.643593\n",
      "[366]\tvalidation_0-auc:0.643604\n",
      "[367]\tvalidation_0-auc:0.643604\n",
      "[368]\tvalidation_0-auc:0.6436\n",
      "[369]\tvalidation_0-auc:0.643573\n",
      "[370]\tvalidation_0-auc:0.643573\n",
      "[371]\tvalidation_0-auc:0.643555\n",
      "[372]\tvalidation_0-auc:0.643555\n",
      "[373]\tvalidation_0-auc:0.643583\n",
      "[374]\tvalidation_0-auc:0.643583\n",
      "[375]\tvalidation_0-auc:0.643579\n",
      "[376]\tvalidation_0-auc:0.643617\n",
      "[377]\tvalidation_0-auc:0.643629\n",
      "[378]\tvalidation_0-auc:0.643641\n",
      "[379]\tvalidation_0-auc:0.643628\n",
      "[380]\tvalidation_0-auc:0.64364\n",
      "[381]\tvalidation_0-auc:0.643658\n",
      "[382]\tvalidation_0-auc:0.643646\n",
      "[383]\tvalidation_0-auc:0.643646\n",
      "[384]\tvalidation_0-auc:0.643647\n",
      "[385]\tvalidation_0-auc:0.643647\n",
      "[386]\tvalidation_0-auc:0.643643\n",
      "[387]\tvalidation_0-auc:0.643643\n",
      "[388]\tvalidation_0-auc:0.643643\n",
      "[389]\tvalidation_0-auc:0.643615\n",
      "[390]\tvalidation_0-auc:0.643586\n",
      "[391]\tvalidation_0-auc:0.643586\n",
      "[392]\tvalidation_0-auc:0.643581\n",
      "[393]\tvalidation_0-auc:0.643581\n",
      "[394]\tvalidation_0-auc:0.643575\n",
      "[395]\tvalidation_0-auc:0.643605\n",
      "[396]\tvalidation_0-auc:0.643584\n",
      "[397]\tvalidation_0-auc:0.643584\n",
      "[398]\tvalidation_0-auc:0.643584\n",
      "[399]\tvalidation_0-auc:0.643584\n",
      "[400]\tvalidation_0-auc:0.643584\n",
      "[401]\tvalidation_0-auc:0.643584\n",
      "[402]\tvalidation_0-auc:0.643588\n",
      "[403]\tvalidation_0-auc:0.643582\n",
      "[404]\tvalidation_0-auc:0.643582\n",
      "Stopping. Best iteration:\n",
      "[354]\tvalidation_0-auc:0.643743\n",
      "\n",
      "Gini score=  0.287163328068\n"
     ]
    }
   ],
   "source": [
    "xgb_params= {'learning_rate': 0.07,\n",
    "             'n_estimators':1000, #525, #,354\n",
    "             'max_depth': 4, \n",
    "             'nthread':8,\n",
    "             'subsample': 0.8,\n",
    "             'min_child_weight':0.77,\n",
    "             'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', \n",
    "             'eval_metric': 'auc', \n",
    "             'seed': 99, \n",
    "             'silent': True,\n",
    "             'scale_pos_weight': 1.6,\n",
    "             'reg_alpha':8,\n",
    "             'reg_lambda':1.3,\n",
    "             'gamma':10\n",
    "            }\n",
    "xgbm1= xgboost.sklearn.XGBClassifier(**xgb_params)\n",
    "xgbm1.fit(X_train,y_train,eval_metric='auc',early_stopping_rounds=50,eval_set=[(X_test,y_test)])\n",
    "y_pred= xgbm1.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep= np.where(xgbm1.feature_importances_ > 0.)[0]\n",
    "# keep2= np.where(xgbm1.feature_importances_ > 0.)[0]\n",
    "keeps= keep[keep2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(open('xgboost_rfe_keepers.bin','wb'),keeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 650\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.05\n",
    "cb_params= {\n",
    "    'learning_rate':0.05, \n",
    "    'depth':6, \n",
    "    'l2_leaf_reg': 14, \n",
    "    'iterations':650,\n",
    "    'verbose': True,\n",
    "    'loss_function':'Logloss'\n",
    "    }\n",
    "\n",
    "cb= catboost.CatBoostClassifier(**cb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: learn: 0.6202101\ttotal: 475ms\tremaining: 5m 8s\n",
      "1: learn: 0.5567888\ttotal: 909ms\tremaining: 4m 54s\n",
      "2: learn: 0.5023358\ttotal: 1.35s\tremaining: 4m 50s\n",
      "3: learn: 0.4557553\ttotal: 1.78s\tremaining: 4m 47s\n",
      "4: learn: 0.4152165\ttotal: 2.19s\tremaining: 4m 43s\n",
      "5: learn: 0.3805192\ttotal: 2.63s\tremaining: 4m 42s\n",
      "6: learn: 0.3507592\ttotal: 3.06s\tremaining: 4m 40s\n",
      "7: learn: 0.3251094\ttotal: 3.48s\tremaining: 4m 39s\n",
      "8: learn: 0.3031735\ttotal: 3.89s\tremaining: 4m 37s\n",
      "9: learn: 0.2841162\ttotal: 4.45s\tremaining: 4m 44s\n",
      "10: learn: 0.2678054\ttotal: 4.76s\tremaining: 4m 36s\n",
      "11: learn: 0.253743\ttotal: 5.22s\tremaining: 4m 37s\n",
      "12: learn: 0.2413729\ttotal: 5.65s\tremaining: 4m 36s\n",
      "13: learn: 0.2306661\ttotal: 6.17s\tremaining: 4m 40s\n",
      "14: learn: 0.2213532\ttotal: 6.59s\tremaining: 4m 39s\n",
      "15: learn: 0.2133104\ttotal: 7.23s\tremaining: 4m 46s\n",
      "16: learn: 0.2063741\ttotal: 7.67s\tremaining: 4m 45s\n",
      "17: learn: 0.2003758\ttotal: 7.94s\tremaining: 4m 38s\n",
      "18: learn: 0.1949752\ttotal: 8.44s\tremaining: 4m 40s\n",
      "19: learn: 0.1902638\ttotal: 8.99s\tremaining: 4m 43s\n",
      "20: learn: 0.1861116\ttotal: 9.44s\tremaining: 4m 42s\n",
      "21: learn: 0.1824768\ttotal: 9.88s\tremaining: 4m 42s\n",
      "22: learn: 0.1793451\ttotal: 10.4s\tremaining: 4m 44s\n",
      "23: learn: 0.1764756\ttotal: 10.9s\tremaining: 4m 43s\n",
      "24: learn: 0.1739872\ttotal: 11.4s\tremaining: 4m 43s\n",
      "25: learn: 0.1717589\ttotal: 11.9s\tremaining: 4m 46s\n",
      "26: learn: 0.1698965\ttotal: 12.4s\tremaining: 4m 46s\n",
      "27: learn: 0.1681523\ttotal: 12.9s\tremaining: 4m 45s\n",
      "28: learn: 0.1666567\ttotal: 13.3s\tremaining: 4m 44s\n",
      "29: learn: 0.1652382\ttotal: 13.9s\tremaining: 4m 47s\n",
      "30: learn: 0.1640324\ttotal: 14.3s\tremaining: 4m 46s\n",
      "31: learn: 0.1629806\ttotal: 14.8s\tremaining: 4m 46s\n",
      "32: learn: 0.162009\ttotal: 15.4s\tremaining: 4m 47s\n",
      "33: learn: 0.1611495\ttotal: 15.8s\tremaining: 4m 46s\n",
      "34: learn: 0.160391\ttotal: 16.2s\tremaining: 4m 44s\n",
      "35: learn: 0.1597431\ttotal: 16.6s\tremaining: 4m 43s\n",
      "36: learn: 0.1591575\ttotal: 17.2s\tremaining: 4m 44s\n",
      "37: learn: 0.1585493\ttotal: 17.6s\tremaining: 4m 43s\n",
      "38: learn: 0.1580236\ttotal: 18.1s\tremaining: 4m 43s\n",
      "39: learn: 0.1575841\ttotal: 18.5s\tremaining: 4m 41s\n",
      "40: learn: 0.1571793\ttotal: 18.9s\tremaining: 4m 40s\n",
      "41: learn: 0.1568065\ttotal: 19.4s\tremaining: 4m 41s\n",
      "42: learn: 0.1564705\ttotal: 19.9s\tremaining: 4m 41s\n",
      "43: learn: 0.1561681\ttotal: 20.4s\tremaining: 4m 40s\n",
      "44: learn: 0.1559183\ttotal: 20.9s\tremaining: 4m 41s\n",
      "45: learn: 0.1556694\ttotal: 21.4s\tremaining: 4m 40s\n",
      "46: learn: 0.1554278\ttotal: 21.8s\tremaining: 4m 40s\n",
      "47: learn: 0.155223\ttotal: 22.3s\tremaining: 4m 39s\n",
      "48: learn: 0.1550324\ttotal: 22.7s\tremaining: 4m 38s\n",
      "49: learn: 0.1548941\ttotal: 23s\tremaining: 4m 36s\n",
      "50: learn: 0.15473\ttotal: 23.4s\tremaining: 4m 35s\n",
      "51: learn: 0.1545908\ttotal: 23.9s\tremaining: 4m 34s\n",
      "52: learn: 0.1544358\ttotal: 24.3s\tremaining: 4m 33s\n",
      "53: learn: 0.1543089\ttotal: 24.9s\tremaining: 4m 34s\n",
      "54: learn: 0.1541812\ttotal: 25.4s\tremaining: 4m 34s\n",
      "55: learn: 0.1540767\ttotal: 25.8s\tremaining: 4m 34s\n",
      "56: learn: 0.153979\ttotal: 26.3s\tremaining: 4m 33s\n",
      "57: learn: 0.1538921\ttotal: 26.7s\tremaining: 4m 32s\n",
      "58: learn: 0.153804\ttotal: 27.3s\tremaining: 4m 33s\n",
      "59: learn: 0.1536992\ttotal: 27.9s\tremaining: 4m 33s\n",
      "60: learn: 0.1536185\ttotal: 28.3s\tremaining: 4m 33s\n",
      "61: learn: 0.1535537\ttotal: 28.8s\tremaining: 4m 33s\n",
      "62: learn: 0.1534864\ttotal: 29.3s\tremaining: 4m 32s\n",
      "63: learn: 0.1534221\ttotal: 29.7s\tremaining: 4m 31s\n",
      "64: learn: 0.15336\ttotal: 30.1s\tremaining: 4m 30s\n",
      "65: learn: 0.1533064\ttotal: 30.5s\tremaining: 4m 30s\n",
      "66: learn: 0.1532528\ttotal: 30.9s\tremaining: 4m 29s\n",
      "67: learn: 0.1531944\ttotal: 31.4s\tremaining: 4m 28s\n",
      "68: learn: 0.1531332\ttotal: 31.8s\tremaining: 4m 27s\n",
      "69: learn: 0.1530908\ttotal: 32.2s\tremaining: 4m 27s\n",
      "70: learn: 0.1530473\ttotal: 32.6s\tremaining: 4m 26s\n",
      "71: learn: 0.153022\ttotal: 33s\tremaining: 4m 24s\n",
      "72: learn: 0.1529823\ttotal: 33.4s\tremaining: 4m 23s\n",
      "73: learn: 0.1529571\ttotal: 33.9s\tremaining: 4m 23s\n",
      "74: learn: 0.1529238\ttotal: 34.5s\tremaining: 4m 24s\n",
      "75: learn: 0.1528976\ttotal: 35s\tremaining: 4m 24s\n",
      "76: learn: 0.15287\ttotal: 35.6s\tremaining: 4m 24s\n",
      "77: learn: 0.15284\ttotal: 36s\tremaining: 4m 24s\n",
      "78: learn: 0.1528151\ttotal: 36.5s\tremaining: 4m 23s\n",
      "79: learn: 0.1527905\ttotal: 36.9s\tremaining: 4m 22s\n",
      "80: learn: 0.1527639\ttotal: 37.3s\tremaining: 4m 22s\n",
      "81: learn: 0.1527361\ttotal: 37.7s\tremaining: 4m 21s\n",
      "82: learn: 0.1527173\ttotal: 38.2s\tremaining: 4m 20s\n",
      "83: learn: 0.1526996\ttotal: 38.7s\tremaining: 4m 20s\n",
      "84: learn: 0.1526745\ttotal: 39.2s\tremaining: 4m 20s\n",
      "85: learn: 0.1526602\ttotal: 39.7s\tremaining: 4m 20s\n",
      "86: learn: 0.1526485\ttotal: 40.3s\tremaining: 4m 20s\n",
      "87: learn: 0.1526308\ttotal: 40.7s\tremaining: 4m 20s\n",
      "88: learn: 0.1526124\ttotal: 41.2s\tremaining: 4m 19s\n",
      "89: learn: 0.1525857\ttotal: 41.6s\tremaining: 4m 18s\n",
      "90: learn: 0.1525632\ttotal: 42s\tremaining: 4m 18s\n",
      "91: learn: 0.1525483\ttotal: 42.5s\tremaining: 4m 17s\n",
      "92: learn: 0.1525281\ttotal: 42.9s\tremaining: 4m 16s\n",
      "93: learn: 0.152512\ttotal: 43.4s\tremaining: 4m 16s\n",
      "94: learn: 0.152505\ttotal: 43.9s\tremaining: 4m 16s\n",
      "95: learn: 0.1524834\ttotal: 44.3s\tremaining: 4m 15s\n",
      "96: learn: 0.152461\ttotal: 44.9s\tremaining: 4m 15s\n",
      "97: learn: 0.1524278\ttotal: 45.4s\tremaining: 4m 15s\n",
      "98: learn: 0.1524122\ttotal: 45.8s\tremaining: 4m 14s\n",
      "99: learn: 0.1523943\ttotal: 46.3s\tremaining: 4m 14s\n",
      "100: learn: 0.1523831\ttotal: 46.7s\tremaining: 4m 13s\n",
      "101: learn: 0.152364\ttotal: 47.3s\tremaining: 4m 13s\n",
      "102: learn: 0.1523476\ttotal: 47.8s\tremaining: 4m 14s\n",
      "103: learn: 0.1523434\ttotal: 48.3s\tremaining: 4m 13s\n",
      "104: learn: 0.1523319\ttotal: 48.8s\tremaining: 4m 13s\n",
      "105: learn: 0.1523173\ttotal: 49.3s\tremaining: 4m 12s\n",
      "106: learn: 0.1523014\ttotal: 49.7s\tremaining: 4m 12s\n",
      "107: learn: 0.1522839\ttotal: 50.2s\tremaining: 4m 11s\n",
      "108: learn: 0.1522677\ttotal: 50.6s\tremaining: 4m 11s\n",
      "109: learn: 0.1522536\ttotal: 51.1s\tremaining: 4m 10s\n",
      "110: learn: 0.1522434\ttotal: 51.6s\tremaining: 4m 10s\n",
      "111: learn: 0.1522245\ttotal: 52s\tremaining: 4m 9s\n",
      "112: learn: 0.1522156\ttotal: 52.5s\tremaining: 4m 9s\n",
      "113: learn: 0.1522066\ttotal: 53s\tremaining: 4m 9s\n",
      "114: learn: 0.1521963\ttotal: 53.4s\tremaining: 4m 8s\n",
      "115: learn: 0.1521864\ttotal: 53.9s\tremaining: 4m 8s\n",
      "116: learn: 0.1521695\ttotal: 54.3s\tremaining: 4m 7s\n",
      "117: learn: 0.1521544\ttotal: 54.8s\tremaining: 4m 6s\n",
      "118: learn: 0.1521384\ttotal: 55.3s\tremaining: 4m 6s\n",
      "119: learn: 0.1521275\ttotal: 55.7s\tremaining: 4m 6s\n",
      "120: learn: 0.1521175\ttotal: 56.2s\tremaining: 4m 5s\n",
      "121: learn: 0.1521038\ttotal: 56.6s\tremaining: 4m 5s\n",
      "122: learn: 0.1520904\ttotal: 57.1s\tremaining: 4m 4s\n",
      "123: learn: 0.1520858\ttotal: 57.5s\tremaining: 4m 3s\n",
      "124: learn: 0.152079\ttotal: 57.9s\tremaining: 4m 3s\n",
      "125: learn: 0.1520668\ttotal: 58.4s\tremaining: 4m 2s\n",
      "126: learn: 0.1520547\ttotal: 58.8s\tremaining: 4m 2s\n",
      "127: learn: 0.1520393\ttotal: 59.2s\tremaining: 4m 1s\n",
      "128: learn: 0.1520301\ttotal: 59.7s\tremaining: 4m\n",
      "129: learn: 0.1520213\ttotal: 1m\tremaining: 4m\n",
      "130: learn: 0.1520201\ttotal: 1m\tremaining: 3m 59s\n",
      "131: learn: 0.1520084\ttotal: 1m\tremaining: 3m 59s\n",
      "132: learn: 0.1520044\ttotal: 1m 1s\tremaining: 3m 58s\n",
      "133: learn: 0.1519906\ttotal: 1m 1s\tremaining: 3m 57s\n",
      "134: learn: 0.1519823\ttotal: 1m 2s\tremaining: 3m 57s\n",
      "135: learn: 0.1519646\ttotal: 1m 2s\tremaining: 3m 56s\n",
      "136: learn: 0.1519621\ttotal: 1m 3s\tremaining: 3m 55s\n",
      "137: learn: 0.1519576\ttotal: 1m 3s\tremaining: 3m 55s\n",
      "138: learn: 0.1519539\ttotal: 1m 3s\tremaining: 3m 54s\n",
      "139: learn: 0.1519472\ttotal: 1m 4s\tremaining: 3m 54s\n",
      "140: learn: 0.1519407\ttotal: 1m 4s\tremaining: 3m 53s\n",
      "141: learn: 0.1519323\ttotal: 1m 5s\tremaining: 3m 53s\n",
      "142: learn: 0.1519259\ttotal: 1m 5s\tremaining: 3m 52s\n",
      "143: learn: 0.1519161\ttotal: 1m 6s\tremaining: 3m 52s\n",
      "144: learn: 0.1519008\ttotal: 1m 6s\tremaining: 3m 51s\n",
      "145: learn: 0.151887\ttotal: 1m 6s\tremaining: 3m 51s\n",
      "146: learn: 0.1518754\ttotal: 1m 7s\tremaining: 3m 50s\n",
      "147: learn: 0.1518646\ttotal: 1m 7s\tremaining: 3m 50s\n",
      "148: learn: 0.1518556\ttotal: 1m 8s\tremaining: 3m 49s\n",
      "149: learn: 0.1518528\ttotal: 1m 8s\tremaining: 3m 49s\n",
      "150: learn: 0.1518439\ttotal: 1m 9s\tremaining: 3m 48s\n",
      "151: learn: 0.1518368\ttotal: 1m 9s\tremaining: 3m 48s\n",
      "152: learn: 0.1518276\ttotal: 1m 10s\tremaining: 3m 47s\n",
      "153: learn: 0.1518127\ttotal: 1m 10s\tremaining: 3m 47s\n",
      "154: learn: 0.1518006\ttotal: 1m 11s\tremaining: 3m 46s\n",
      "155: learn: 0.1517989\ttotal: 1m 11s\tremaining: 3m 45s\n",
      "156: learn: 0.15179\ttotal: 1m 11s\tremaining: 3m 45s\n",
      "157: learn: 0.1517799\ttotal: 1m 12s\tremaining: 3m 44s\n",
      "158: learn: 0.1517725\ttotal: 1m 12s\tremaining: 3m 44s\n",
      "159: learn: 0.1517618\ttotal: 1m 13s\tremaining: 3m 43s\n",
      "160: learn: 0.1517501\ttotal: 1m 13s\tremaining: 3m 43s\n",
      "161: learn: 0.1517446\ttotal: 1m 14s\tremaining: 3m 43s\n",
      "162: learn: 0.151734\ttotal: 1m 14s\tremaining: 3m 43s\n",
      "163: learn: 0.1517267\ttotal: 1m 15s\tremaining: 3m 42s\n",
      "164: learn: 0.1517174\ttotal: 1m 15s\tremaining: 3m 42s\n",
      "165: learn: 0.1517108\ttotal: 1m 16s\tremaining: 3m 42s\n",
      "166: learn: 0.1517035\ttotal: 1m 16s\tremaining: 3m 41s\n",
      "167: learn: 0.1516976\ttotal: 1m 17s\tremaining: 3m 41s\n",
      "168: learn: 0.1516898\ttotal: 1m 17s\tremaining: 3m 40s\n",
      "169: learn: 0.1516835\ttotal: 1m 18s\tremaining: 3m 40s\n",
      "170: learn: 0.1516776\ttotal: 1m 18s\tremaining: 3m 39s\n",
      "171: learn: 0.1516711\ttotal: 1m 18s\tremaining: 3m 39s\n",
      "172: learn: 0.151665\ttotal: 1m 19s\tremaining: 3m 38s\n",
      "173: learn: 0.1516524\ttotal: 1m 19s\tremaining: 3m 38s\n",
      "174: learn: 0.1516478\ttotal: 1m 20s\tremaining: 3m 38s\n",
      "175: learn: 0.1516358\ttotal: 1m 21s\tremaining: 3m 38s\n",
      "176: learn: 0.1516228\ttotal: 1m 21s\tremaining: 3m 38s\n",
      "177: learn: 0.1516179\ttotal: 1m 22s\tremaining: 3m 37s\n",
      "178: learn: 0.1516131\ttotal: 1m 22s\tremaining: 3m 37s\n",
      "179: learn: 0.1516006\ttotal: 1m 23s\tremaining: 3m 36s\n",
      "180: learn: 0.1515963\ttotal: 1m 23s\tremaining: 3m 36s\n",
      "181: learn: 0.1515863\ttotal: 1m 23s\tremaining: 3m 35s\n",
      "182: learn: 0.151585\ttotal: 1m 24s\tremaining: 3m 35s\n",
      "183: learn: 0.1515793\ttotal: 1m 24s\tremaining: 3m 34s\n",
      "184: learn: 0.1515743\ttotal: 1m 25s\tremaining: 3m 34s\n",
      "185: learn: 0.1515686\ttotal: 1m 25s\tremaining: 3m 33s\n",
      "186: learn: 0.1515544\ttotal: 1m 26s\tremaining: 3m 33s\n",
      "187: learn: 0.1515499\ttotal: 1m 26s\tremaining: 3m 33s\n",
      "188: learn: 0.1515391\ttotal: 1m 27s\tremaining: 3m 33s\n",
      "189: learn: 0.1515317\ttotal: 1m 27s\tremaining: 3m 32s\n",
      "190: learn: 0.1515206\ttotal: 1m 28s\tremaining: 3m 32s\n",
      "191: learn: 0.1515152\ttotal: 1m 28s\tremaining: 3m 31s\n",
      "192: learn: 0.1515095\ttotal: 1m 29s\tremaining: 3m 31s\n",
      "193: learn: 0.1515038\ttotal: 1m 29s\tremaining: 3m 30s\n",
      "194: learn: 0.1514952\ttotal: 1m 30s\tremaining: 3m 30s\n",
      "195: learn: 0.151488\ttotal: 1m 30s\tremaining: 3m 29s\n",
      "196: learn: 0.1514791\ttotal: 1m 31s\tremaining: 3m 29s\n",
      "197: learn: 0.1514708\ttotal: 1m 31s\tremaining: 3m 29s\n",
      "198: learn: 0.151463\ttotal: 1m 32s\tremaining: 3m 28s\n",
      "199: learn: 0.151462\ttotal: 1m 32s\tremaining: 3m 28s\n",
      "200: learn: 0.1514564\ttotal: 1m 32s\tremaining: 3m 27s\n",
      "201: learn: 0.1514548\ttotal: 1m 33s\tremaining: 3m 27s\n",
      "202: learn: 0.1514496\ttotal: 1m 33s\tremaining: 3m 26s\n",
      "203: learn: 0.1514428\ttotal: 1m 34s\tremaining: 3m 26s\n",
      "204: learn: 0.1514384\ttotal: 1m 34s\tremaining: 3m 25s\n",
      "205: learn: 0.1514317\ttotal: 1m 35s\tremaining: 3m 25s\n",
      "206: learn: 0.1514269\ttotal: 1m 35s\tremaining: 3m 25s\n",
      "207: learn: 0.1514173\ttotal: 1m 36s\tremaining: 3m 24s\n",
      "208: learn: 0.1514139\ttotal: 1m 36s\tremaining: 3m 24s\n",
      "209: learn: 0.15141\ttotal: 1m 37s\tremaining: 3m 23s\n",
      "210: learn: 0.1514048\ttotal: 1m 37s\tremaining: 3m 23s\n",
      "211: learn: 0.1514038\ttotal: 1m 37s\tremaining: 3m 22s\n",
      "212: learn: 0.1513974\ttotal: 1m 38s\tremaining: 3m 21s\n",
      "213: learn: 0.1513943\ttotal: 1m 38s\tremaining: 3m 21s\n",
      "214: learn: 0.151388\ttotal: 1m 39s\tremaining: 3m 20s\n",
      "215: learn: 0.1513801\ttotal: 1m 39s\tremaining: 3m 20s\n",
      "216: learn: 0.1513798\ttotal: 1m 39s\tremaining: 3m 19s\n",
      "217: learn: 0.1513744\ttotal: 1m 40s\tremaining: 3m 18s\n",
      "218: learn: 0.1513629\ttotal: 1m 40s\tremaining: 3m 18s\n",
      "219: learn: 0.1513558\ttotal: 1m 41s\tremaining: 3m 17s\n",
      "220: learn: 0.1513526\ttotal: 1m 41s\tremaining: 3m 17s\n",
      "221: learn: 0.1513456\ttotal: 1m 42s\tremaining: 3m 17s\n",
      "222: learn: 0.1513398\ttotal: 1m 42s\tremaining: 3m 16s\n",
      "223: learn: 0.1513287\ttotal: 1m 43s\tremaining: 3m 16s\n",
      "224: learn: 0.1513202\ttotal: 1m 43s\tremaining: 3m 15s\n",
      "225: learn: 0.1513128\ttotal: 1m 44s\tremaining: 3m 15s\n",
      "226: learn: 0.151304\ttotal: 1m 44s\tremaining: 3m 14s\n",
      "227: learn: 0.1512965\ttotal: 1m 45s\tremaining: 3m 14s\n",
      "228: learn: 0.1512878\ttotal: 1m 45s\tremaining: 3m 13s\n",
      "229: learn: 0.1512791\ttotal: 1m 45s\tremaining: 3m 13s\n",
      "230: learn: 0.1512724\ttotal: 1m 46s\tremaining: 3m 12s\n",
      "231: learn: 0.1512666\ttotal: 1m 46s\tremaining: 3m 12s\n",
      "232: learn: 0.1512575\ttotal: 1m 47s\tremaining: 3m 11s\n",
      "233: learn: 0.1512536\ttotal: 1m 47s\tremaining: 3m 11s\n",
      "234: learn: 0.1512466\ttotal: 1m 48s\tremaining: 3m 11s\n",
      "235: learn: 0.1512355\ttotal: 1m 48s\tremaining: 3m 10s\n",
      "236: learn: 0.151232\ttotal: 1m 49s\tremaining: 3m 10s\n",
      "237: learn: 0.1512249\ttotal: 1m 49s\tremaining: 3m 10s\n",
      "238: learn: 0.1512167\ttotal: 1m 50s\tremaining: 3m 9s\n",
      "239: learn: 0.1512105\ttotal: 1m 50s\tremaining: 3m 9s\n",
      "240: learn: 0.1512035\ttotal: 1m 51s\tremaining: 3m 9s\n",
      "241: learn: 0.1511988\ttotal: 1m 52s\tremaining: 3m 8s\n",
      "242: learn: 0.1511933\ttotal: 1m 52s\tremaining: 3m 8s\n",
      "243: learn: 0.1511891\ttotal: 1m 53s\tremaining: 3m 8s\n",
      "244: learn: 0.1511834\ttotal: 1m 53s\tremaining: 3m 8s\n",
      "245: learn: 0.1511763\ttotal: 1m 54s\tremaining: 3m 7s\n",
      "246: learn: 0.1511719\ttotal: 1m 54s\tremaining: 3m 7s\n",
      "247: learn: 0.151168\ttotal: 1m 55s\tremaining: 3m 6s\n",
      "248: learn: 0.1511627\ttotal: 1m 55s\tremaining: 3m 6s\n",
      "249: learn: 0.1511585\ttotal: 1m 56s\tremaining: 3m 5s\n",
      "250: learn: 0.1511525\ttotal: 1m 56s\tremaining: 3m 5s\n",
      "251: learn: 0.1511452\ttotal: 1m 57s\tremaining: 3m 4s\n",
      "252: learn: 0.1511332\ttotal: 1m 57s\tremaining: 3m 4s\n",
      "253: learn: 0.1511239\ttotal: 1m 57s\tremaining: 3m 3s\n",
      "254: learn: 0.1511193\ttotal: 1m 58s\tremaining: 3m 3s\n",
      "255: learn: 0.1511113\ttotal: 1m 58s\tremaining: 3m 2s\n",
      "256: learn: 0.1511067\ttotal: 1m 59s\tremaining: 3m 2s\n",
      "257: learn: 0.1511014\ttotal: 1m 59s\tremaining: 3m 2s\n",
      "258: learn: 0.1510954\ttotal: 2m\tremaining: 3m 1s\n",
      "259: learn: 0.1510877\ttotal: 2m\tremaining: 3m 1s\n",
      "260: learn: 0.1510775\ttotal: 2m 1s\tremaining: 3m\n",
      "261: learn: 0.151072\ttotal: 2m 1s\tremaining: 3m\n",
      "262: learn: 0.1510615\ttotal: 2m 2s\tremaining: 2m 59s\n",
      "263: learn: 0.1510543\ttotal: 2m 2s\tremaining: 2m 59s\n",
      "264: learn: 0.1510449\ttotal: 2m 3s\tremaining: 2m 58s\n",
      "265: learn: 0.1510422\ttotal: 2m 3s\tremaining: 2m 58s\n",
      "266: learn: 0.1510342\ttotal: 2m 4s\tremaining: 2m 58s\n",
      "267: learn: 0.1510293\ttotal: 2m 4s\tremaining: 2m 57s\n",
      "268: learn: 0.151019\ttotal: 2m 5s\tremaining: 2m 57s\n",
      "269: learn: 0.1510118\ttotal: 2m 5s\tremaining: 2m 56s\n",
      "270: learn: 0.1510008\ttotal: 2m 6s\tremaining: 2m 56s\n",
      "271: learn: 0.1509946\ttotal: 2m 6s\tremaining: 2m 55s\n",
      "272: learn: 0.1509878\ttotal: 2m 6s\tremaining: 2m 55s\n",
      "273: learn: 0.1509834\ttotal: 2m 7s\tremaining: 2m 54s\n",
      "274: learn: 0.1509745\ttotal: 2m 7s\tremaining: 2m 54s\n",
      "275: learn: 0.1509669\ttotal: 2m 8s\tremaining: 2m 54s\n",
      "276: learn: 0.1509615\ttotal: 2m 9s\tremaining: 2m 53s\n",
      "277: learn: 0.1509528\ttotal: 2m 9s\tremaining: 2m 53s\n",
      "278: learn: 0.1509498\ttotal: 2m 10s\tremaining: 2m 52s\n",
      "279: learn: 0.1509459\ttotal: 2m 10s\tremaining: 2m 52s\n",
      "280: learn: 0.1509368\ttotal: 2m 11s\tremaining: 2m 52s\n",
      "281: learn: 0.1509317\ttotal: 2m 11s\tremaining: 2m 51s\n",
      "282: learn: 0.1509214\ttotal: 2m 12s\tremaining: 2m 51s\n",
      "283: learn: 0.150913\ttotal: 2m 12s\tremaining: 2m 50s\n",
      "284: learn: 0.1509089\ttotal: 2m 13s\tremaining: 2m 50s\n",
      "285: learn: 0.1509007\ttotal: 2m 13s\tremaining: 2m 49s\n",
      "286: learn: 0.150896\ttotal: 2m 14s\tremaining: 2m 49s\n",
      "287: learn: 0.150892\ttotal: 2m 14s\tremaining: 2m 49s\n",
      "288: learn: 0.1508852\ttotal: 2m 15s\tremaining: 2m 48s\n",
      "289: learn: 0.1508755\ttotal: 2m 15s\tremaining: 2m 48s\n",
      "290: learn: 0.1508713\ttotal: 2m 16s\tremaining: 2m 47s\n",
      "291: learn: 0.1508596\ttotal: 2m 16s\tremaining: 2m 47s\n",
      "292: learn: 0.1508564\ttotal: 2m 16s\tremaining: 2m 46s\n",
      "293: learn: 0.1508518\ttotal: 2m 17s\tremaining: 2m 46s\n",
      "294: learn: 0.1508449\ttotal: 2m 17s\tremaining: 2m 45s\n",
      "295: learn: 0.1508337\ttotal: 2m 18s\tremaining: 2m 45s\n",
      "296: learn: 0.1508212\ttotal: 2m 19s\tremaining: 2m 45s\n",
      "297: learn: 0.150814\ttotal: 2m 19s\tremaining: 2m 44s\n",
      "298: learn: 0.1508099\ttotal: 2m 20s\tremaining: 2m 44s\n",
      "299: learn: 0.1508004\ttotal: 2m 20s\tremaining: 2m 44s\n",
      "300: learn: 0.150791\ttotal: 2m 21s\tremaining: 2m 43s\n",
      "301: learn: 0.1507834\ttotal: 2m 21s\tremaining: 2m 43s\n",
      "302: learn: 0.1507756\ttotal: 2m 22s\tremaining: 2m 42s\n",
      "303: learn: 0.1507717\ttotal: 2m 22s\tremaining: 2m 42s\n",
      "304: learn: 0.1507647\ttotal: 2m 23s\tremaining: 2m 42s\n",
      "305: learn: 0.1507613\ttotal: 2m 23s\tremaining: 2m 41s\n",
      "306: learn: 0.1507533\ttotal: 2m 24s\tremaining: 2m 41s\n",
      "307: learn: 0.1507479\ttotal: 2m 25s\tremaining: 2m 41s\n",
      "308: learn: 0.150742\ttotal: 2m 25s\tremaining: 2m 40s\n",
      "309: learn: 0.1507357\ttotal: 2m 26s\tremaining: 2m 40s\n",
      "310: learn: 0.1507315\ttotal: 2m 26s\tremaining: 2m 40s\n",
      "311: learn: 0.1507265\ttotal: 2m 27s\tremaining: 2m 39s\n",
      "312: learn: 0.1507216\ttotal: 2m 27s\tremaining: 2m 39s\n",
      "313: learn: 0.1507156\ttotal: 2m 28s\tremaining: 2m 38s\n",
      "314: learn: 0.1507089\ttotal: 2m 28s\tremaining: 2m 38s\n",
      "315: learn: 0.1507049\ttotal: 2m 29s\tremaining: 2m 38s\n",
      "316: learn: 0.1506969\ttotal: 2m 29s\tremaining: 2m 37s\n",
      "317: learn: 0.1506886\ttotal: 2m 30s\tremaining: 2m 37s\n",
      "318: learn: 0.1506811\ttotal: 2m 30s\tremaining: 2m 36s\n",
      "319: learn: 0.1506736\ttotal: 2m 31s\tremaining: 2m 36s\n",
      "320: learn: 0.1506655\ttotal: 2m 31s\tremaining: 2m 35s\n",
      "321: learn: 0.1506613\ttotal: 2m 32s\tremaining: 2m 34s\n",
      "322: learn: 0.1506564\ttotal: 2m 32s\tremaining: 2m 34s\n",
      "323: learn: 0.1506463\ttotal: 2m 33s\tremaining: 2m 34s\n",
      "324: learn: 0.1506444\ttotal: 2m 33s\tremaining: 2m 33s\n",
      "325: learn: 0.150641\ttotal: 2m 34s\tremaining: 2m 33s\n",
      "326: learn: 0.1506309\ttotal: 2m 34s\tremaining: 2m 32s\n",
      "327: learn: 0.1506245\ttotal: 2m 34s\tremaining: 2m 32s\n",
      "328: learn: 0.1506162\ttotal: 2m 35s\tremaining: 2m 31s\n",
      "329: learn: 0.1506086\ttotal: 2m 36s\tremaining: 2m 31s\n",
      "330: learn: 0.1506028\ttotal: 2m 37s\tremaining: 2m 31s\n",
      "331: learn: 0.1505969\ttotal: 2m 37s\tremaining: 2m 31s\n",
      "332: learn: 0.1505938\ttotal: 2m 38s\tremaining: 2m 30s\n",
      "333: learn: 0.1505873\ttotal: 2m 38s\tremaining: 2m 30s\n",
      "334: learn: 0.1505818\ttotal: 2m 39s\tremaining: 2m 29s\n",
      "335: learn: 0.150577\ttotal: 2m 39s\tremaining: 2m 29s\n",
      "336: learn: 0.1505726\ttotal: 2m 40s\tremaining: 2m 28s\n",
      "337: learn: 0.1505694\ttotal: 2m 40s\tremaining: 2m 28s\n",
      "338: learn: 0.1505638\ttotal: 2m 41s\tremaining: 2m 27s\n",
      "339: learn: 0.1505586\ttotal: 2m 41s\tremaining: 2m 27s\n",
      "340: learn: 0.1505546\ttotal: 2m 42s\tremaining: 2m 26s\n",
      "341: learn: 0.1505511\ttotal: 2m 42s\tremaining: 2m 26s\n",
      "342: learn: 0.1505428\ttotal: 2m 43s\tremaining: 2m 26s\n",
      "343: learn: 0.1505309\ttotal: 2m 43s\tremaining: 2m 25s\n",
      "344: learn: 0.1505261\ttotal: 2m 44s\tremaining: 2m 25s\n",
      "345: learn: 0.150518\ttotal: 2m 44s\tremaining: 2m 24s\n",
      "346: learn: 0.1505115\ttotal: 2m 45s\tremaining: 2m 24s\n",
      "347: learn: 0.1505076\ttotal: 2m 45s\tremaining: 2m 23s\n",
      "348: learn: 0.1505017\ttotal: 2m 46s\tremaining: 2m 23s\n",
      "349: learn: 0.1504955\ttotal: 2m 46s\tremaining: 2m 22s\n",
      "350: learn: 0.1504952\ttotal: 2m 46s\tremaining: 2m 22s\n",
      "351: learn: 0.1504889\ttotal: 2m 47s\tremaining: 2m 21s\n",
      "352: learn: 0.1504847\ttotal: 2m 47s\tremaining: 2m 21s\n",
      "353: learn: 0.1504791\ttotal: 2m 48s\tremaining: 2m 20s\n",
      "354: learn: 0.1504687\ttotal: 2m 48s\tremaining: 2m 20s\n",
      "355: learn: 0.150462\ttotal: 2m 49s\tremaining: 2m 19s\n",
      "356: learn: 0.1504537\ttotal: 2m 49s\tremaining: 2m 19s\n",
      "357: learn: 0.1504497\ttotal: 2m 50s\tremaining: 2m 18s\n",
      "358: learn: 0.1504447\ttotal: 2m 50s\tremaining: 2m 18s\n",
      "359: learn: 0.1504369\ttotal: 2m 51s\tremaining: 2m 17s\n",
      "360: learn: 0.1504292\ttotal: 2m 51s\tremaining: 2m 17s\n",
      "361: learn: 0.1504204\ttotal: 2m 52s\tremaining: 2m 16s\n",
      "362: learn: 0.150414\ttotal: 2m 52s\tremaining: 2m 16s\n",
      "363: learn: 0.1504024\ttotal: 2m 52s\tremaining: 2m 15s\n",
      "364: learn: 0.1503969\ttotal: 2m 53s\tremaining: 2m 15s\n",
      "365: learn: 0.1503916\ttotal: 2m 53s\tremaining: 2m 14s\n",
      "366: learn: 0.1503854\ttotal: 2m 54s\tremaining: 2m 14s\n",
      "367: learn: 0.1503775\ttotal: 2m 54s\tremaining: 2m 14s\n",
      "368: learn: 0.1503719\ttotal: 2m 55s\tremaining: 2m 13s\n",
      "369: learn: 0.1503673\ttotal: 2m 55s\tremaining: 2m 13s\n",
      "370: learn: 0.1503597\ttotal: 2m 56s\tremaining: 2m 12s\n",
      "371: learn: 0.1503541\ttotal: 2m 56s\tremaining: 2m 12s\n",
      "372: learn: 0.1503446\ttotal: 2m 57s\tremaining: 2m 11s\n",
      "373: learn: 0.1503389\ttotal: 2m 57s\tremaining: 2m 11s\n",
      "374: learn: 0.1503321\ttotal: 2m 58s\tremaining: 2m 10s\n",
      "375: learn: 0.1503263\ttotal: 2m 58s\tremaining: 2m 10s\n",
      "376: learn: 0.1503213\ttotal: 2m 59s\tremaining: 2m 9s\n",
      "377: learn: 0.1503176\ttotal: 2m 59s\tremaining: 2m 9s\n",
      "378: learn: 0.1503146\ttotal: 3m\tremaining: 2m 8s\n",
      "379: learn: 0.150308\ttotal: 3m\tremaining: 2m 8s\n",
      "380: learn: 0.1503077\ttotal: 3m 1s\tremaining: 2m 7s\n",
      "381: learn: 0.1503014\ttotal: 3m 1s\tremaining: 2m 7s\n",
      "382: learn: 0.1502929\ttotal: 3m 2s\tremaining: 2m 6s\n",
      "383: learn: 0.1502833\ttotal: 3m 2s\tremaining: 2m 6s\n",
      "384: learn: 0.1502777\ttotal: 3m 3s\tremaining: 2m 6s\n",
      "385: learn: 0.1502717\ttotal: 3m 3s\tremaining: 2m 5s\n",
      "386: learn: 0.1502683\ttotal: 3m 4s\tremaining: 2m 5s\n",
      "387: learn: 0.1502572\ttotal: 3m 4s\tremaining: 2m 4s\n",
      "388: learn: 0.1502504\ttotal: 3m 5s\tremaining: 2m 4s\n",
      "389: learn: 0.1502405\ttotal: 3m 5s\tremaining: 2m 3s\n",
      "390: learn: 0.1502326\ttotal: 3m 6s\tremaining: 2m 3s\n",
      "391: learn: 0.1502277\ttotal: 3m 6s\tremaining: 2m 2s\n",
      "392: learn: 0.1502239\ttotal: 3m 6s\tremaining: 2m 2s\n",
      "393: learn: 0.1502182\ttotal: 3m 7s\tremaining: 2m 1s\n",
      "394: learn: 0.1502145\ttotal: 3m 7s\tremaining: 2m 1s\n",
      "395: learn: 0.1502077\ttotal: 3m 8s\tremaining: 2m\n",
      "396: learn: 0.1502058\ttotal: 3m 8s\tremaining: 2m\n",
      "397: learn: 0.1502027\ttotal: 3m 9s\tremaining: 1m 59s\n",
      "398: learn: 0.1501963\ttotal: 3m 9s\tremaining: 1m 59s\n",
      "399: learn: 0.1501901\ttotal: 3m 10s\tremaining: 1m 58s\n",
      "400: learn: 0.1501839\ttotal: 3m 10s\tremaining: 1m 58s\n",
      "401: learn: 0.1501785\ttotal: 3m 11s\tremaining: 1m 57s\n",
      "402: learn: 0.1501724\ttotal: 3m 11s\tremaining: 1m 57s\n",
      "403: learn: 0.1501664\ttotal: 3m 12s\tremaining: 1m 56s\n",
      "404: learn: 0.1501609\ttotal: 3m 12s\tremaining: 1m 56s\n",
      "405: learn: 0.1501571\ttotal: 3m 13s\tremaining: 1m 56s\n",
      "406: learn: 0.1501491\ttotal: 3m 13s\tremaining: 1m 55s\n",
      "407: learn: 0.1501408\ttotal: 3m 14s\tremaining: 1m 55s\n",
      "408: learn: 0.1501366\ttotal: 3m 14s\tremaining: 1m 54s\n",
      "409: learn: 0.1501294\ttotal: 3m 14s\tremaining: 1m 54s\n",
      "410: learn: 0.1501253\ttotal: 3m 15s\tremaining: 1m 53s\n",
      "411: learn: 0.1501153\ttotal: 3m 15s\tremaining: 1m 53s\n",
      "412: learn: 0.1501091\ttotal: 3m 16s\tremaining: 1m 52s\n",
      "413: learn: 0.1501021\ttotal: 3m 16s\tremaining: 1m 52s\n",
      "414: learn: 0.1500965\ttotal: 3m 17s\tremaining: 1m 51s\n",
      "415: learn: 0.1500919\ttotal: 3m 17s\tremaining: 1m 51s\n",
      "416: learn: 0.1500873\ttotal: 3m 18s\tremaining: 1m 50s\n",
      "417: learn: 0.150084\ttotal: 3m 18s\tremaining: 1m 50s\n",
      "418: learn: 0.1500784\ttotal: 3m 18s\tremaining: 1m 49s\n",
      "419: learn: 0.1500754\ttotal: 3m 19s\tremaining: 1m 49s\n",
      "420: learn: 0.150068\ttotal: 3m 19s\tremaining: 1m 48s\n",
      "421: learn: 0.1500612\ttotal: 3m 20s\tremaining: 1m 48s\n",
      "422: learn: 0.1500582\ttotal: 3m 20s\tremaining: 1m 47s\n",
      "423: learn: 0.1500487\ttotal: 3m 21s\tremaining: 1m 47s\n",
      "424: learn: 0.1500443\ttotal: 3m 21s\tremaining: 1m 46s\n",
      "425: learn: 0.1500385\ttotal: 3m 21s\tremaining: 1m 46s\n",
      "426: learn: 0.1500359\ttotal: 3m 22s\tremaining: 1m 45s\n",
      "427: learn: 0.1500308\ttotal: 3m 22s\tremaining: 1m 45s\n",
      "428: learn: 0.150026\ttotal: 3m 23s\tremaining: 1m 44s\n",
      "429: learn: 0.1500154\ttotal: 3m 23s\tremaining: 1m 44s\n",
      "430: learn: 0.1500107\ttotal: 3m 24s\tremaining: 1m 43s\n",
      "431: learn: 0.1500029\ttotal: 3m 24s\tremaining: 1m 43s\n",
      "432: learn: 0.1499978\ttotal: 3m 24s\tremaining: 1m 42s\n",
      "433: learn: 0.149994\ttotal: 3m 25s\tremaining: 1m 42s\n",
      "434: learn: 0.1499897\ttotal: 3m 25s\tremaining: 1m 41s\n",
      "435: learn: 0.1499853\ttotal: 3m 26s\tremaining: 1m 41s\n",
      "436: learn: 0.1499825\ttotal: 3m 26s\tremaining: 1m 40s\n",
      "437: learn: 0.1499787\ttotal: 3m 27s\tremaining: 1m 40s\n",
      "438: learn: 0.1499736\ttotal: 3m 27s\tremaining: 1m 39s\n",
      "439: learn: 0.1499683\ttotal: 3m 27s\tremaining: 1m 39s\n",
      "440: learn: 0.1499613\ttotal: 3m 28s\tremaining: 1m 38s\n",
      "441: learn: 0.149958\ttotal: 3m 28s\tremaining: 1m 38s\n",
      "442: learn: 0.149952\ttotal: 3m 29s\tremaining: 1m 37s\n",
      "443: learn: 0.1499473\ttotal: 3m 30s\tremaining: 1m 37s\n",
      "444: learn: 0.1499445\ttotal: 3m 30s\tremaining: 1m 36s\n",
      "445: learn: 0.1499382\ttotal: 3m 31s\tremaining: 1m 36s\n",
      "446: learn: 0.1499309\ttotal: 3m 31s\tremaining: 1m 36s\n",
      "447: learn: 0.1499238\ttotal: 3m 31s\tremaining: 1m 35s\n",
      "448: learn: 0.1499168\ttotal: 3m 32s\tremaining: 1m 35s\n",
      "449: learn: 0.149914\ttotal: 3m 32s\tremaining: 1m 34s\n",
      "450: learn: 0.1499084\ttotal: 3m 33s\tremaining: 1m 34s\n",
      "451: learn: 0.1499047\ttotal: 3m 34s\tremaining: 1m 33s\n",
      "452: learn: 0.1498975\ttotal: 3m 34s\tremaining: 1m 33s\n",
      "453: learn: 0.1498891\ttotal: 3m 34s\tremaining: 1m 32s\n",
      "454: learn: 0.1498823\ttotal: 3m 35s\tremaining: 1m 32s\n",
      "455: learn: 0.1498802\ttotal: 3m 35s\tremaining: 1m 31s\n",
      "456: learn: 0.1498745\ttotal: 3m 36s\tremaining: 1m 31s\n",
      "457: learn: 0.1498681\ttotal: 3m 36s\tremaining: 1m 30s\n",
      "458: learn: 0.1498647\ttotal: 3m 37s\tremaining: 1m 30s\n",
      "459: learn: 0.1498623\ttotal: 3m 37s\tremaining: 1m 29s\n",
      "460: learn: 0.1498579\ttotal: 3m 38s\tremaining: 1m 29s\n",
      "461: learn: 0.1498527\ttotal: 3m 38s\tremaining: 1m 29s\n",
      "462: learn: 0.1498469\ttotal: 3m 39s\tremaining: 1m 28s\n",
      "463: learn: 0.1498447\ttotal: 3m 39s\tremaining: 1m 28s\n",
      "464: learn: 0.1498343\ttotal: 3m 40s\tremaining: 1m 27s\n",
      "465: learn: 0.1498314\ttotal: 3m 41s\tremaining: 1m 27s\n",
      "466: learn: 0.1498264\ttotal: 3m 41s\tremaining: 1m 26s\n",
      "467: learn: 0.1498205\ttotal: 3m 42s\tremaining: 1m 26s\n",
      "468: learn: 0.1498144\ttotal: 3m 42s\tremaining: 1m 25s\n",
      "469: learn: 0.1498055\ttotal: 3m 42s\tremaining: 1m 25s\n",
      "470: learn: 0.1498041\ttotal: 3m 43s\tremaining: 1m 24s\n",
      "471: learn: 0.1497943\ttotal: 3m 43s\tremaining: 1m 24s\n",
      "472: learn: 0.1497886\ttotal: 3m 44s\tremaining: 1m 23s\n",
      "473: learn: 0.1497848\ttotal: 3m 44s\tremaining: 1m 23s\n",
      "474: learn: 0.1497823\ttotal: 3m 45s\tremaining: 1m 22s\n",
      "475: learn: 0.1497786\ttotal: 3m 45s\tremaining: 1m 22s\n",
      "476: learn: 0.1497751\ttotal: 3m 46s\tremaining: 1m 22s\n",
      "477: learn: 0.1497708\ttotal: 3m 46s\tremaining: 1m 21s\n",
      "478: learn: 0.1497664\ttotal: 3m 47s\tremaining: 1m 21s\n",
      "479: learn: 0.1497629\ttotal: 3m 47s\tremaining: 1m 20s\n",
      "480: learn: 0.1497567\ttotal: 3m 48s\tremaining: 1m 20s\n",
      "481: learn: 0.1497516\ttotal: 3m 48s\tremaining: 1m 19s\n",
      "482: learn: 0.1497437\ttotal: 3m 48s\tremaining: 1m 19s\n",
      "483: learn: 0.1497355\ttotal: 3m 49s\tremaining: 1m 18s\n",
      "484: learn: 0.1497345\ttotal: 3m 49s\tremaining: 1m 18s\n",
      "485: learn: 0.1497271\ttotal: 3m 50s\tremaining: 1m 17s\n",
      "486: learn: 0.1497212\ttotal: 3m 50s\tremaining: 1m 17s\n",
      "487: learn: 0.149718\ttotal: 3m 51s\tremaining: 1m 16s\n",
      "488: learn: 0.1497126\ttotal: 3m 51s\tremaining: 1m 16s\n",
      "489: learn: 0.1497078\ttotal: 3m 52s\tremaining: 1m 15s\n",
      "490: learn: 0.1497071\ttotal: 3m 52s\tremaining: 1m 15s\n",
      "491: learn: 0.1496994\ttotal: 3m 53s\tremaining: 1m 14s\n",
      "492: learn: 0.1496958\ttotal: 3m 53s\tremaining: 1m 14s\n",
      "493: learn: 0.1496914\ttotal: 3m 54s\tremaining: 1m 13s\n",
      "494: learn: 0.1496867\ttotal: 3m 54s\tremaining: 1m 13s\n",
      "495: learn: 0.1496773\ttotal: 3m 54s\tremaining: 1m 12s\n",
      "496: learn: 0.1496708\ttotal: 3m 55s\tremaining: 1m 12s\n",
      "497: learn: 0.1496637\ttotal: 3m 55s\tremaining: 1m 12s\n",
      "498: learn: 0.1496599\ttotal: 3m 56s\tremaining: 1m 11s\n",
      "499: learn: 0.1496572\ttotal: 3m 56s\tremaining: 1m 11s\n",
      "500: learn: 0.1496518\ttotal: 3m 57s\tremaining: 1m 10s\n",
      "501: learn: 0.1496475\ttotal: 3m 57s\tremaining: 1m 10s\n",
      "502: learn: 0.149642\ttotal: 3m 58s\tremaining: 1m 9s\n",
      "503: learn: 0.1496378\ttotal: 3m 58s\tremaining: 1m 9s\n",
      "504: learn: 0.1496315\ttotal: 3m 59s\tremaining: 1m 8s\n",
      "505: learn: 0.149626\ttotal: 3m 59s\tremaining: 1m 8s\n",
      "506: learn: 0.1496203\ttotal: 4m\tremaining: 1m 7s\n",
      "507: learn: 0.1496157\ttotal: 4m\tremaining: 1m 7s\n",
      "508: learn: 0.1496111\ttotal: 4m\tremaining: 1m 6s\n",
      "509: learn: 0.1496057\ttotal: 4m 1s\tremaining: 1m 6s\n",
      "510: learn: 0.1496022\ttotal: 4m 1s\tremaining: 1m 5s\n",
      "511: learn: 0.1496013\ttotal: 4m 2s\tremaining: 1m 5s\n",
      "512: learn: 0.1495946\ttotal: 4m 2s\tremaining: 1m 4s\n",
      "513: learn: 0.1495876\ttotal: 4m 3s\tremaining: 1m 4s\n",
      "514: learn: 0.1495815\ttotal: 4m 3s\tremaining: 1m 3s\n",
      "515: learn: 0.1495736\ttotal: 4m 3s\tremaining: 1m 3s\n",
      "516: learn: 0.1495677\ttotal: 4m 4s\tremaining: 1m 2s\n",
      "517: learn: 0.1495604\ttotal: 4m 4s\tremaining: 1m 2s\n",
      "518: learn: 0.1495572\ttotal: 4m 5s\tremaining: 1m 1s\n",
      "519: learn: 0.149549\ttotal: 4m 5s\tremaining: 1m 1s\n",
      "520: learn: 0.1495415\ttotal: 4m 6s\tremaining: 1m\n",
      "521: learn: 0.1495363\ttotal: 4m 6s\tremaining: 1m\n",
      "522: learn: 0.1495307\ttotal: 4m 7s\tremaining: 60s\n",
      "523: learn: 0.1495243\ttotal: 4m 7s\tremaining: 59.5s\n",
      "524: learn: 0.1495201\ttotal: 4m 7s\tremaining: 59s\n",
      "525: learn: 0.149514\ttotal: 4m 8s\tremaining: 58.6s\n",
      "526: learn: 0.1495084\ttotal: 4m 8s\tremaining: 58.1s\n",
      "527: learn: 0.1495013\ttotal: 4m 9s\tremaining: 57.6s\n",
      "528: learn: 0.1494935\ttotal: 4m 9s\tremaining: 57.1s\n",
      "529: learn: 0.1494912\ttotal: 4m 10s\tremaining: 56.6s\n",
      "530: learn: 0.1494836\ttotal: 4m 10s\tremaining: 56.2s\n",
      "531: learn: 0.1494757\ttotal: 4m 11s\tremaining: 55.7s\n",
      "532: learn: 0.1494722\ttotal: 4m 11s\tremaining: 55.2s\n",
      "533: learn: 0.1494697\ttotal: 4m 11s\tremaining: 54.7s\n",
      "534: learn: 0.1494658\ttotal: 4m 12s\tremaining: 54.2s\n",
      "535: learn: 0.1494607\ttotal: 4m 12s\tremaining: 53.7s\n",
      "536: learn: 0.149456\ttotal: 4m 13s\tremaining: 53.3s\n",
      "537: learn: 0.1494488\ttotal: 4m 13s\tremaining: 52.8s\n",
      "538: learn: 0.149447\ttotal: 4m 14s\tremaining: 52.3s\n",
      "539: learn: 0.1494451\ttotal: 4m 14s\tremaining: 51.8s\n",
      "540: learn: 0.1494396\ttotal: 4m 14s\tremaining: 51.4s\n",
      "541: learn: 0.1494332\ttotal: 4m 15s\tremaining: 50.9s\n",
      "542: learn: 0.1494281\ttotal: 4m 15s\tremaining: 50.4s\n",
      "543: learn: 0.1494239\ttotal: 4m 16s\tremaining: 49.9s\n",
      "544: learn: 0.149422\ttotal: 4m 16s\tremaining: 49.4s\n",
      "545: learn: 0.1494167\ttotal: 4m 17s\tremaining: 49s\n",
      "546: learn: 0.1494155\ttotal: 4m 17s\tremaining: 48.5s\n",
      "547: learn: 0.1494108\ttotal: 4m 17s\tremaining: 48s\n",
      "548: learn: 0.1494042\ttotal: 4m 18s\tremaining: 47.6s\n",
      "549: learn: 0.1493991\ttotal: 4m 19s\tremaining: 47.1s\n",
      "550: learn: 0.1493904\ttotal: 4m 19s\tremaining: 46.6s\n",
      "551: learn: 0.1493871\ttotal: 4m 20s\tremaining: 46.2s\n",
      "552: learn: 0.1493805\ttotal: 4m 20s\tremaining: 45.7s\n",
      "553: learn: 0.1493755\ttotal: 4m 21s\tremaining: 45.3s\n",
      "554: learn: 0.1493683\ttotal: 4m 21s\tremaining: 44.8s\n",
      "555: learn: 0.1493613\ttotal: 4m 22s\tremaining: 44.3s\n",
      "556: learn: 0.1493606\ttotal: 4m 22s\tremaining: 43.9s\n",
      "557: learn: 0.1493582\ttotal: 4m 23s\tremaining: 43.4s\n",
      "558: learn: 0.1493528\ttotal: 4m 23s\tremaining: 42.9s\n",
      "559: learn: 0.1493493\ttotal: 4m 24s\tremaining: 42.5s\n",
      "560: learn: 0.1493459\ttotal: 4m 24s\tremaining: 42s\n",
      "561: learn: 0.1493393\ttotal: 4m 25s\tremaining: 41.5s\n",
      "562: learn: 0.1493351\ttotal: 4m 25s\tremaining: 41s\n",
      "563: learn: 0.1493303\ttotal: 4m 26s\tremaining: 40.6s\n",
      "564: learn: 0.1493276\ttotal: 4m 26s\tremaining: 40.1s\n",
      "565: learn: 0.1493212\ttotal: 4m 27s\tremaining: 39.6s\n",
      "566: learn: 0.1493184\ttotal: 4m 27s\tremaining: 39.2s\n",
      "567: learn: 0.1493105\ttotal: 4m 28s\tremaining: 38.7s\n",
      "568: learn: 0.1493068\ttotal: 4m 28s\tremaining: 38.3s\n",
      "569: learn: 0.1493047\ttotal: 4m 29s\tremaining: 37.8s\n",
      "570: learn: 0.1492997\ttotal: 4m 29s\tremaining: 37.3s\n",
      "571: learn: 0.1492957\ttotal: 4m 30s\tremaining: 36.9s\n",
      "572: learn: 0.1492922\ttotal: 4m 30s\tremaining: 36.4s\n",
      "573: learn: 0.1492835\ttotal: 4m 31s\tremaining: 35.9s\n",
      "574: learn: 0.149278\ttotal: 4m 31s\tremaining: 35.4s\n",
      "575: learn: 0.1492739\ttotal: 4m 32s\tremaining: 35s\n",
      "576: learn: 0.1492676\ttotal: 4m 32s\tremaining: 34.5s\n",
      "577: learn: 0.1492627\ttotal: 4m 33s\tremaining: 34s\n",
      "578: learn: 0.1492564\ttotal: 4m 33s\tremaining: 33.6s\n",
      "579: learn: 0.1492543\ttotal: 4m 34s\tremaining: 33.1s\n",
      "580: learn: 0.1492525\ttotal: 4m 34s\tremaining: 32.6s\n",
      "581: learn: 0.1492489\ttotal: 4m 35s\tremaining: 32.2s\n",
      "582: learn: 0.1492433\ttotal: 4m 35s\tremaining: 31.7s\n",
      "583: learn: 0.1492408\ttotal: 4m 36s\tremaining: 31.2s\n",
      "584: learn: 0.1492361\ttotal: 4m 36s\tremaining: 30.8s\n",
      "585: learn: 0.1492316\ttotal: 4m 37s\tremaining: 30.3s\n",
      "586: learn: 0.149227\ttotal: 4m 37s\tremaining: 29.8s\n",
      "587: learn: 0.1492224\ttotal: 4m 38s\tremaining: 29.3s\n",
      "588: learn: 0.1492165\ttotal: 4m 38s\tremaining: 28.8s\n",
      "589: learn: 0.1492118\ttotal: 4m 38s\tremaining: 28.4s\n",
      "590: learn: 0.1492073\ttotal: 4m 39s\tremaining: 27.9s\n",
      "591: learn: 0.1492032\ttotal: 4m 39s\tremaining: 27.4s\n",
      "592: learn: 0.149199\ttotal: 4m 40s\tremaining: 26.9s\n",
      "593: learn: 0.1491896\ttotal: 4m 40s\tremaining: 26.5s\n",
      "594: learn: 0.1491826\ttotal: 4m 41s\tremaining: 26s\n",
      "595: learn: 0.1491748\ttotal: 4m 41s\tremaining: 25.5s\n",
      "596: learn: 0.1491697\ttotal: 4m 41s\tremaining: 25s\n",
      "597: learn: 0.1491657\ttotal: 4m 42s\tremaining: 24.6s\n",
      "598: learn: 0.1491589\ttotal: 4m 42s\tremaining: 24.1s\n",
      "599: learn: 0.1491524\ttotal: 4m 43s\tremaining: 23.6s\n",
      "600: learn: 0.1491488\ttotal: 4m 43s\tremaining: 23.1s\n",
      "601: learn: 0.1491443\ttotal: 4m 44s\tremaining: 22.7s\n",
      "602: learn: 0.1491393\ttotal: 4m 44s\tremaining: 22.2s\n",
      "603: learn: 0.1491371\ttotal: 4m 45s\tremaining: 21.7s\n",
      "604: learn: 0.1491321\ttotal: 4m 45s\tremaining: 21.3s\n",
      "605: learn: 0.1491296\ttotal: 4m 46s\tremaining: 20.8s\n",
      "606: learn: 0.1491225\ttotal: 4m 46s\tremaining: 20.3s\n",
      "607: learn: 0.1491178\ttotal: 4m 47s\tremaining: 19.8s\n",
      "608: learn: 0.1491105\ttotal: 4m 47s\tremaining: 19.4s\n",
      "609: learn: 0.1491022\ttotal: 4m 48s\tremaining: 18.9s\n",
      "610: learn: 0.1490979\ttotal: 4m 48s\tremaining: 18.4s\n",
      "611: learn: 0.1490949\ttotal: 4m 49s\tremaining: 18s\n",
      "612: learn: 0.1490927\ttotal: 4m 49s\tremaining: 17.5s\n",
      "613: learn: 0.1490872\ttotal: 4m 50s\tremaining: 17s\n",
      "614: learn: 0.1490835\ttotal: 4m 50s\tremaining: 16.6s\n",
      "615: learn: 0.1490714\ttotal: 4m 51s\tremaining: 16.1s\n",
      "616: learn: 0.1490673\ttotal: 4m 51s\tremaining: 15.6s\n",
      "617: learn: 0.1490613\ttotal: 4m 52s\tremaining: 15.1s\n",
      "618: learn: 0.1490538\ttotal: 4m 52s\tremaining: 14.7s\n",
      "619: learn: 0.1490495\ttotal: 4m 53s\tremaining: 14.2s\n",
      "620: learn: 0.1490405\ttotal: 4m 53s\tremaining: 13.7s\n",
      "621: learn: 0.1490365\ttotal: 4m 54s\tremaining: 13.2s\n",
      "622: learn: 0.1490325\ttotal: 4m 54s\tremaining: 12.8s\n",
      "623: learn: 0.1490314\ttotal: 4m 55s\tremaining: 12.3s\n",
      "624: learn: 0.1490292\ttotal: 4m 55s\tremaining: 11.8s\n",
      "625: learn: 0.1490227\ttotal: 4m 56s\tremaining: 11.4s\n",
      "626: learn: 0.1490155\ttotal: 4m 56s\tremaining: 10.9s\n",
      "627: learn: 0.1490074\ttotal: 4m 57s\tremaining: 10.4s\n",
      "628: learn: 0.1490031\ttotal: 4m 57s\tremaining: 9.94s\n",
      "629: learn: 0.149\ttotal: 4m 58s\tremaining: 9.47s\n",
      "630: learn: 0.1489952\ttotal: 4m 58s\tremaining: 9s\n",
      "631: learn: 0.1489921\ttotal: 4m 59s\tremaining: 8.53s\n",
      "632: learn: 0.1489887\ttotal: 5m\tremaining: 8.06s\n",
      "633: learn: 0.1489847\ttotal: 5m\tremaining: 7.58s\n",
      "634: learn: 0.1489806\ttotal: 5m 1s\tremaining: 7.11s\n",
      "635: learn: 0.148977\ttotal: 5m 1s\tremaining: 6.64s\n",
      "636: learn: 0.1489745\ttotal: 5m 2s\tremaining: 6.16s\n",
      "637: learn: 0.1489702\ttotal: 5m 2s\tremaining: 5.69s\n",
      "638: learn: 0.1489657\ttotal: 5m 3s\tremaining: 5.22s\n",
      "639: learn: 0.1489613\ttotal: 5m 3s\tremaining: 4.74s\n",
      "640: learn: 0.1489583\ttotal: 5m 4s\tremaining: 4.27s\n",
      "641: learn: 0.1489537\ttotal: 5m 4s\tremaining: 3.79s\n",
      "642: learn: 0.1489509\ttotal: 5m 5s\tremaining: 3.32s\n",
      "643: learn: 0.1489467\ttotal: 5m 5s\tremaining: 2.85s\n",
      "644: learn: 0.1489411\ttotal: 5m 6s\tremaining: 2.37s\n",
      "645: learn: 0.1489372\ttotal: 5m 6s\tremaining: 1.9s\n",
      "646: learn: 0.148931\ttotal: 5m 7s\tremaining: 1.42s\n",
      "647: learn: 0.1489291\ttotal: 5m 7s\tremaining: 950ms\n",
      "648: learn: 0.1489229\ttotal: 5m 8s\tremaining: 475ms\n",
      "649: learn: 0.1489183\ttotal: 5m 8s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core._CatBoostBase at 0x110bed850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gini score=  0.285913088474\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "y_pred= cb.predict_proba(X_test)[:,1]\n",
    "print 'Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
