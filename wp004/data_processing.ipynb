{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group columns by type\n",
    "colnames= map(lambda x: str(x),df.columns.values)\n",
    "id_col= colnames[0]\n",
    "target_col= colnames[1]\n",
    "cat_cols= filter(lambda x: '_cat' in x,colnames)\n",
    "bin_cols= filter(lambda x: '_bin' in x,colnames)\n",
    "num_cols= filter(lambda x: ('_cat' not in x) and ('_bin' not in x) and x not in [id_col,target_col] ,\n",
    "                colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cut bad fields, based on kernel discussions\n",
    "bin_cols.remove('ps_ind_12_bin')\n",
    "df.drop('ps_ind_12_bin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove uninformative of noisy shadow features\n",
    "shadows= ['ps_car_11_cat',       \n",
    "            'ps_calc_14',        \n",
    "            'ps_calc_11',         \n",
    "            'ps_calc_06',           \n",
    "            'ps_calc_16_bin',       \n",
    "            'ps_calc_19_bin',       \n",
    "            'ps_calc_20_bin',     \n",
    "            'ps_calc_15_bin',      \n",
    "            'ps_ind_11_bin',       \n",
    "            'ps_ind_10_bin']\n",
    "for s in shadows:\n",
    "    if s in bin_cols:\n",
    "        bin_cols.remove(s)\n",
    "    elif s in num_cols:\n",
    "        num_cols.remove(s)\n",
    "    elif s in cat_cols:\n",
    "        cat_cols.remove(s)\n",
    "    df.drop(s,axis=1,inplace=True)\n",
    "    \n",
    "for c in df.columns:\n",
    "    if 'calc' in c:\n",
    "        df.drop(c,axis=1,inplace=True)\n",
    "        if c in bin_cols:\n",
    "            bin_cols.remove(c)\n",
    "        elif c in num_cols:\n",
    "            num_cols.remove(c)\n",
    "        elif c in cat_cols:\n",
    "            cat_cols.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split train and test\n",
    "import sklearn.cross_validation\n",
    "#train= range(len(df[target_col].values))\n",
    "train,test= sklearn.cross_validation.train_test_split(range(df[target_col].count()),test_size= 0.33,random_state=0)\n",
    "\n",
    "train_df= df.loc[train,:]\n",
    "test_df= df.loc[test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add some extra features\n",
    "train_df = train_df.replace(-1, np.NaN)\n",
    "d_median = train_df.median(axis=0)\n",
    "d_mean = train_df.mean(axis=0)\n",
    "train_df = train_df.fillna(-1)\n",
    "\n",
    "def transform_df(indf):\n",
    "    indf = pd.DataFrame(indf)\n",
    "    dcol = [c for c in indf.columns if c not in ['id','target']]\n",
    "    indf['ps_car_13_x_ps_reg_03'] = indf['ps_car_13'] * indf['ps_reg_03']\n",
    "    indf['negative_one_vals'] = np.sum((indf[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            indf[c+str('_median_range')] = (indf[c].values > d_median[c]).astype(np.int)\n",
    "            indf[c+str('_mean_range')] = (indf[c].values > d_mean[c]).astype(np.int)\n",
    "    return indf\n",
    "\n",
    "# def transform_df(df):\n",
    "#     df = pd.DataFrame(df)\n",
    "#     dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "#     df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "#     df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "#     for c in dcol:\n",
    "#         if '_bin' not in c: #standard arithmetic\n",
    "#             df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "#             df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "#     return df\n",
    "\n",
    "train_df= transform_df(train_df)\n",
    "test_df= transform_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: implement a class prevalence vectorizer for categoricals, to be used in processing some columns \n",
    "# and in understanding field importance\n",
    "\n",
    "class prevalence_vectorizer:\n",
    "    def __init__(self,field_list):\n",
    "        self.field_list= field_list\n",
    "        self.vectorizer= {}\n",
    "        for f in field_list:\n",
    "            self.vectorizer[f]= {}\n",
    "        return None\n",
    "    \n",
    "    def train(self,df,labelcol):\n",
    "        data_fields= map(lambda x: str(x),df.columns)\n",
    "        for f in self.field_list:\n",
    "            if f in data_fields:\n",
    "                self.vectorizer[f]= {}\n",
    "                grps= df.groupby(f).apply(lambda x: float(np.sum(x[labelcol])) / len(x[labelcol]) )\n",
    "                for g in grps.index.values:\n",
    "                    self.vectorizer[f][g]= grps[g]\n",
    "            else:\n",
    "                print 'Warning: field '+f+' not in train data'\n",
    "        return None\n",
    "    \n",
    "    def parse(self,vec,field_name):\n",
    "        if field_name in self.field_list:\n",
    "            return map(lambda x: self.vectorizer[field_name][x],vec)\n",
    "        else:\n",
    "            print field_name + ' not in vectorizer. Available fields: '+ self.field_list\n",
    "            raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing plan: \n",
    "- cut rows with missing ps_car_11 and ps_car_12\n",
    "- Normalize all numerics, except: [ps_car_14 and ps_reg_03]\n",
    "- For [ps_car_14 and ps_reg_03], bin and convert to class prevalence (future work: fit for the missing values?)\n",
    "- Treat categoricals: dict vectorize, except for: \n",
    "     [ps_car_11_cat, ps_car_06_cat, ps_car_04_cat, ps_car_01_cat, ps_car_09_cat, ps_ind_05_cat], which we turn into class prevalence rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: better treatment of: [ps_car_14 and ps_reg_03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toPrevalate= ['ps_car_06_cat','ps_car_01_cat']\n",
    "toOneHot= filter(lambda x: x not in toPrevalate,cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot encoder\n",
    "import sklearn.preprocessing\n",
    "enc= sklearn.preprocessing.OneHotEncoder(sparse= False)\n",
    "X_train_onehot= enc.fit_transform( train_df.loc[:,toOneHot].as_matrix()+1.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prevalence vectorizer\n",
    "vectorizer= prevalence_vectorizer(toPrevalate)\n",
    "vectorizer.train(train_df.loc[:,toPrevalate + [target_col] ],target_col)\n",
    "\n",
    "X_train_prevalence= np.zeros([len(train),len(toPrevalate)])\n",
    "i=0\n",
    "for c in toPrevalate:\n",
    "    X_train_prevalence[:,i]= vectorizer.parse( train_df.loc[:,c].values, c ) \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get means and stds for the columns in training set (for non-missing values)\n",
    "numerical_norms= {}\n",
    "for c in num_cols:\n",
    "    numerical_norms[c]= (train_df.loc[ train_df[c] >= 0, c].mean(),train_df.loc[ train_df[c] >= 0, c].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalise numerical fields <- TODO: better treatment of [ps_car_14 and ps_reg_03]\n",
    "X_train_numeric= np.zeros([len(train),len(num_cols)])\n",
    "i=0\n",
    "for c in num_cols:\n",
    "    X_train_numeric[:,i]= ( train_df[c].values - numerical_norms[c][0] ) / numerical_norms[c][1]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train= np.concatenate([ X_train_numeric, \n",
    "                          X_train_prevalence, \n",
    "                          X_train_onehot, \n",
    "                          train_df.loc[:,bin_cols].as_matrix() \n",
    "                        ],\n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(open('train_matrix.bin','wb'),X_train)\n",
    "np.save(open('train_labels.bin','wb'),train_df[target_col].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat encodings for test set (without fitting them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_onehot= enc.transform( test_df.loc[:,toOneHot].as_matrix()+1.0 )\n",
    "X_test_prevalence= np.zeros([len(test),len(toPrevalate)])\n",
    "i=0\n",
    "for c in toPrevalate:\n",
    "    X_test_prevalence[:,i]= vectorizer.parse( test_df.loc[:,c].values, c ) \n",
    "    i += 1\n",
    "X_test_numeric= np.zeros([len(test),len(num_cols)])\n",
    "i=0\n",
    "for c in num_cols:\n",
    "    X_test_numeric[:,i]= ( test_df[c].values - numerical_norms[c][0] ) / numerical_norms[c][1]\n",
    "    i+=1\n",
    "X_test= np.concatenate([ X_test_numeric, \n",
    "                          X_test_prevalence, \n",
    "                          X_test_onehot, \n",
    "                          test_df.loc[:,bin_cols].as_matrix() \n",
    "                        ],\n",
    "                        axis=1)\n",
    "np.save(open('test_matrix.bin','wb'),X_test)\n",
    "np.save(open('test_labels.bin','wb'),test_df[target_col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
