{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simpler modelling stack, where models have been pulled from the stack if they are not useful.  Strangely, the regularization on the top level of the stack must be light l1.  Produces 0.28966 in local test. Just over 0.285 on LB.  Position: 387 (386 was bottom of bronze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd,matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(array):\n",
    "    srtInd = array.argsort()\n",
    "    ranks = np.empty(len(array), float)\n",
    "    ranks[srtInd] = np.arange(len(array))\n",
    "    return ranks / float(len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, n_splits, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.pipelines= []\n",
    "        self.base_models= []\n",
    "        for x in base_models:\n",
    "            self.pipelines.append( x[0] )\n",
    "            self.base_models.append( x[1] )\n",
    "\n",
    "    def fit_predict(self, df_train, y, df_test):\n",
    "        y = np.array(y)\n",
    "\n",
    "        folds = StratifiedKFold(y,n_folds=self.n_splits, shuffle=True, random_state=2016)\n",
    "\n",
    "        S_train = np.zeros((len(df_train.index), len(self.base_models)))\n",
    "        S_test = np.zeros((len(df_test.index), len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            #\n",
    "            PIPELINE= self.pipelines[i]\n",
    "            #\n",
    "            S_test_i = np.zeros((len(df_test.index), self.n_splits))\n",
    "#             X_train, y_train, X_test, y_test= PIPELINE(df_train.copy(),df_test.copy())\n",
    "            #\n",
    "            for j, (train_idx, val_idx) in enumerate(folds):\n",
    "                #\n",
    "                X_train, y_train, X_holdout, y_holdout= PIPELINE(\n",
    "                    df_train.copy().loc[train_idx,:],\n",
    "                    df_train.copy().loc[val_idx,:]\n",
    "                )\n",
    "                _, _, X_test, y_test= PIPELINE(df_train.copy().loc[train_idx,:],df_test.copy()\n",
    "                )\n",
    "                #\n",
    "                print (\"Fit %s --> %s fold %d\" % (str(PIPELINE).split()[1],str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]              \n",
    "\n",
    "                S_train[val_idx, i] = y_pred\n",
    "                #\n",
    "                test_probs= clf.predict_proba(X_test)[:,1]\n",
    "                S_test_i[:, j] = np.log(test_probs) - np.log(1.0 - test_probs)\n",
    "            agg_lor= S_test_i.mean(axis=1)\n",
    "            S_test[:, i] = 1.0 / (1.0 + np.exp( -agg_lor) )\n",
    "        return pd.DataFrame(S_train,columns=['x_'+str(i) for i in range(np.shape(S_train)[1])]),pd.DataFrame(S_test,columns=['x_'+str(i) for i in range(np.shape(S_test)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add output of layer results ofr quick iteration\n",
    "class Stack:\n",
    "    def __init__(self,k_folds,hidden_layers,top_layer,saveInternalVectors=False):\n",
    "        self.saveInternalVectors= saveInternalVectors\n",
    "        self.layers= []\n",
    "        for h in hidden_layers:\n",
    "            self.layers.append( Layer(k_folds,h) )\n",
    "        self.top_layer= top_layer \n",
    "        return None\n",
    "    \n",
    "    def fit_predict(self,df_train,y,df_test,external_base_scores= None):\n",
    "        Xt_train= df_train\n",
    "        Xt_test= df_test\n",
    "        i= 1\n",
    "        for layer in self.layers:\n",
    "            print 'Fitting stack layer '+str(i)\n",
    "            Xt_train, Xt_test= layer.fit_predict(Xt_train,y,Xt_test)\n",
    "            Xt_train.loc[:,'target']= y\n",
    "            if external_base_scores is not None and i==1:\n",
    "                Xt_train.loc[:,'ext']= external_base_scores[0]\n",
    "                Xt_test.loc[:,'ext']= external_base_scores[1]\n",
    "#                 Xt_train= np.concatenate( (Xt_train,np.reshape(external_base_scores[0],\n",
    "#                                                                (np.shape(external_base_scores[0])[0],1))),\n",
    "#                                          axis=1)\n",
    "#                 Xt_test= np.concatenate( (Xt_test,np.reshape(external_base_scores[1],\n",
    "#                                                             (np.shape(external_base_scores[1])[0],1))), \n",
    "#                                         axis=1)\n",
    "            #\n",
    "            if self.saveInternalVectors:\n",
    "                fname= 'STACK_internal_train_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_train)\n",
    "                fname= 'STACK_internal_test_layer_'+str(i)+'.bin'\n",
    "                np.save(open(fname,'wb'),Xt_test)\n",
    "            i+=1\n",
    "        Xt_train.drop('target',axis=1,inplace=True)\n",
    "        self.top_layer.fit(Xt_train.as_matrix(),y)\n",
    "        return self.top_layer.predict_proba(Xt_test.as_matrix())[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now score the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Read data\n",
    "\n",
    "# # train\n",
    "# X_train= np.load(open('../WP014/dummy_train_matrix.bin','rb'))\n",
    "# y_train= np.load(open('../WP014/dummy_train_labels.bin','rb'))\n",
    "\n",
    "# # test\n",
    "# X_test= np.load(open('../WP014/dummy_test_matrix.bin','rb'))\n",
    "# y_test= np.load(open('../WP014/dummy_test_labels.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection, pipe0_median as pipe0\n",
    "\n",
    "df_train= pd.read_csv('../data/train.csv')\n",
    "df_test= pd.read_csv('../data/test.csv')\n",
    "\n",
    "X_train, y_train, X_test, y_test= pipe0.run_pipe0( df_train.copy(),df_test.copy() )\n",
    "\n",
    "# index_train, index_test= sklearn.model_selection.train_test_split( range(len(df_train.index)) , \n",
    "#                                                                     test_size=0.3,random_state=1)\n",
    "# \n",
    "# df_test= df_train.loc[index_test,:].reset_index(drop=True)\n",
    "# y_test= df_test.target.values\n",
    "# df_train= df_train.loc[index_train,:].reset_index(drop=True)\n",
    "# y_train= df_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read rgf pipeline train and test scores\n",
    "# X_rgf_train= pd.read_csv('../wp017/rgf_scores_train.csv').target.values\n",
    "# X_rgf_test= pd.read_csv('../wp017/rgf_blind_scores.csv').target.values\n",
    "X_rgf_test= pd.read_csv('../wp018/output_0.01_300leaf/rgf_blind_scores.csv').target.values\n",
    "X_rgf_train= pd.read_csv('../wp018/output_0.01_300leaf/rgf_validation_ scores.csv').target.values\n",
    "# X_rgf_test= X_rgf_train.target.values[index_test]\n",
    "# X_rgf_train= X_rgf_train.target.values[index_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ids= pd.read_csv('../data/test.csv',usecols=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm.sklearn\n",
    "import xgboost.sklearn\n",
    "import catboost\n",
    "import sklearn.linear_model, sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['n_estimators'] = 1300\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['num_leaves']= 25\n",
    "lgb_params['n_jobs']=8\n",
    "\n",
    "\n",
    "# lgb_params_3 = {\n",
    "#     'learning_rate': 0.02,\n",
    "#     'n_estimators': 800,\n",
    "#     'max_depth': 4,\n",
    "#     'n_jobs':8\n",
    "# }\n",
    "lgb_params_3 = {\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 800, #150,\n",
    "    'max_depth': 4,\n",
    "    'n_jobs':8\n",
    "#     'min_child_samples':100\n",
    "}\n",
    "\n",
    "lgb_params_4 = {\n",
    "    'learning_rate':0.05,\n",
    "    'n_estimators':600,\n",
    "    'num_leaves':35,\n",
    "    'min_child_samples':500,\n",
    "    'n_jobs':8\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params= {'learning_rate': 0.07,\n",
    "             'n_estimators':525,\n",
    "             'max_depth': 4, \n",
    "             'nthread':8,\n",
    "             'subsample': 0.8,\n",
    "             'min_child_weight':6.0, \n",
    "             'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', \n",
    "             'eval_metric': 'auc', \n",
    "             'seed': 99, \n",
    "             'silent': True,\n",
    "             'scale_pos_weight': 1.6,\n",
    "             'reg_alpha':8,\n",
    "             'reg_lambda':1.3,\n",
    "             'gamma':10\n",
    "            }\n",
    "\n",
    "cb_params= {\n",
    "    'learning_rate':0.05, \n",
    "    'depth':6, \n",
    "    'l2_leaf_reg': 14, \n",
    "    'iterations': 650,\n",
    "    'verbose': False,\n",
    "    'loss_function':'Logloss'\n",
    "    }\n",
    "\n",
    "# lgbmn_params= {'num_leaves': 81, 'verbose': 1, 'learning_rate': 0.005, \n",
    "#                'min_data': 650, 'categorical_column': [], 'bagging_fraction': 0.9, \n",
    "#                'metric': ['auc'], 'boosting_type': 'gbdt', 'lambda_l1': 30,\n",
    "#                'bagging_freq': 3, 'lambda_l2': 0, 'is_unbalance': True, \n",
    "#                'max_bin': 255, 'objective': ['binary'], 'max_depth': 6, \n",
    "#                'feature_fraction': 0.7,'n_estimators':1600\n",
    "#               }\n",
    "\n",
    "# Layer 1\n",
    "lgbm1 = (pipe0.run_pipe0,  lightgbm.sklearn.LGBMClassifier(**lgb_params))\n",
    "xgbm1= (pipe0.run_pipe0,   xgboost.sklearn.XGBClassifier(**xgb_params))\n",
    "lgbm3 = (pipe0.run_pipe0,  lightgbm.sklearn.LGBMClassifier(**lgb_params_3))\n",
    "lgbm4 = (pipe0.run_pipe0,  lightgbm.sklearn.LGBMClassifier(**lgb_params_4))\n",
    "cb= (pipe0.run_pipe0,      catboost.CatBoostClassifier(**cb_params))\n",
    "# lgbmn = (pipe3.run_pipe3,  lightgbm.sklearn.LGBMClassifier(**lgbmn_params))\n",
    "\n",
    "# Top layer\n",
    "# stacker= sklearn.linear_model.LogisticRegression(C=500.0,class_weight='balanced',penalty='l1')\n",
    "\n",
    "# Define the stack\n",
    "# stack = Stack(3,[ [cb,xgbm1,lgbm1,lgbm3,lgbm4] ], stacker, saveInternalVectors=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  57.309064\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime,timedelta\n",
    "tc= datetime.now()\n",
    "X_train, y_train, X_test, y_test= pipe0.run_pipe0( df_train.copy(),df_test.copy() )\n",
    "lgbm3= lightgbm.sklearn.LGBMClassifier(**lgb_params_3)\n",
    "lgbm3.fit(X_train,y_train)\n",
    "ypred= lgbm3.predict_proba(X_test)[:,1]\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds()\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ypred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "import bagging_me\n",
    "def bag_classifier(base,PIPELINE,df_train,df_test):\n",
    "    tc= datetime.now()\n",
    "    clf= bagging_me.BaggingClassifier(base,\n",
    "                                            n_estimators=32,\n",
    "                                            oob_score=True,\n",
    "                                            max_features=0.8,\n",
    "                                            max_samples=0.6,\n",
    "                                            random_state=1,\n",
    "                                            n_jobs=1\n",
    "                                           )\n",
    "    X_train, y_train, X_test, y_test= PIPELINE( df_train.copy(),df_test.copy() )\n",
    "    clf.fit(X_train,y_train,sample_weight=None)\n",
    "    oob= clf.oob_decision_function_[:,1]\n",
    "    y_pred= clf.predict_proba(X_test)[:,1]\n",
    "    print 'Training took: ',(datetime.now() - tc).total_seconds()\n",
    "    return oob, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  830.969689\n",
      "OOB Gini score=  0.286489148083\n"
     ]
    }
   ],
   "source": [
    "lgbm3= lightgbm.sklearn.LGBMClassifier(**lgb_params_3)\n",
    "oob, ptest= bag_classifier(lgbm3,pipe0.run_pipe0,df_train,df_test)\n",
    "print 'OOB Gini score= ',2.*sklearn.metrics.roc_auc_score(y_train,oob)-1.\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ptest)-1.\n",
    "pd.DataFrame({'id':df_train['id'].values, 'target':oob},columns=['id','target']).to_csv('internals_test/lgbm3_oob.csv',\n",
    "                                                                                        index=False)\n",
    "pd.DataFrame({'id':df_test['id'].values, 'target':ptest},columns=['id','target']).to_csv('internals_test/lgbm3_test.csv',\n",
    "                                                                                        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  96.548018\n"
     ]
    }
   ],
   "source": [
    "tc= datetime.now()\n",
    "X_train, y_train, X_test, y_test= pipe0.run_pipe0( df_train.copy(),df_test.copy() )\n",
    "lgbm1= lightgbm.sklearn.LGBMClassifier(**lgb_params)\n",
    "lgbm1.fit(X_train,y_train)\n",
    "ypred= lgbm1.predict_proba(X_test)[:,1]\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds()\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ypred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  1678.619106\n",
      "OOB Gini score=  0.285851819675\n"
     ]
    }
   ],
   "source": [
    "lgbm1= lightgbm.sklearn.LGBMClassifier(**lgb_params)\n",
    "oob, ptest= bag_classifier(lgbm1,pipe0.run_pipe0,df_train,df_test)\n",
    "print 'OOB Gini score= ',2.*sklearn.metrics.roc_auc_score(y_train,oob)-1.\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ptest)-1.\n",
    "pd.DataFrame({'id':df_train['id'].values, 'target':oob},columns=['id','target']).to_csv('internals_test/lgbm1_oob.csv',\n",
    "                                                                                        index=False)\n",
    "pd.DataFrame({'id':df_test['id'].values, 'target':ptest},columns=['id','target']).to_csv('internals_test/lgbm1_test.csv',\n",
    "                                                                                        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LGBM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  53.311398\n"
     ]
    }
   ],
   "source": [
    "tc= datetime.now()\n",
    "X_train, y_train, X_test, y_test= pipe0.run_pipe0( df_train.copy(),df_test.copy() )\n",
    "lgbm4= lightgbm.sklearn.LGBMClassifier(**lgb_params_4)\n",
    "lgbm4.fit(X_train,y_train)\n",
    "ypred= lgbm4.predict_proba(X_test)[:,1]\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds()\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ypred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  790.394124\n",
      "OOB Gini score=  0.285332756327\n"
     ]
    }
   ],
   "source": [
    "lgbm4= lightgbm.sklearn.LGBMClassifier(**lgb_params_4)\n",
    "oob, ptest= bag_classifier(lgbm4,pipe0.run_pipe0,df_train,df_test)\n",
    "print 'OOB Gini score= ',2.*sklearn.metrics.roc_auc_score(y_train,oob)-1.\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ptest)-1.\n",
    "pd.DataFrame({'id':df_train['id'].values, 'target':oob},columns=['id','target']).to_csv('internals_test/lgbm4_oob.csv',\n",
    "                                                                                        index=False)\n",
    "pd.DataFrame({'id':df_test['id'].values, 'target':ptest},columns=['id','target']).to_csv('internals_test/lgbm4_test.csv',\n",
    "                                                                                        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  153.069223\n"
     ]
    }
   ],
   "source": [
    "tc= datetime.now()\n",
    "X_train, y_train, X_test, y_test= pipe0.run_pipe0( df_train.copy(),df_test.copy() )\n",
    "xgb= xgboost.sklearn.XGBClassifier(**xgb_params)\n",
    "xgb.fit(X_train,y_train)\n",
    "ypred= xgb.predict_proba(X_test)[:,1]\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds()\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ypred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  2536.753526\n",
      "OOB Gini score=  0.288650029066\n"
     ]
    }
   ],
   "source": [
    "xgb= xgboost.sklearn.XGBClassifier(**xgb_params)\n",
    "oob, ptest= bag_classifier(xgb,pipe0.run_pipe0,df_train,df_test)\n",
    "print 'OOB Gini score= ',2.*sklearn.metrics.roc_auc_score(y_train,oob)-1.\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ptest)-1.\n",
    "pd.DataFrame({'id':df_train['id'].values, 'target':oob},columns=['id','target']).to_csv('internals_test/xgb_oob.csv',\n",
    "                                                                                        index=False)\n",
    "pd.DataFrame({'id':df_test['id'].values, 'target':ptest},columns=['id','target']).to_csv('internals_test/xgb_test.csv',\n",
    "                                                                                        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  349.613966\n"
     ]
    }
   ],
   "source": [
    "tc= datetime.now()\n",
    "X_train, y_train, X_test, y_test= pipe0.run_pipe0( df_train.copy(),df_test.copy() )\n",
    "cb= catboost.CatBoostClassifier(**cb_params)\n",
    "cb.fit(X_train,y_train)\n",
    "ypred= cb.predict_proba(X_test)[:,1]\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds()\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ypred)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  5751.556413\n",
      "OOB Gini score=  0.286864230361\n"
     ]
    }
   ],
   "source": [
    "cb= catboost.CatBoostClassifier(**cb_params)\n",
    "oob, ptest= bag_classifier(cb,pipe0.run_pipe0,df_train,df_test)\n",
    "print 'OOB Gini score= ',2.*sklearn.metrics.roc_auc_score(y_train,oob)-1.\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,ptest)-1.\n",
    "pd.DataFrame({'id':df_train['id'].values, 'target':oob},columns=['id','target']).to_csv('internals_test/cb_oob.csv',\n",
    "                                                                                        index=False)\n",
    "pd.DataFrame({'id':df_test['id'].values, 'target':ptest},columns=['id','target']).to_csv('internals_test/cb_test.csv',\n",
    "                                                                                        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now grab the data and ensemble it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb= pd.read_csv('internals_test/cb_oob.csv')\n",
    "xgb= pd.read_csv('internals_test/xgb_oob.csv')\n",
    "lgb1= pd.read_csv('internals_test/lgbm1_oob.csv')\n",
    "lgb3= pd.read_csv('internals_test/lgbm3_oob.csv')\n",
    "lgb4= pd.read_csv('internals_test/lgbm4_oob.csv')\n",
    "harl= pd.read_csv('../wp023/internals_test/harless_oob.csv')\n",
    "# froza= pd.read_csv('../wp023/internals_test/froza_oof.csv')\n",
    "# keras= pd.read_csv('internals/keras_oob.csv')\n",
    "# lrbase= pd.read_csv('internals/LRbase_oob.csv')\n",
    "X_OOB= pd.DataFrame({'cb':cb.target.values,\n",
    "                     'xgb':xgb.target.values,\n",
    "                     'lgb1':lgb1.target.values,\n",
    "                     'lgb3':lgb3.target.values,\n",
    "                     'lgb4':lgb4.target.values,\n",
    "                     'rgf':X_rgf_train,\n",
    "                     'harl':harl.target.values\n",
    "#                      'froza':froza.target.values\n",
    "#                      'keras':keras.target.values[index_train]\n",
    "#                      'lrbase':lrbase.target.values\n",
    "                     }).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb= pd.read_csv('internals_test/cb_test.csv')\n",
    "xgb= pd.read_csv('internals_test/xgb_test.csv')\n",
    "lgb1= pd.read_csv('internals_test/lgbm1_test.csv')\n",
    "lgb3= pd.read_csv('internals_test/lgbm3_test.csv')\n",
    "lgb4= pd.read_csv('internals_test/lgbm4_test.csv')\n",
    "harl= pd.read_csv('../wp023/internals_test/harless_test.csv')\n",
    "# froza= pd.read_csv('../wp023/internals_test/froza_test.csv')\n",
    "# keras= pd.read_csv('internals/keras_test.csv')\n",
    "# lrbase= pd.read_csv('internals/LRbase_test.csv')\n",
    "\n",
    "X_TEST= pd.DataFrame({'cb':cb.target.values,\n",
    "                     'xgb':xgb.target.values,\n",
    "                     'lgb1':lgb1.target.values,\n",
    "                     'lgb3':lgb3.target.values,\n",
    "                     'lgb4':lgb4.target.values,\n",
    "                     'rgf':X_rgf_test,\n",
    "                     'harl':harl.target.values\n",
    "#                      'froza':froza.target.values\n",
    "#                      'keras':keras.target.values[index_test]\n",
    "#                      'lrbase':lrbase.target.values\n",
    "                     }).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Gini score=  0.291194763656 0.286699739102 0.289887071208 0.287\n"
     ]
    }
   ],
   "source": [
    "#  This for testing ensemble incl RGF\n",
    "internal= [0,1,2,3,4,5,6]\n",
    "folds = StratifiedKFold(y_train,n_folds=40, shuffle=True, random_state=2016)\n",
    "y_pred= np.zeros(len(y_train))\n",
    "for i, (itr,ite) in enumerate(folds):\n",
    "    stacker= sklearn.linear_model.LogisticRegression(C=1.0,class_weight='balanced',penalty='l2')\n",
    "    stacker.fit( X_OOB[np.ix_(itr,internal)] , y_train[itr] )\n",
    "    y_pred[ite]= stacker.predict_proba(X_OOB[np.ix_(ite,internal)])[:,1]\n",
    "print 'CV Gini score= ',2.*sklearn.metrics.roc_auc_score(y_train,y_pred)-1.,0.286699739102,0.289887071208,0.2870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred= stacker.predict_proba(X_TEST[:,internal])[:,1]\n",
    "# print 'TEST Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1.,0.286699739102,0.287116870117,0.292955968548"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try the bagging approach (which will take longer).  Now the above appears to be better!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  56.774913\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "from datetime import datetime,timedelta\n",
    "tc= datetime.now()\n",
    "clf= sklearn.ensemble.BaggingClassifier(stacker,\n",
    "                                        n_estimators=128,\n",
    "                                        oob_score=True,\n",
    "                                        max_features=4,\n",
    "                                        max_samples=0.8,\n",
    "                                        random_state=1,\n",
    "                                        n_jobs=-1\n",
    "                                       )\n",
    "clf.fit(X_OOB,y_train)\n",
    "y_pred= clf.predict_proba(X_TEST)[:,1]\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595212 595212\n"
     ]
    }
   ],
   "source": [
    "y_pred2= clf.oob_decision_function_[:,1]\n",
    "ok= np.where(map(np.isfinite,y_pred2))[0]\n",
    "print len(ok),len(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Gini score=  0.29086944693 0.286463220363 (0.286760096353)\n"
     ]
    }
   ],
   "source": [
    "print 'OOB Gini score= ',2.*sklearn.metrics.roc_auc_score(y_train[ok],y_pred2[ok])-1.,0.286463220363,'(0.286760096353)'\n",
    "# print 'Test Gini score= ',2.*sklearn.metrics.roc_auc_score(y_test,y_pred)-1.,0.291740847787,'(0.292343541304)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# out_df= pd.DataFrame( {'id': test_ids.id.values, 'target': y_pred},\n",
    "#                      columns=['id','target']\n",
    "#                     ).to_csv('submission_wp023b.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
