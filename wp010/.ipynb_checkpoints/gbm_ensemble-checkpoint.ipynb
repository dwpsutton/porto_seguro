{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidsutton/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    " \n",
    "def test_gini():\n",
    "    def fequ(a,b):\n",
    "        return abs( a -b) < 1e-6\n",
    "    def T(a, p, g, n):\n",
    "        assert( fequ(gini(a,p), g) )\n",
    "        assert( fequ(gini_normalized(a,p), n) )\n",
    "    T([1, 2, 3], [10, 20, 30], 0.111111, 1)\n",
    "    T([1, 2, 3], [30, 20, 10], -0.111111, -1)\n",
    "    T([1, 2, 3], [0, 0, 0], -0.111111, -1)\n",
    "    T([3, 2, 1], [0, 0, 0], 0.111111, 1)\n",
    "    T([1, 2, 4, 3], [0, 0, 0, 0], -0.1, -0.8)\n",
    "    T([2, 1, 4, 3], [0, 0, 2, 1], 0.125, 1)\n",
    "    T([0, 20, 40, 0, 10], [40, 40, 10, 5, 5], 0, 0)\n",
    "    T([40, 0, 20, 0, 10], [1000000, 40, 40, 5, 5], 0.171428,\n",
    "       0.6)\n",
    "    T([40, 20, 10, 0, 0], [40, 20, 10, 0, 0], 0.285714, 1)\n",
    "    T([1, 1, 0, 1], [0.86, 0.26, 0.52, 0.32], -0.041666,\n",
    "       -0.333333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train= np.load(open('../wp005/full_train_matrix.bin','rb'))\n",
    "y_train= np.load(open('../wp005/full_train_labels.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test= np.load(open('../wp005/blind_test_matrix.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids= pd.read_csv('../data/test.csv',usecols=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df= pd.DataFrame(X_train,columns= ['x'+str(i) for i in range(np.shape(X_train)[1])])\n",
    "# df.loc[:,'y']= y_train\n",
    "# df.to_csv('train.csv',index=False,columns=['y']+['x'+str(i) for i in range(np.shape(X_train)[1])])\n",
    "# \n",
    "# df= pd.DataFrame(X_test,columns= ['x'+str(i) for i in range(np.shape(X_train)[1])])\n",
    "# df.loc[:,'y']= np.zeros(np.shape(X_test)[0])\n",
    "# df.to_csv('test.csv',index=False,columns=['y']+['x'+str(i) for i in range(np.shape(X_train)[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run vanilla random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sklearn.linear_model\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tc= datetime.now()\n",
    "# lr= sklearn.linear_model.LogisticRegression(penalty='l2',\n",
    "#                                             C=1.,\n",
    "#                                             class_weight='balanced'\n",
    "#                                             )\n",
    "# lr.fit(X_train,y_train)\n",
    "# print 'Training took: ',(datetime.now() - tc).total_seconds(),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "#                y_holdout = y[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "#                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "#                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (2.*results.mean()-1.))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 4\n",
      "Fit LGBMClassifier fold 5\n",
      "Fit LGBMClassifier fold 6\n",
      "Fit LGBMClassifier fold 7\n",
      "Fit LGBMClassifier fold 8\n",
      "Fit LGBMClassifier fold 9\n",
      "Fit LGBMClassifier fold 10\n",
      "Stacker score: 0.28931\n",
      "Training took:  2803.169391  seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tc= datetime.now()\n",
    "import lightgbm.sklearn\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['n_estimators'] = 1300\n",
    "#lgb_params['max_depth'] = 10\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['num_leaves']= 25\n",
    "# lgb_params['random_state']= 0\n",
    "gbm1 = lightgbm.sklearn.LGBMClassifier(**lgb_params)\n",
    "\n",
    "lgb_params_2 = {\n",
    "    'learning_rate': 0.005,\n",
    "    'n_estimators': 3700,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 2,\n",
    "    'colsample_bytree': 0.3,  \n",
    "    'num_leaves': 16\n",
    "}\n",
    "\n",
    "lgb_params_3 = {\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 800,\n",
    "    'max_depth': 4\n",
    "}\n",
    "\n",
    "lgb_params_4 = {\n",
    "    'learning_rate':0.05,\n",
    "    'n_estimators':600,\n",
    "    'num_leaves':35,\n",
    "    'min_child_samples':500\n",
    "}\n",
    "\n",
    "gbm2 = lightgbm.sklearn.LGBMClassifier(**lgb_params_2)\n",
    "gbm3 = lightgbm.sklearn.LGBMClassifier(**lgb_params_3)\n",
    "gbm4 = lightgbm.sklearn.LGBMClassifier(**lgb_params_4)\n",
    "\n",
    "\n",
    "import sklearn.neural_network\n",
    "mlp_params= {\n",
    "    'hidden_layer_sizes':(100,100), \n",
    "    'activation':'relu', \n",
    "    'solver':'adam', \n",
    "    'alpha':0.0000001, \n",
    "    'batch_size':'auto', \n",
    "    'learning_rate_init':0.001, \n",
    "    'shuffle':True, \n",
    "    'tol':0.0001, \n",
    "    'early_stopping': True,\n",
    "    'validation_fraction':0.1, \n",
    "    'beta_1':0.9, \n",
    "    'beta_2':0.999, \n",
    "    'epsilon':1e-08\n",
    "}\n",
    "mlp= sklearn.neural_network.MLPClassifier(**mlp_params)\n",
    "#mlp.fit(X_train,y_train)\n",
    "#y_pred= mlp.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "import sklearn.linear_model\n",
    "lr_base_params= {\n",
    "    'C':100.0,\n",
    "     'penalty':'l2',\n",
    "    'class_weight':'balanced'\n",
    "}\n",
    "lr_base= sklearn.linear_model.LogisticRegression(**lr_base_params)\n",
    "#lr_base.fit(X_train,y_train)\n",
    "#y_pred= lr_base.predict_proba(X_test)[:,1]\n",
    "\n",
    "lr_stacker= sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "# knnparams={\n",
    "#     'n_neighbors':5, \n",
    "#     'weights':'uniform', \n",
    "#     'algorithm':'kd_tree'\n",
    "# }\n",
    "# import sklearn.neighbors\n",
    "# knn= sklearn.neighbors.KNeighborsClassifier(**knnparams)\n",
    "# knn.fit(X_train,y_train)\n",
    "# y_pred= knn.predict_proba(X_test)\n",
    "\n",
    "tc= datetime.now()\n",
    "stack = Ensemble(n_splits=10,\n",
    "stacker = lr_stacker,\n",
    "        base_models = (gbm1, gbm2, gbm3, gbm4))#, mlp, lr_base))        \n",
    "y_pred = stack.fit_predict(X_train, y_train, X_test) \n",
    "\n",
    "print 'Training took: ',(datetime.now() - tc).total_seconds(),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob= y_pred #gbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output predictions:  id 0 based and target\n",
    "out_df= pd.DataFrame( {'id': test_ids.id.values, 'target': prob},\n",
    "                     columns=['id','target']\n",
    "                    ).to_csv('submission_wp010.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(stack,open('simple_stacker.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
